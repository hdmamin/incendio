{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "`# TODO: summary here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:04.698255Z",
     "start_time": "2020-11-04T01:56:04.680904Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:45:14.851849Z",
     "start_time": "2020-11-05T06:45:14.831536Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Iterable, Mapping\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, \\\n",
    "    PegasusTokenizerFast, pipeline\n",
    "\n",
    "from htools import *\n",
    "from incendio.utils import DEVICE, gpu_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:28.431548Z",
     "start_time": "2020-11-04T01:56:28.422988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:38: UserWarning: Cuda not available.\n",
      "  if not torch.cuda.is_available(): warnings.warn('Cuda not available.')\n",
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:41: UserWarning: Incendio device is not cuda.\n",
      "  warnings.warn('Incendio device is not cuda.')\n"
     ]
    }
   ],
   "source": [
    "gpu_setup(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:08:35.518032Z",
     "start_time": "2020-11-03T05:00:40.657875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92da3ec470d4eb8be89512326ea21d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1142.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bd9a1afd3840b8aac70a9555e3ca4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275437102.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57de7fc53a3548e484a29750e08b7b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60954), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60955), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80664141cea4abcbf763e3ffd8d9086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3636536d7c81495baeb06f1e6d76919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=86.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:69: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/hmamin/.cache/torch/transformers/fa4532c0035b101d7abcd5c0c9c34a83288902b66c5616034db1a47643e05c75.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e'>\n",
      "  m.ParseFromString(open(filename, \"rb\").read())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "version = 'tuner007/pegasus_paraphrase'\n",
    "net = PegasusForConditionalGeneration.from_pretrained(version)\n",
    "tok = PegasusTokenizerFast.from_pretrained(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:23:58.588210Z",
     "start_time": "2020-11-03T05:23:58.575168Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:00.401253Z",
     "start_time": "2020-11-03T05:35:00.396827Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Educational games and digital learning materials to provide K-12 '\n",
    "    'students with enriching experiences.',\n",
    "    'The world\\'s largest social network. Helping people build and maintain '\n",
    "    'relationships in a disconnected world.',\n",
    "    'I hate school. I wish my teacher would leave me alone. I don\\'t think '\n",
    "    ' he likes me.',\n",
    "    'Today the president announced new plans to revamp the private '\n",
    "    'healthcare system. Pundits questioned how he would manage to pass the '\n",
    "    'bill.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:09:03.847681Z",
     "start_time": "2020-11-03T05:09:03.824049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SPECIAL_TOKENS_ATTRIBUTES': 'attribute',\n",
       " 'add_special_tokens': 'method',\n",
       " 'add_tokens': 'method',\n",
       " 'additional_special_tokens': 'attribute',\n",
       " 'additional_special_tokens_ids': 'attribute',\n",
       " 'all_special_ids': 'attribute',\n",
       " 'all_special_tokens': 'attribute',\n",
       " 'all_special_tokens_extended': 'attribute',\n",
       " 'backend_tokenizer': 'attribute',\n",
       " 'batch_decode': 'method',\n",
       " 'batch_encode_plus': 'method',\n",
       " 'bos_token': 'attribute',\n",
       " 'bos_token_id': 'attribute',\n",
       " 'build_inputs_with_special_tokens': 'method',\n",
       " 'clean_up_tokenization': 'method',\n",
       " 'cls_token': 'attribute',\n",
       " 'cls_token_id': 'attribute',\n",
       " 'convert_ids_to_tokens': 'method',\n",
       " 'convert_tokens_to_ids': 'method',\n",
       " 'create_token_type_ids_from_sequences': 'method',\n",
       " 'decode': 'method',\n",
       " 'deprecation_warnings': 'attribute',\n",
       " 'encode': 'method',\n",
       " 'encode_plus': 'method',\n",
       " 'eos_token': 'attribute',\n",
       " 'eos_token_id': 'attribute',\n",
       " 'from_pretrained': 'method',\n",
       " 'get_added_vocab': 'method',\n",
       " 'get_special_tokens_mask': 'method',\n",
       " 'get_vocab': 'method',\n",
       " 'init_inputs': 'attribute',\n",
       " 'init_kwargs': 'attribute',\n",
       " 'is_fast': 'attribute',\n",
       " 'mask_token': 'attribute',\n",
       " 'mask_token_id': 'attribute',\n",
       " 'max_len': 'attribute',\n",
       " 'max_len_sentences_pair': 'attribute',\n",
       " 'max_len_single_sentence': 'attribute',\n",
       " 'max_model_input_sizes': 'attribute',\n",
       " 'model_input_names': 'attribute',\n",
       " 'model_max_length': 'attribute',\n",
       " 'name_or_path': 'attribute',\n",
       " 'num_special_tokens_to_add': 'method',\n",
       " 'offset': 'attribute',\n",
       " 'pad': 'method',\n",
       " 'pad_token': 'attribute',\n",
       " 'pad_token_id': 'attribute',\n",
       " 'pad_token_type_id': 'attribute',\n",
       " 'padding_side': 'attribute',\n",
       " 'prepare_for_model': 'method',\n",
       " 'prepare_seq2seq_batch': 'method',\n",
       " 'pretrained_init_configuration': 'attribute',\n",
       " 'pretrained_vocab_files_map': 'attribute',\n",
       " 'sanitize_special_tokens': 'method',\n",
       " 'save_pretrained': 'method',\n",
       " 'save_vocabulary': 'method',\n",
       " 'sep_token': 'attribute',\n",
       " 'sep_token_id': 'attribute',\n",
       " 'set_truncation_and_padding': 'method',\n",
       " 'slow_tokenizer_class': 'method',\n",
       " 'special_tokens_map': 'attribute',\n",
       " 'special_tokens_map_extended': 'attribute',\n",
       " 'tokenize': 'method',\n",
       " 'truncate_sequences': 'method',\n",
       " 'unk_token': 'attribute',\n",
       " 'unk_token_id': 'attribute',\n",
       " 'verbose': 'attribute',\n",
       " 'vocab_file': 'attribute',\n",
       " 'vocab_files_names': 'attribute',\n",
       " 'vocab_size': 'attribute'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdir(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:06.682140Z",
     "start_time": "2020-11-03T05:11:06.638522Z"
    }
   },
   "outputs": [],
   "source": [
    "res = tok.prepare_seq2seq_batch(texts, truncation=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:08.427646Z",
     "start_time": "2020-11-03T05:11:08.403336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11263,   727,   111,  1016,   761,   917,   112,   319,  1046,  6054,\n",
       "           392,   122, 26838,  1747,   107,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  139,   278,   131,   116,  1368,   525,   952,   107, 22844,   200,\n",
       "           736,   111,  1634,  2074,   115,   114, 20402,   278,   107,     1,\n",
       "             0,     0,     0],\n",
       "        [  125,  4180,   399,   107,   125,  1216,   161,  2118,   192,   858,\n",
       "           213,  1600,   107,   125,   272,   131,   144,   311,   178,  5606,\n",
       "           213,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:13:07.112402Z",
     "start_time": "2020-11-03T05:12:49.471597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1046, 6054,  392,  137,  207, 2387,  727,  111, 1016,  761,  917,\n",
       "          107,    1,    0,    0,    0],\n",
       "        [   0,  139,  278,  131,  116, 1368,  525,  952,  107,    1,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [   0,  125,  272,  131,  144,  172,  399,  111,  161, 2118,  591,  131,\n",
       "          144,  172,  213,  107,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = net.generate(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:15:57.224563Z",
     "start_time": "2020-11-03T05:15:57.215548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K-12 students can use educational games and digital learning materials.',\n",
       " \"The world's largest social network.\",\n",
       " \"I don't like school and my teacher doesn't like me.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.batch_decode(gen.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:36:34.347485Z",
     "start_time": "2020-11-03T05:36:34.337003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "@add_docstring(net.generate)\n",
    "def paraphrase(text, n=1, temperature=1.5, **gen_kwargs):\n",
    "    batch = tok.prepare_seq2seq_batch([text], truncation=True, \n",
    "                                      padding='longest').to(DEVICE)\n",
    "    paraphrased = net.generate(**batch, num_return_sequences=n,\n",
    "                               temperature=temperature, **gen_kwargs)\n",
    "    return tok.batch_decode(paraphrased.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.051823Z",
     "start_time": "2020-11-03T05:35:21.489262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The president announced plans to reform the private healthcare system.',\n",
       " 'Pundits wondered how the president would pass the bill.',\n",
       " 'Pundits questioned how the president would pass the bill.',\n",
       " 'Pundits were questioning how the president would pass the bill.',\n",
       " 'Pundits questioned how he would get the bill passed.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase(texts[3], n=5, num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.113484Z",
     "start_time": "2020-11-03T05:35:36.066617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today the president announced new plans to revamp the private healthcare system. Pundits questioned how he would manage to pass the bill.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:31:10.784475Z",
     "start_time": "2020-11-03T05:31:10.771992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <Parameter \"input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_input_ids': <Parameter \"decoder_input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'max_length': <Parameter \"max_length: Union[int, NoneType] = None\">,\n",
       " 'min_length': <Parameter \"min_length: Union[int, NoneType] = None\">,\n",
       " 'do_sample': <Parameter \"do_sample: Union[bool, NoneType] = None\">,\n",
       " 'early_stopping': <Parameter \"early_stopping: Union[bool, NoneType] = None\">,\n",
       " 'num_beams': <Parameter \"num_beams: Union[int, NoneType] = None\">,\n",
       " 'temperature': <Parameter \"temperature: Union[float, NoneType] = None\">,\n",
       " 'top_k': <Parameter \"top_k: Union[int, NoneType] = None\">,\n",
       " 'top_p': <Parameter \"top_p: Union[float, NoneType] = None\">,\n",
       " 'repetition_penalty': <Parameter \"repetition_penalty: Union[float, NoneType] = None\">,\n",
       " 'bad_words_ids': <Parameter \"bad_words_ids: Union[Iterable[int], NoneType] = None\">,\n",
       " 'bos_token_id': <Parameter \"bos_token_id: Union[int, NoneType] = None\">,\n",
       " 'pad_token_id': <Parameter \"pad_token_id: Union[int, NoneType] = None\">,\n",
       " 'eos_token_id': <Parameter \"eos_token_id: Union[int, NoneType] = None\">,\n",
       " 'length_penalty': <Parameter \"length_penalty: Union[float, NoneType] = None\">,\n",
       " 'no_repeat_ngram_size': <Parameter \"no_repeat_ngram_size: Union[int, NoneType] = None\">,\n",
       " 'num_return_sequences': <Parameter \"num_return_sequences: Union[int, NoneType] = None\">,\n",
       " 'attention_mask': <Parameter \"attention_mask: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_start_token_id': <Parameter \"decoder_start_token_id: Union[int, NoneType] = None\">,\n",
       " 'use_cache': <Parameter \"use_cache: Union[bool, NoneType] = None\">,\n",
       " 'model_kwargs': <Parameter \"**model_kwargs\">}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:00.223761Z",
     "start_time": "2020-11-04T02:14:00.215949Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParaphrasePipeline:\n",
    "    \n",
    "    name = 'tuner007/pegasus_paraphrase'\n",
    "    \n",
    "    def __init__(self, net=None, tok=None):\n",
    "        self.net = net or PegasusForConditionalGeneration.from_pretrained(\n",
    "            self.name).to(DEVICE)\n",
    "        self.tok = tok or PegasusTokenizerFast.from_pretrained(self.name)\n",
    "        \n",
    "    @add_docstring(PegasusForConditionalGeneration.generate)\n",
    "    def __call__(self, text, n=1, temperature=1.5, **kwargs):\n",
    "        # TODO: not sure how many rows of text can be done in a single batch.\n",
    "        # Maybe look at other pipelines to see what they do. I'm thinking we\n",
    "        # could auto-batch longer sequences (e.g. a list w/ 10_000 strings\n",
    "        # might become 100 batches of 100).\n",
    "        texts = [text] if isinstance(text, str) else text\n",
    "        batch = self.tok.prepare_seq2seq_batch(texts, truncation=True, \n",
    "                                               padding='longest').to(DEVICE)\n",
    "        gen_tokens = self.net.generate(**batch, num_return_sequences=n,\n",
    "                                       temperature=temperature, **kwargs)\n",
    "        gen = self.tok.batch_decode(gen_tokens.tolist(), \n",
    "                                    skip_special_tokens=True)\n",
    "        if not isinstance(text, str) and len(text) > 1: \n",
    "            gen = [gen[i*n:(i+1)*n] for i in range(len(text))]\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:11:53.691189Z",
     "start_time": "2020-11-04T02:11:53.688274Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = ParaphrasePipeline(net, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:11:59.094586Z",
     "start_time": "2020-11-04T02:11:55.579388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('It was a beautiful rainy day.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:02.864510Z",
     "start_time": "2020-11-04T02:11:59.098781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.',\n",
       " 'It was a nice day.',\n",
       " 'It was raining but it was nice.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('It was a beautiful rainy day.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:06.328322Z",
     "start_time": "2020-11-04T02:12:02.868563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.'], ['The duck was fluffy and yellow.']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:09.898263Z",
     "start_time": "2020-11-04T02:12:06.330746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.',\n",
       "  'It was a nice day.',\n",
       "  'It was raining but it was nice.'],\n",
       " ['The duck was fluffy and yellow.',\n",
       "  'The duck was fluffy.',\n",
       "  'The duck was big and fluffy.']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'], \n",
    "     n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:12.933407Z",
     "start_time": "2020-11-04T02:12:09.901067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.', 'It was a nice day.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.'], n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:58:59.740937Z",
     "start_time": "2020-11-03T05:58:59.734081Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerTransform:\n",
    "    \n",
    "    def __init__(self, mode, n=1):\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "        self.predictor = self._get_transformer()\n",
    "        \n",
    "#     def __call__(self, text):\n",
    "#         self._preprocess(text)\n",
    "    \n",
    "#     @abstractmethod\n",
    "#     def _preprocess(self, text):\n",
    "#         pass\n",
    "    \n",
    "    def _get_transformer(self):\n",
    "        if self.mode == 'mask':\n",
    "            return pipeline('fill-mask')\n",
    "        elif self.mode == 'generate':\n",
    "            return pipeline('text-generation')\n",
    "        elif self.mode == 'paraphrase':\n",
    "            return ParaphrasePipeline()\n",
    "        else:\n",
    "            raise ValueError('mode must be in (mask, generate, paraphrase).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:01.828462Z",
     "start_time": "2020-11-05T06:55:01.817858Z"
    }
   },
   "outputs": [],
   "source": [
    "class FillMaskTransform:    \n",
    "    \n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('fill-mask')\n",
    "        assert type(self.pipe).__name__ == 'FillMaskPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, n=1, min_keep=3):\n",
    "        \"\"\"min_keep overrides n if they conflict.\"\"\"\n",
    "        if listlike(text):\n",
    "            return [self._preprocess(row, n, min_keep) for row in text]\n",
    "        \n",
    "        tokens = text.split()\n",
    "        idx = np.random.choice(range(len(tokens)), \n",
    "                               min(len(tokens)-min_keep, n),\n",
    "                               replace=False)\n",
    "        return ' '.join(t if i not in idx else MASK \n",
    "                        for i, t in enumerate(tokens))\n",
    "    \n",
    "    def __call__(self, text, n=1, min_keep=3, return_all=False):\n",
    "        # Each item will be a list of strings. Each string in res[i]\n",
    "        # will have i words changed. If text is a sequence of strings, we must\n",
    "        # handle each one separately because each is passed through pipeline\n",
    "        # repeatedly.\n",
    "        if listlike(text):\n",
    "            return [self(row, n, min_keep, return_all) for row in text]\n",
    "        \n",
    "        res = [[text]]\n",
    "        for i in range(n):\n",
    "            text = [enc['sequence'].replace('<s>', '').replace('</s>', '')\n",
    "                    for row in res[-1] for enc in \n",
    "                    self.pipe(self._preprocess(row, min_keep=min_keep))]\n",
    "            res.append(text)\n",
    "        if not return_all: res = res[n]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:03.252475Z",
     "start_time": "2020-11-05T06:54:03.244645Z"
    }
   },
   "outputs": [],
   "source": [
    "MASK = '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:03.526458Z",
     "start_time": "2020-11-05T06:54:03.523612Z"
    }
   },
   "outputs": [],
   "source": [
    "t = 'I went to the store today to buy eggs.'\n",
    "ts = [t, 'The bird swooped down onto the picnic table and squawked loudly.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:04.073931Z",
     "start_time": "2020-11-05T06:54:04.069682Z"
    }
   },
   "outputs": [],
   "source": [
    "# m_pipe = pipeline('fill-mask')\n",
    "masker = FillMaskTransform(m_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:04.396271Z",
     "start_time": "2020-11-05T06:54:04.386804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went <mask> the store today to buy eggs.'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker._preprocess(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:05.034055Z",
     "start_time": "2020-11-05T06:54:05.027669Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to <mask> eggs.',\n",
       " 'The bird swooped down onto <mask> picnic table and squawked loudly.']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker._preprocess(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:54:20.712022Z",
     "start_time": "2020-11-05T06:54:20.704344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I <mask> to <mask> store today <mask> buy eggs.',\n",
       " 'The bird swooped down onto <mask> picnic table and <mask> <mask>']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker._preprocess(ts, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:31.697963Z",
     "start_time": "2020-11-05T06:55:31.603219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy eggs.',\n",
       " 'We went to the store today to buy eggs.',\n",
       " 'She went to the store today to buy eggs.',\n",
       " 'He went to the store today to buy eggs.',\n",
       " 'Someone went to the store today to buy eggs.']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:34.737806Z",
     "start_time": "2020-11-05T06:55:34.421241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy eggs.',\n",
       " 'I headed to the store today to buy eggs.',\n",
       " 'I drove to the store today to buy eggs.',\n",
       " 'I came to the store today to buy eggs.',\n",
       " 'I head to the store today to buy eggs.',\n",
       " 'I went to the store today to purchase...',\n",
       " 'I went to the store today to purchase.',\n",
       " 'I went to the store today to purchase:',\n",
       " 'I went to the store today to purchase…',\n",
       " 'I went to the store today to purchase....',\n",
       " 'I went to the store today to get eggs.',\n",
       " 'I went to the store today and get eggs.',\n",
       " 'I went to the store today & get eggs.',\n",
       " 'I went to the store today I get eggs.',\n",
       " 'I went to the store today, get eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I drove to the store today to collect eggs.',\n",
       " 'I headed to the store today to collect eggs.',\n",
       " 'I returned to the store today to collect eggs.',\n",
       " 'I came to the store today to collect eggs.',\n",
       " 'I went to the store today to buy eggs.',\n",
       " 'I went to the store today to purchase eggs.',\n",
       " 'I went to the store today to get eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I went to the store today to grab eggs.']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:37.521356Z",
     "start_time": "2020-11-05T06:55:37.440263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'I went to the store today to purchase eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to the store today to collect eggs.',\n",
       "  'I went to the store today to grab eggs.']]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t, 1, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:39.808162Z",
     "start_time": "2020-11-05T06:55:39.634028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the supermarket today to buy eggs.',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'I went to the grocery today to buy eggs.',\n",
       "  'I went to the mall today to buy eggs.',\n",
       "  'I went to the butcher today to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped up onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped overhead onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped gently onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped softly onto the picnic table and squawked loudly.']]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:55:43.920883Z",
     "start_time": "2020-11-05T06:55:43.279572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store yesterday to buy eggs.',\n",
       "  'I went to the store intending to buy eggs.',\n",
       "  'I went to the store wanting to buy eggs.',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'I went to the store expecting to buy eggs.',\n",
       "  'I went to the store today to purchase eggs.',\n",
       "  'We went to the store today to purchase eggs.',\n",
       "  'She went to the store today to purchase eggs.',\n",
       "  'Someone went to the store today to purchase eggs.',\n",
       "  'He went to the store today to purchase eggs.',\n",
       "  'I went to the store yesterday to get eggs.',\n",
       "  'I went to the store wanting to get eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to the store intending to get eggs.',\n",
       "  'I went to the store expecting to get eggs.',\n",
       "  'I went to grocery store today to collect eggs.',\n",
       "  'I went to the store today to collect eggs.',\n",
       "  'I went to my store today to collect eggs.',\n",
       "  'I went to a store today to collect eggs.',\n",
       "  'I went to another store today to collect eggs.',\n",
       "  'I went to the supermarket today to grab eggs.',\n",
       "  'I went to the store today to grab eggs.',\n",
       "  'I went to the bakery today to grab eggs.',\n",
       "  'I went to the grocery today to grab eggs.',\n",
       "  'I went to the mall today to grab eggs.'],\n",
       " ['The bird swooped down onto the picnic table and sang.',\n",
       "  'The bird swooped down onto the picnic table and sang!',\n",
       "  'The bird swooped down onto the picnic table and sang loudly',\n",
       "  'The bird swooped down onto the picnic table and sang happily',\n",
       "  'The bird swooped down onto the picnic table and sang...',\n",
       "  'The bird swooped down onto the picnic table and cheered loudly.',\n",
       "  'The bird swooped overhead onto the picnic table and cheered loudly.',\n",
       "  'The bird swooped up onto the picnic table and cheered loudly.',\n",
       "  'The bird swooped gently onto the picnic table and cheered loudly.',\n",
       "  'The bird swooped right onto the picnic table and cheered loudly.',\n",
       "  'The bird swooped down onto a picnic table and cried loudly.',\n",
       "  'The bird swooped down onto the picnic table and cried loudly.',\n",
       "  'The bird swooped down onto another picnic table and cried loudly.',\n",
       "  'The bird swooped down onto his picnic table and cried loudly.',\n",
       "  'The bird swooped down onto her picnic table and cried loudly.',\n",
       "  'Another bird swooped down onto the picnic table and complained loudly.',\n",
       "  'The bird swooped down onto the picnic table and complained loudly.',\n",
       "  'A bird swooped down onto the picnic table and complained loudly.',\n",
       "  'This bird swooped down onto the picnic table and complained loudly.',\n",
       "  'One bird swooped down onto the picnic table and complained loudly.',\n",
       "  'The birds swooped down onto the picnic table and roared loudly.',\n",
       "  'The owl swooped down onto the picnic table and roared loudly.',\n",
       "  'The bird swooped down onto the picnic table and roared loudly.',\n",
       "  'The eagle swooped down onto the picnic table and roared loudly.',\n",
       "  'The chickens swooped down onto the picnic table and roared loudly.']]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(ts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:56:05.540366Z",
     "start_time": "2020-11-05T06:56:05.532676Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParaphraseTransform:\n",
    "    \"\"\"Not sure how useful this will really be but this basically just \n",
    "    wraps ParaphrasePipeline to share a more similar interface with the other\n",
    "    NLP transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or ParaphrasePipeline()\n",
    "        assert type(self.pipe).__name__ == 'ParaphrasePipeline'\n",
    "        \n",
    "    def _preprocess(self, text):\n",
    "        return text\n",
    "    \n",
    "    def __call__(self, text, n=1, **kwargs):\n",
    "        return self.pipe(text, n=n, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:19:00.163439Z",
     "start_time": "2020-11-04T02:19:00.158477Z"
    }
   },
   "outputs": [],
   "source": [
    "p_tfm = ParaphraseTransform(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:19:06.210920Z",
     "start_time": "2020-11-04T02:19:02.675108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The beach is crowded.',\n",
       " 'There is a lot of people on the beach.',\n",
       " 'There is a lot of people at the beach.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm('The beach is loud and crowded today.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:22:36.982196Z",
     "start_time": "2020-11-05T06:22:22.156295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to buy eggs.'], ['The bird swooped down onto the picnic table.']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:22:44.555755Z",
     "start_time": "2020-11-05T06:22:38.723246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to buy eggs.', 'I went to the store to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table.',\n",
       "  'The bird swooped down on the picnic table.']]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm(ts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:48:03.758403Z",
     "start_time": "2020-11-05T06:48:03.754099Z"
    }
   },
   "outputs": [],
   "source": [
    "def listlike(x):\n",
    "    \"\"\"Checks if an object is a list/tuple/set/array etc. Strings and\n",
    "    mappings (e.g. dicts) are not considered list-like.\n",
    "    \"\"\"\n",
    "    return isinstance(x, Iterable) and not isinstance(x, (str, Mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:47:50.367487Z",
     "start_time": "2020-11-05T06:47:50.357976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> False\n",
      "<class 'int'> False\n",
      "<class 'list'> True\n",
      "<class 'tuple'> True\n",
      "<class 'dict'> False\n",
      "<class 'set'> True\n",
      "<class 'list'> True\n",
      "<class 'list'> True\n",
      "<class 'tuple'> True\n",
      "<class 'dict'> False\n",
      "<class 'set'> True\n",
      "<class 'numpy.ndarray'> True\n"
     ]
    }
   ],
   "source": [
    "for obj in ('a', 6, [], (), {}, set(), [3, 4], ['a', 'b'], ('a',), {'a': 'b'},\n",
    "            {'a', 'b'}, np.arange(5)):\n",
    "    print(type(obj), listlike(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:24.493455Z",
     "start_time": "2020-11-05T06:58:24.482183Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenerativeTransform:\n",
    "    \n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('text-generation')\n",
    "        assert type(self.pipe).__name__ == 'TextGenerationPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, drop=None, drop_pct=None, rand_low=None, \n",
    "                    rand_high=None, min_keep=3, return_tuple=False):\n",
    "        \"\"\"Truncate text.\"\"\"\n",
    "        if listlike(text):\n",
    "            return [self._preprocess(row, drop, drop_pct, rand_low, rand_high,\n",
    "                                     min_keep, return_tuple) for row in text]\n",
    "        \n",
    "        tokens = text.split()\n",
    "        if len(tokens) <= min_keep:\n",
    "            n = 0\n",
    "        else:\n",
    "            # Default is to truncate the last 20% of the sequence.\n",
    "            if drop:\n",
    "                n = drop\n",
    "            elif drop_pct:\n",
    "                n = int(drop_pct * len(tokens))\n",
    "            elif rand_low is not None and rand_high is not None:\n",
    "                n = np.random.randint(rand_low, rand_high)\n",
    "            else:\n",
    "                n = int(np.ceil(.2 * len(tokens)))\n",
    "            n = np.clip(n, 0, len(tokens) - min_keep)\n",
    "            tokens = tokens[:-n]\n",
    "        truncated = ' '.join(tokens)\n",
    "        return (truncated, n) if return_tuple else truncated\n",
    "    \n",
    "    def __call__(self, text, n=1, min_length=3, max_length=8, \n",
    "                 **generate_kwargs):\n",
    "        if listlike(text):\n",
    "            return [self(row, n, min_length, max_length, **generate_kwargs) \n",
    "                    for row in text]\n",
    "    \n",
    "        # generate counts current length as part of min_length. \n",
    "        # For now, we're just splitting words so I'm naively inflating n_curr \n",
    "        # a bit since pipeline does some form of sub-word tokenization.\n",
    "        text = self._preprocess(text)\n",
    "        n_curr = int(len(text.split()) * 1.1)\n",
    "        res = self.pipe(text, min_length=n_curr + min_length,\n",
    "                        max_length=n_curr + max_length,\n",
    "                        num_return_sequences=n, **generate_kwargs)\n",
    "        return [row['generated_text'] for row in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:25.488170Z",
     "start_time": "2020-11-05T06:58:25.483990Z"
    }
   },
   "outputs": [],
   "source": [
    "# g_pipe = pipeline('text-generation')\n",
    "g_tfm = GenerativeTransform(g_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:35.387713Z",
     "start_time": "2020-11-05T06:58:35.381066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went to the store today to'"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm._preprocess(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:36.354587Z",
     "start_time": "2020-11-05T06:58:36.347150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I went to the store today to', 2),\n",
       " ('The bird swooped down onto the picnic table', 3)]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm._preprocess(ts, return_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:40.553093Z",
     "start_time": "2020-11-05T06:58:38.314634Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy my groceries. My son went and']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:44.553078Z",
     "start_time": "2020-11-05T06:58:43.664520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I went to the store today to ask to meet with the clerk I think',\n",
       " 'I went to the store today to sell them. It seemed like a well']"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(t, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:47.531687Z",
     "start_time": "2020-11-05T06:58:46.817755Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to pick up a couple of pieces, and'],\n",
       " ['The bird swooped down onto the picnic table on the third floor and took some']]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:58:53.893401Z",
     "start_time": "2020-11-05T06:58:52.940910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to pick up a pair of shoes with the',\n",
       "  'I went to the store today to get up because I heard there was some'],\n",
       " ['The bird swooped down onto the picnic table across from me before he could get',\n",
       "  'The bird swooped down onto the picnic table and made a short descent in a']]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(ts, n=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
