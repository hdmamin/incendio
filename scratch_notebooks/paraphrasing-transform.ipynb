{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "`# TODO: summary here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:04.698255Z",
     "start_time": "2020-11-04T01:56:04.680904Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:08.935620Z",
     "start_time": "2020-11-04T01:56:05.260884Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, \\\n",
    "    PegasusTokenizerFast, pipeline\n",
    "\n",
    "from htools import *\n",
    "from incendio.utils import DEVICE, gpu_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:28.431548Z",
     "start_time": "2020-11-04T01:56:28.422988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:38: UserWarning: Cuda not available.\n",
      "  if not torch.cuda.is_available(): warnings.warn('Cuda not available.')\n",
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:41: UserWarning: Incendio device is not cuda.\n",
      "  warnings.warn('Incendio device is not cuda.')\n"
     ]
    }
   ],
   "source": [
    "gpu_setup(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:08:35.518032Z",
     "start_time": "2020-11-03T05:00:40.657875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92da3ec470d4eb8be89512326ea21d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1142.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bd9a1afd3840b8aac70a9555e3ca4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275437102.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57de7fc53a3548e484a29750e08b7b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60954), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60955), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80664141cea4abcbf763e3ffd8d9086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3636536d7c81495baeb06f1e6d76919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=86.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:69: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/hmamin/.cache/torch/transformers/fa4532c0035b101d7abcd5c0c9c34a83288902b66c5616034db1a47643e05c75.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e'>\n",
      "  m.ParseFromString(open(filename, \"rb\").read())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "version = 'tuner007/pegasus_paraphrase'\n",
    "net = PegasusForConditionalGeneration.from_pretrained(version)\n",
    "tok = PegasusTokenizerFast.from_pretrained(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:23:58.588210Z",
     "start_time": "2020-11-03T05:23:58.575168Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:00.401253Z",
     "start_time": "2020-11-03T05:35:00.396827Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Educational games and digital learning materials to provide K-12 '\n",
    "    'students with enriching experiences.',\n",
    "    'The world\\'s largest social network. Helping people build and maintain '\n",
    "    'relationships in a disconnected world.',\n",
    "    'I hate school. I wish my teacher would leave me alone. I don\\'t think '\n",
    "    ' he likes me.',\n",
    "    'Today the president announced new plans to revamp the private '\n",
    "    'healthcare system. Pundits questioned how he would manage to pass the '\n",
    "    'bill.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:09:03.847681Z",
     "start_time": "2020-11-03T05:09:03.824049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SPECIAL_TOKENS_ATTRIBUTES': 'attribute',\n",
       " 'add_special_tokens': 'method',\n",
       " 'add_tokens': 'method',\n",
       " 'additional_special_tokens': 'attribute',\n",
       " 'additional_special_tokens_ids': 'attribute',\n",
       " 'all_special_ids': 'attribute',\n",
       " 'all_special_tokens': 'attribute',\n",
       " 'all_special_tokens_extended': 'attribute',\n",
       " 'backend_tokenizer': 'attribute',\n",
       " 'batch_decode': 'method',\n",
       " 'batch_encode_plus': 'method',\n",
       " 'bos_token': 'attribute',\n",
       " 'bos_token_id': 'attribute',\n",
       " 'build_inputs_with_special_tokens': 'method',\n",
       " 'clean_up_tokenization': 'method',\n",
       " 'cls_token': 'attribute',\n",
       " 'cls_token_id': 'attribute',\n",
       " 'convert_ids_to_tokens': 'method',\n",
       " 'convert_tokens_to_ids': 'method',\n",
       " 'create_token_type_ids_from_sequences': 'method',\n",
       " 'decode': 'method',\n",
       " 'deprecation_warnings': 'attribute',\n",
       " 'encode': 'method',\n",
       " 'encode_plus': 'method',\n",
       " 'eos_token': 'attribute',\n",
       " 'eos_token_id': 'attribute',\n",
       " 'from_pretrained': 'method',\n",
       " 'get_added_vocab': 'method',\n",
       " 'get_special_tokens_mask': 'method',\n",
       " 'get_vocab': 'method',\n",
       " 'init_inputs': 'attribute',\n",
       " 'init_kwargs': 'attribute',\n",
       " 'is_fast': 'attribute',\n",
       " 'mask_token': 'attribute',\n",
       " 'mask_token_id': 'attribute',\n",
       " 'max_len': 'attribute',\n",
       " 'max_len_sentences_pair': 'attribute',\n",
       " 'max_len_single_sentence': 'attribute',\n",
       " 'max_model_input_sizes': 'attribute',\n",
       " 'model_input_names': 'attribute',\n",
       " 'model_max_length': 'attribute',\n",
       " 'name_or_path': 'attribute',\n",
       " 'num_special_tokens_to_add': 'method',\n",
       " 'offset': 'attribute',\n",
       " 'pad': 'method',\n",
       " 'pad_token': 'attribute',\n",
       " 'pad_token_id': 'attribute',\n",
       " 'pad_token_type_id': 'attribute',\n",
       " 'padding_side': 'attribute',\n",
       " 'prepare_for_model': 'method',\n",
       " 'prepare_seq2seq_batch': 'method',\n",
       " 'pretrained_init_configuration': 'attribute',\n",
       " 'pretrained_vocab_files_map': 'attribute',\n",
       " 'sanitize_special_tokens': 'method',\n",
       " 'save_pretrained': 'method',\n",
       " 'save_vocabulary': 'method',\n",
       " 'sep_token': 'attribute',\n",
       " 'sep_token_id': 'attribute',\n",
       " 'set_truncation_and_padding': 'method',\n",
       " 'slow_tokenizer_class': 'method',\n",
       " 'special_tokens_map': 'attribute',\n",
       " 'special_tokens_map_extended': 'attribute',\n",
       " 'tokenize': 'method',\n",
       " 'truncate_sequences': 'method',\n",
       " 'unk_token': 'attribute',\n",
       " 'unk_token_id': 'attribute',\n",
       " 'verbose': 'attribute',\n",
       " 'vocab_file': 'attribute',\n",
       " 'vocab_files_names': 'attribute',\n",
       " 'vocab_size': 'attribute'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdir(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:06.682140Z",
     "start_time": "2020-11-03T05:11:06.638522Z"
    }
   },
   "outputs": [],
   "source": [
    "res = tok.prepare_seq2seq_batch(texts, truncation=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:08.427646Z",
     "start_time": "2020-11-03T05:11:08.403336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11263,   727,   111,  1016,   761,   917,   112,   319,  1046,  6054,\n",
       "           392,   122, 26838,  1747,   107,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  139,   278,   131,   116,  1368,   525,   952,   107, 22844,   200,\n",
       "           736,   111,  1634,  2074,   115,   114, 20402,   278,   107,     1,\n",
       "             0,     0,     0],\n",
       "        [  125,  4180,   399,   107,   125,  1216,   161,  2118,   192,   858,\n",
       "           213,  1600,   107,   125,   272,   131,   144,   311,   178,  5606,\n",
       "           213,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:13:07.112402Z",
     "start_time": "2020-11-03T05:12:49.471597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1046, 6054,  392,  137,  207, 2387,  727,  111, 1016,  761,  917,\n",
       "          107,    1,    0,    0,    0],\n",
       "        [   0,  139,  278,  131,  116, 1368,  525,  952,  107,    1,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [   0,  125,  272,  131,  144,  172,  399,  111,  161, 2118,  591,  131,\n",
       "          144,  172,  213,  107,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = net.generate(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:15:57.224563Z",
     "start_time": "2020-11-03T05:15:57.215548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K-12 students can use educational games and digital learning materials.',\n",
       " \"The world's largest social network.\",\n",
       " \"I don't like school and my teacher doesn't like me.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.batch_decode(gen.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:36:34.347485Z",
     "start_time": "2020-11-03T05:36:34.337003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "@add_docstring(net.generate)\n",
    "def paraphrase(text, n=1, temperature=1.5, **gen_kwargs):\n",
    "    batch = tok.prepare_seq2seq_batch([text], truncation=True, \n",
    "                                      padding='longest').to(DEVICE)\n",
    "    paraphrased = net.generate(**batch, num_return_sequences=n,\n",
    "                               temperature=temperature, **gen_kwargs)\n",
    "    return tok.batch_decode(paraphrased.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.051823Z",
     "start_time": "2020-11-03T05:35:21.489262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The president announced plans to reform the private healthcare system.',\n",
       " 'Pundits wondered how the president would pass the bill.',\n",
       " 'Pundits questioned how the president would pass the bill.',\n",
       " 'Pundits were questioning how the president would pass the bill.',\n",
       " 'Pundits questioned how he would get the bill passed.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase(texts[3], n=5, num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.113484Z",
     "start_time": "2020-11-03T05:35:36.066617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today the president announced new plans to revamp the private healthcare system. Pundits questioned how he would manage to pass the bill.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:31:10.784475Z",
     "start_time": "2020-11-03T05:31:10.771992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <Parameter \"input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_input_ids': <Parameter \"decoder_input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'max_length': <Parameter \"max_length: Union[int, NoneType] = None\">,\n",
       " 'min_length': <Parameter \"min_length: Union[int, NoneType] = None\">,\n",
       " 'do_sample': <Parameter \"do_sample: Union[bool, NoneType] = None\">,\n",
       " 'early_stopping': <Parameter \"early_stopping: Union[bool, NoneType] = None\">,\n",
       " 'num_beams': <Parameter \"num_beams: Union[int, NoneType] = None\">,\n",
       " 'temperature': <Parameter \"temperature: Union[float, NoneType] = None\">,\n",
       " 'top_k': <Parameter \"top_k: Union[int, NoneType] = None\">,\n",
       " 'top_p': <Parameter \"top_p: Union[float, NoneType] = None\">,\n",
       " 'repetition_penalty': <Parameter \"repetition_penalty: Union[float, NoneType] = None\">,\n",
       " 'bad_words_ids': <Parameter \"bad_words_ids: Union[Iterable[int], NoneType] = None\">,\n",
       " 'bos_token_id': <Parameter \"bos_token_id: Union[int, NoneType] = None\">,\n",
       " 'pad_token_id': <Parameter \"pad_token_id: Union[int, NoneType] = None\">,\n",
       " 'eos_token_id': <Parameter \"eos_token_id: Union[int, NoneType] = None\">,\n",
       " 'length_penalty': <Parameter \"length_penalty: Union[float, NoneType] = None\">,\n",
       " 'no_repeat_ngram_size': <Parameter \"no_repeat_ngram_size: Union[int, NoneType] = None\">,\n",
       " 'num_return_sequences': <Parameter \"num_return_sequences: Union[int, NoneType] = None\">,\n",
       " 'attention_mask': <Parameter \"attention_mask: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_start_token_id': <Parameter \"decoder_start_token_id: Union[int, NoneType] = None\">,\n",
       " 'use_cache': <Parameter \"use_cache: Union[bool, NoneType] = None\">,\n",
       " 'model_kwargs': <Parameter \"**model_kwargs\">}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:00.223761Z",
     "start_time": "2020-11-04T02:14:00.215949Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParaphrasePipeline:\n",
    "    \n",
    "    name = 'tuner007/pegasus_paraphrase'\n",
    "    \n",
    "    def __init__(self, net=None, tok=None):\n",
    "        self.net = net or PegasusForConditionalGeneration.from_pretrained(\n",
    "            self.name).to(DEVICE)\n",
    "        self.tok = tok or PegasusTokenizerFast.from_pretrained(self.name)\n",
    "        \n",
    "    @add_docstring(PegasusForConditionalGeneration.generate)\n",
    "    def __call__(self, text, n=1, temperature=1.5, **kwargs):\n",
    "        # TODO: not sure how many rows of text can be done in a single batch.\n",
    "        # Maybe look at other pipelines to see what they do. I'm thinking we\n",
    "        # could auto-batch longer sequences (e.g. a list w/ 10_000 strings\n",
    "        # might become 100 batches of 100).\n",
    "        texts = [text] if isinstance(text, str) else text\n",
    "        batch = self.tok.prepare_seq2seq_batch(texts, truncation=True, \n",
    "                                               padding='longest').to(DEVICE)\n",
    "        gen_tokens = self.net.generate(**batch, num_return_sequences=n,\n",
    "                                       temperature=temperature, **kwargs)\n",
    "        gen = self.tok.batch_decode(gen_tokens.tolist(), \n",
    "                                    skip_special_tokens=True)\n",
    "        if not isinstance(text, str) and len(text) > 1: \n",
    "            gen = [gen[i*n:(i+1)*n] for i in range(len(text))]\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:11:53.691189Z",
     "start_time": "2020-11-04T02:11:53.688274Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = ParaphrasePipeline(net, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:11:59.094586Z",
     "start_time": "2020-11-04T02:11:55.579388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('It was a beautiful rainy day.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:02.864510Z",
     "start_time": "2020-11-04T02:11:59.098781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.',\n",
       " 'It was a nice day.',\n",
       " 'It was raining but it was nice.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('It was a beautiful rainy day.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:06.328322Z",
     "start_time": "2020-11-04T02:12:02.868563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.'], ['The duck was fluffy and yellow.']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:09.898263Z",
     "start_time": "2020-11-04T02:12:06.330746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.',\n",
       "  'It was a nice day.',\n",
       "  'It was raining but it was nice.'],\n",
       " ['The duck was fluffy and yellow.',\n",
       "  'The duck was fluffy.',\n",
       "  'The duck was big and fluffy.']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'], \n",
    "     n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:12.933407Z",
     "start_time": "2020-11-04T02:12:09.901067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.', 'It was a nice day.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(['It was a beautiful rainy day.'], n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:58:59.740937Z",
     "start_time": "2020-11-03T05:58:59.734081Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerTransform:\n",
    "    \n",
    "    def __init__(self, mode, n=1):\n",
    "        self.mode = mode\n",
    "        self.n = n\n",
    "        self.predictor = self._get_transformer()\n",
    "        \n",
    "#     def __call__(self, text):\n",
    "#         self._preprocess(text)\n",
    "    \n",
    "#     @abstractmethod\n",
    "#     def _preprocess(self, text):\n",
    "#         pass\n",
    "    \n",
    "    def _get_transformer(self):\n",
    "        if self.mode == 'mask':\n",
    "            return pipeline('fill-mask')\n",
    "        elif self.mode == 'generate':\n",
    "            return pipeline('text-generation')\n",
    "        elif self.mode == 'paraphrase':\n",
    "            return ParaphrasePipeline()\n",
    "        else:\n",
    "            raise ValueError('mode must be in (mask, generate, paraphrase).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:16:30.094067Z",
     "start_time": "2020-11-04T02:16:30.083520Z"
    }
   },
   "outputs": [],
   "source": [
    "class FillMaskTransform:    \n",
    "    \n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('fill-mask')\n",
    "        assert type(self.pipe).__name__ == 'FillMaskPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, n=1, min_keep=3):\n",
    "        tokens = text.split()\n",
    "        idx = np.random.choice(range(len(tokens)), \n",
    "                               min(len(tokens)-min_keep, n),\n",
    "                               replace=False)\n",
    "        return ' '.join(t if i not in idx else MASK \n",
    "                        for i, t in enumerate(tokens))\n",
    "    \n",
    "    def __call__(self, text, n=1, return_all=False):\n",
    "        # Each item will be a list of strings. Each string in res[i]\n",
    "        # will have i words changed.\n",
    "        res = [[text]]\n",
    "        for i in range(n+1):\n",
    "            text = [enc['sequence'].replace('<s>', '').replace('</s>', '')\n",
    "                    for row in res[-1] for enc in \n",
    "                    self.pipe(self._preprocess(row))]\n",
    "            res.append(text)\n",
    "        if not return_all: res = res[n]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:50.622832Z",
     "start_time": "2020-11-04T02:14:50.618115Z"
    }
   },
   "outputs": [],
   "source": [
    "MASK = '<mask>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:50.807133Z",
     "start_time": "2020-11-04T02:14:50.799796Z"
    }
   },
   "outputs": [],
   "source": [
    "t = 'I went to the store today to buy eggs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:59.396010Z",
     "start_time": "2020-11-04T02:14:52.624695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "masker = FillMaskTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:15:08.863788Z",
     "start_time": "2020-11-04T02:15:08.823029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FillMaskPipeline'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(masker.pipe).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:12:36.565204Z",
     "start_time": "2020-11-03T06:12:36.109581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy eggs.',\n",
       " 'I headed to the store today to buy eggs.',\n",
       " 'I drove to the store today to buy eggs.',\n",
       " 'I came to the store today to buy eggs.',\n",
       " 'I head to the store today to buy eggs.']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:13:00.308030Z",
     "start_time": "2020-11-03T06:12:51.594449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy eggs.',\n",
       " 'I went to the store today and buy eggs.',\n",
       " 'I went to the store today & buy eggs.',\n",
       " 'I went to the store today I buy eggs.',\n",
       " 'I went to the store today, buy eggs.',\n",
       " 'I went to grocery store today to purchase eggs.',\n",
       " 'I went to the store today to purchase eggs.',\n",
       " 'I went to my store today to purchase eggs.',\n",
       " 'I went to a store today to purchase eggs.',\n",
       " 'I went to another store today to purchase eggs.',\n",
       " 'I went to the store today to buy eggs.',\n",
       " 'I went to the store today to purchase eggs.',\n",
       " 'I went to the store today to get eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I went to the store today to grab eggs.',\n",
       " 'I went to the store today to buy eggs.',\n",
       " 'I went to the store today to purchase eggs.',\n",
       " 'I went to the store today to get eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I went to the store today to grab eggs.',\n",
       " 'I went to the store today to grab groceries',\n",
       " 'I went to the store today to grab some',\n",
       " 'I went to the store today to grab snacks',\n",
       " 'I went to the store today to grab popcorn',\n",
       " 'I went to the store today to grab mine',\n",
       " 'I went to the supermarket yesterday to purchase eggs.',\n",
       " 'I went to the supermarket afterwards to purchase eggs.',\n",
       " 'I went to the supermarket today to purchase eggs.',\n",
       " 'I went to the supermarket instead to purchase eggs.',\n",
       " 'I went to the supermarket nearby to purchase eggs.',\n",
       " 'I went to grocery store today to purchase eggs.',\n",
       " 'I went to the store today to purchase eggs.',\n",
       " 'I went to my store today to purchase eggs.',\n",
       " 'I went to a store today to purchase eggs.',\n",
       " 'I went to another store today to purchase eggs.',\n",
       " 'I went to the butcher today to purchase.',\n",
       " 'I went to the butcher today to purchase...',\n",
       " 'I went to the butcher today to purchase!',\n",
       " 'I went to the butcher today to purchase bacon',\n",
       " 'I went to the butcher today to purchase mine',\n",
       " 'She went to the bakery today to purchase eggs.',\n",
       " 'I went to the bakery today to purchase eggs.',\n",
       " 'We went to the bakery today to purchase eggs.',\n",
       " 'People went to the bakery today to purchase eggs.',\n",
       " 'Someone went to the bakery today to purchase eggs.',\n",
       " 'I went to the grocery today to purchase...',\n",
       " 'I went to the grocery today to purchase groceries',\n",
       " 'I went to the grocery today to purchase.',\n",
       " 'I went to the grocery today to purchase:',\n",
       " 'I went to the grocery today to purchase....',\n",
       " 'I went to grocery store today to get eggs.',\n",
       " 'I went to the store today to get eggs.',\n",
       " 'I went to a store today to get eggs.',\n",
       " 'I went to my store today to get eggs.',\n",
       " 'I went to another store today to get eggs.',\n",
       " 'I drove to the store today to buy eggs.',\n",
       " 'I drove to the store today to purchase eggs.',\n",
       " 'I drove to the store today to get eggs.',\n",
       " 'I drove to the store today to grab eggs.',\n",
       " 'I drove to the store today to collect eggs.',\n",
       " 'I headed to the store today to get eggs.',\n",
       " 'I headed into the store today to get eggs.',\n",
       " 'I headed through the store today to get eggs.',\n",
       " 'I headed down the store today to get eggs.',\n",
       " 'I headed up the store today to get eggs.',\n",
       " 'I came into the store today to get eggs.',\n",
       " 'I came to the store today to get eggs.',\n",
       " 'I came in the store today to get eggs.',\n",
       " 'I came through the store today to get eggs.',\n",
       " 'I came across the store today to get eggs.',\n",
       " 'I ran into the store today to get eggs.',\n",
       " 'I ran to the store today to get eggs.',\n",
       " 'I ran through the store today to get eggs.',\n",
       " 'I ran around the store today to get eggs.',\n",
       " 'I ran across the store today to get eggs.',\n",
       " 'I went into the store today to collect groceries',\n",
       " 'I went into the store today to collect CDs',\n",
       " 'I went into the store today to collect...',\n",
       " 'I went into the store today to collect.',\n",
       " 'I went into the store today to collect some',\n",
       " 'I went into the store today to collect eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I went through the store today to collect eggs.',\n",
       " 'I went around the store today to collect eggs.',\n",
       " 'I went outside the store today to collect eggs.',\n",
       " 'I went through the store today to buy eggs.',\n",
       " 'I went through the store today to purchase eggs.',\n",
       " 'I went through the store today to get eggs.',\n",
       " 'I went through the store today to find eggs.',\n",
       " 'I went through the store today to collect eggs.',\n",
       " 'I went around the farm today to collect eggs.',\n",
       " 'I went around the zoo today to collect eggs.',\n",
       " 'I went around the house today to collect eggs.',\n",
       " 'I went around the bush today to collect eggs.',\n",
       " 'I went around the store today to collect eggs.',\n",
       " 'I went into the store today to collect eggs.',\n",
       " 'I went to the store today to collect eggs.',\n",
       " 'I went through the store today to collect eggs.',\n",
       " 'I went around the store today to collect eggs.',\n",
       " 'I went outside the store today to collect eggs.',\n",
       " 'I went to the store today to grab groceries',\n",
       " 'I went to the store today to grab some',\n",
       " 'I went to the store today to grab snacks',\n",
       " 'I went to the store today to grab popcorn',\n",
       " 'I went to the store today to grab mine',\n",
       " 'I went into the store today to grab some',\n",
       " 'I went to the store today to grab some',\n",
       " 'I went through the store today to grab some',\n",
       " 'I went around the store today to grab some',\n",
       " 'I went inside the store today to grab some',\n",
       " 'I went to the store today to grab snacks',\n",
       " 'Kids went to the store today to grab snacks',\n",
       " 'We went to the store today to grab snacks',\n",
       " 'People went to the store today to grab snacks',\n",
       " 'Everyone went to the store today to grab snacks',\n",
       " 'I went to the cinema today to grab popcorn',\n",
       " 'I went to the supermarket today to grab popcorn',\n",
       " 'I went to the movies today to grab popcorn',\n",
       " 'I went to the mall today to grab popcorn',\n",
       " 'I went to the gym today to grab popcorn',\n",
       " 'I went to the store today to buy mine',\n",
       " 'I went to the store today to refill mine',\n",
       " 'I went to the store today to borrow mine',\n",
       " 'I went to the store today to get mine',\n",
       " 'I went to the store today to purchase mine']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:14:21.580871Z",
     "start_time": "2020-11-03T06:14:19.276832Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'I went to the store today to purchase eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to the store today to collect eggs.',\n",
       "  'I went to the store today to grab eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'We went to the store today to buy eggs.',\n",
       "  'She went to the store today to buy eggs.',\n",
       "  'He went to the store today to buy eggs.',\n",
       "  'Someone went to the store today to buy eggs.',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'I went to the store today to purchase eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to the store today to collect eggs.',\n",
       "  'I went to the store today to grab eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went into the store today to get eggs.',\n",
       "  'I went through the store today to get eggs.',\n",
       "  'I went around the store today to get eggs.',\n",
       "  'I went in the store today to get eggs.',\n",
       "  'I went to the store today to collect groceries',\n",
       "  'I went to the store today to collect...',\n",
       "  'I went to the store today to collect mine',\n",
       "  'I went to the store today to collect some',\n",
       "  'I went to the store today to collect.',\n",
       "  'I went to the store today to grab eggs.',\n",
       "  'I went to the store today and grab eggs.',\n",
       "  'I went to the store today & grab eggs.',\n",
       "  'I went to the store today, grab eggs.',\n",
       "  'I went to the store today or grab eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'I headed to the store today to buy eggs.',\n",
       "  'I drove to the store today to buy eggs.',\n",
       "  'I came to the store today to buy eggs.',\n",
       "  'I head to the store today to buy eggs.',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'We went to the store today to buy eggs.',\n",
       "  'She went to the store today to buy eggs.',\n",
       "  'He went to the store today to buy eggs.',\n",
       "  'Someone went to the store today to buy eggs.',\n",
       "  'She went to the store today to buy eggs.',\n",
       "  'She heads to the store today to buy eggs.',\n",
       "  'She headed to the store today to buy eggs.',\n",
       "  'She drove to the store today to buy eggs.',\n",
       "  'She goes to the store today to buy eggs.',\n",
       "  'He went to the store intending to buy eggs.',\n",
       "  'He went to the store wanting to buy eggs.',\n",
       "  'He went to the store yesterday to buy eggs.',\n",
       "  'He went to the store instead to buy eggs.',\n",
       "  'He went to the store hoping to buy eggs.',\n",
       "  'Someone went to the store today to buy pizza',\n",
       "  'Someone went to the store today to buy popcorn',\n",
       "  'Someone went to the store today to buy groceries',\n",
       "  'Someone went to the store today to buy...',\n",
       "  'Someone went to the store today to buy coffee',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'I went into the store today to buy eggs.',\n",
       "  'I went through the store today to buy eggs.',\n",
       "  'I went around the store today to buy eggs.',\n",
       "  'I went in the store today to buy eggs.',\n",
       "  'I went to the store today to purchase eggs.',\n",
       "  'We went to the store today to purchase eggs.',\n",
       "  'She went to the store today to purchase eggs.',\n",
       "  'Someone went to the store today to purchase eggs.',\n",
       "  'He went to the store today to purchase eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to the store today and get eggs.',\n",
       "  'I went to the store today & get eggs.',\n",
       "  'I went to the store today I get eggs.',\n",
       "  'I went to the store today, get eggs.',\n",
       "  'We went to the store today to collect eggs.',\n",
       "  'Someone went to the store today to collect eggs.',\n",
       "  'I went to the store today to collect eggs.',\n",
       "  'She went to the store today to collect eggs.',\n",
       "  'They went to the store today to collect eggs.',\n",
       "  'I went to the store today to grab eggs.',\n",
       "  'I went to the store today and grab eggs.',\n",
       "  'I went to the store today & grab eggs.',\n",
       "  'I went to the store today, grab eggs.',\n",
       "  'I went to the store today or grab eggs.',\n",
       "  'I went to grocery store today to get eggs.',\n",
       "  'I went to the store today to get eggs.',\n",
       "  'I went to a store today to get eggs.',\n",
       "  'I went to my store today to get eggs.',\n",
       "  'I went to another store today to get eggs.',\n",
       "  'I went into the store today to get groceries',\n",
       "  'I went into the store today to get some',\n",
       "  'I went into the store today to get coffee',\n",
       "  'I went into the store today to get supplies',\n",
       "  'I went into the store today to get mine',\n",
       "  'I went through the store today to buy eggs.',\n",
       "  'I went through the store today to purchase eggs.',\n",
       "  'I went through the store today to get eggs.',\n",
       "  'I went through the store today to find eggs.',\n",
       "  'I went through the store today to collect eggs.',\n",
       "  'I went around the store today to get eggs.',\n",
       "  'I went around the store today and get eggs.',\n",
       "  'I went around the store today trying get eggs.',\n",
       "  'I went around the store today helping get eggs.',\n",
       "  'I went around the store today & get eggs.',\n",
       "  'I went in the store today to get groceries',\n",
       "  'I went in the store today to get some',\n",
       "  'I went in the store today to get coffee',\n",
       "  'I went in the store today to get lunch',\n",
       "  'I went in the store today to get mine',\n",
       "  'I went to the store today to collect groceries',\n",
       "  'I went to the store today to collect...',\n",
       "  'I went to the store today to collect mine',\n",
       "  'I went to the store today to collect some',\n",
       "  'I went to the store today to collect.',\n",
       "  'I went to my store today to collect...',\n",
       "  'I went to grocery store today to collect...',\n",
       "  'I went to the store today to collect...',\n",
       "  'I went to a store today to collect...',\n",
       "  'I went to another store today to collect...',\n",
       "  'I went to the store today to collect mine',\n",
       "  'I went to the store today and collect mine',\n",
       "  'I went to the store today & collect mine',\n",
       "  'I went to the store today I collect mine',\n",
       "  'I went to the store today or collect mine',\n",
       "  'I went to the store today to buy some',\n",
       "  'I went to the store today to grab some',\n",
       "  'I went to the store today to get some',\n",
       "  'I went to the store today to purchase some',\n",
       "  'I went to the store today to order some',\n",
       "  'I went to the store today to collect.',\n",
       "  'I headed to the store today to collect.',\n",
       "  'I drove to the store today to collect.',\n",
       "  'I returned to the store today to collect.',\n",
       "  'I came to the store today to collect.',\n",
       "  'I went to the store today to grab eggs.',\n",
       "  'I headed to the store today to grab eggs.',\n",
       "  'I drove to the store today to grab eggs.',\n",
       "  'I came to the store today to grab eggs.',\n",
       "  'I rushed to the store today to grab eggs.',\n",
       "  'I went to grocery store today and grab eggs.',\n",
       "  'I went to the store today and grab eggs.',\n",
       "  'I went to my store today and grab eggs.',\n",
       "  'I went to a store today and grab eggs.',\n",
       "  'I went to another store today and grab eggs.',\n",
       "  'I head to the store today & grab eggs.',\n",
       "  'I go to the store today & grab eggs.',\n",
       "  'I went to the store today & grab eggs.',\n",
       "  'I headed to the store today & grab eggs.',\n",
       "  'I drive to the store today & grab eggs.',\n",
       "  'I went to the store today, grab mine',\n",
       "  'I went to the store today, grab popcorn',\n",
       "  'I went to the store today, grab groceries',\n",
       "  'I went to the store today, grab...',\n",
       "  'I went to the store today, grab some',\n",
       "  'I went to the store today or grab mine',\n",
       "  'I went to the store today or grab one',\n",
       "  'I went to the store today or grab lunch',\n",
       "  'I went to the store today or grab groceries',\n",
       "  'I went to the store today or grab some']]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t, 2, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:14:35.656167Z",
     "start_time": "2020-11-03T06:14:35.121841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to grocery store today to buy eggs.',\n",
       " 'I went to the store today to buy eggs.',\n",
       " 'I went to my store today to buy eggs.',\n",
       " 'I went to a store today to buy eggs.',\n",
       " 'I went to another store today to buy eggs.']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T06:15:39.153027Z",
     "start_time": "2020-11-03T06:15:39.006250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '<s>I went to work after school.</s>',\n",
       "  'score': 0.21024835109710693,\n",
       "  'token': 334,\n",
       "  'token_str': 'Ġschool'},\n",
       " {'sequence': '<s>I went to work after graduation.</s>',\n",
       "  'score': 0.10130680352449417,\n",
       "  'token': 11412,\n",
       "  'token_str': 'Ġgraduation'},\n",
       " {'sequence': '<s>I went to work after lunch.</s>',\n",
       "  'score': 0.09977195411920547,\n",
       "  'token': 4592,\n",
       "  'token_str': 'Ġlunch'},\n",
       " {'sequence': '<s>I went to work after midnight.</s>',\n",
       "  'score': 0.06013602390885353,\n",
       "  'token': 5832,\n",
       "  'token_str': 'Ġmidnight'},\n",
       " {'sequence': '<s>I went to work after dinner.</s>',\n",
       "  'score': 0.04950949549674988,\n",
       "  'token': 3630,\n",
       "  'token_str': 'Ġdinner'}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker.pipe('I went to work after <mask>.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:35:07.468456Z",
     "start_time": "2020-11-04T01:35:07.330477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'sequence': '<s>I am happy because tomorrow is tomorrow.</s>',\n",
       "   'score': 0.6882706880569458,\n",
       "   'token': 3859,\n",
       "   'token_str': 'Ġtomorrow'},\n",
       "  {'sequence': '<s>I am happy because today is tomorrow.</s>',\n",
       "   'score': 0.06922067701816559,\n",
       "   'token': 452,\n",
       "   'token_str': 'Ġtoday'},\n",
       "  {'sequence': '<s>I am happy because tonight is tomorrow.</s>',\n",
       "   'score': 0.05604426562786102,\n",
       "   'token': 3422,\n",
       "   'token_str': 'Ġtonight'},\n",
       "  {'sequence': '<s>I am happy because it is tomorrow.</s>',\n",
       "   'score': 0.032564278692007065,\n",
       "   'token': 24,\n",
       "   'token_str': 'Ġit'},\n",
       "  {'sequence': '<s>I am happy because this is tomorrow.</s>',\n",
       "   'score': 0.019241180270910263,\n",
       "   'token': 42,\n",
       "   'token_str': 'Ġthis'}],\n",
       " [{'sequence': '<s>It is rainy and cold at the moment.</s>',\n",
       "   'score': 0.19970344007015228,\n",
       "   'token': 2569,\n",
       "   'token_str': 'Ġcold'},\n",
       "  {'sequence': '<s>It is rainy and cloudy at the moment.</s>',\n",
       "   'score': 0.16377227008342743,\n",
       "   'token': 2779,\n",
       "   'token_str': 'Ġcloudy'},\n",
       "  {'sequence': '<s>It is rainy and humid at the moment.</s>',\n",
       "   'score': 0.10497710853815079,\n",
       "   'token': 27280,\n",
       "   'token_str': 'Ġhumid'},\n",
       "  {'sequence': '<s>It is rainy and dark at the moment.</s>',\n",
       "   'score': 0.05757330730557442,\n",
       "   'token': 2933,\n",
       "   'token_str': 'Ġdark'},\n",
       "  {'sequence': '<s>It is rainy and dry at the moment.</s>',\n",
       "   'score': 0.03605516254901886,\n",
       "   'token': 3841,\n",
       "   'token_str': 'Ġdry'}]]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masker.pipe(['I am happy because <mask> is tomorrow.',\n",
    "             'It is rainy and <mask> at the moment.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:18:59.862909Z",
     "start_time": "2020-11-04T02:18:59.855197Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParaphraseTransform:\n",
    "\n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or ParaphrasePipeline()\n",
    "        assert type(self.pipe).__name__ == 'ParaphrasePipeline'\n",
    "        \n",
    "    def _preprocess(self, text):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, text, n=1, **kwargs):\n",
    "        return self.pipe(text, n=n, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:19:00.163439Z",
     "start_time": "2020-11-04T02:19:00.158477Z"
    }
   },
   "outputs": [],
   "source": [
    "p_tfm = ParaphraseTransform(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:19:06.210920Z",
     "start_time": "2020-11-04T02:19:02.675108Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The beach is crowded.',\n",
       " 'There is a lot of people on the beach.',\n",
       " 'There is a lot of people at the beach.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm('The beach is loud and crowded today.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:29:53.941329Z",
     "start_time": "2020-11-04T02:29:53.925731Z"
    }
   },
   "outputs": [],
   "source": [
    "class GenerativeTransform:\n",
    "    \n",
    "    def __init__(self, pipe=None):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('text-generation')\n",
    "        assert type(self.pipe).__name__ == 'TextGenerationPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, drop=None, drop_pct=None, rand_low=None, \n",
    "                    rand_high=None, min_keep=3, return_tuple=False):\n",
    "        \"\"\"Truncate text.\"\"\"\n",
    "        tokens = text.split()\n",
    "        if len(tokens) <= min_keep:\n",
    "            n = 0\n",
    "        else:\n",
    "            if drop:\n",
    "                n = drop\n",
    "            elif drop_pct:\n",
    "                n = int(drop_pct * len(tokens))\n",
    "            elif rand_low is not None and rand_high is not None:\n",
    "                n = np.random.randint(rand_low, rand_high)\n",
    "            else:\n",
    "                n = int(np.ceil(.1 * len(tokens)))\n",
    "            n = np.clip(n, 0, len(tokens) - min_keep)\n",
    "            tokens = tokens[:-n]\n",
    "        truncated = ' '.join(tokens)\n",
    "        return (truncated, n) if return_tuple else truncated\n",
    "    \n",
    "    def __call__(self, text, min_length=5, max_length=15, **generate_kwargs):\n",
    "        # generate counts current length as part of min_length. For now, we're just splitting words\n",
    "        # so I'm naively inflating n_curr a bit since pipeline does some form of sub-word tokenization.\n",
    "        text = self._preprocess(text)\n",
    "        print(text)\n",
    "        n_curr = int(len(text.split()) * 1.1)\n",
    "        return self.pipe(text, min_length=n_curr + min_length,\n",
    "                         max_length=n_curr + max_length, **generate_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:29:54.537897Z",
     "start_time": "2020-11-04T02:29:54.533154Z"
    }
   },
   "outputs": [],
   "source": [
    "# g_pipe = pipeline('text-generation')\n",
    "g_tfm = GenerativeTransform(g_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:29:56.057617Z",
     "start_time": "2020-11-04T02:29:56.043860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I went to the store today to buy', 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm._preprocess(t, return_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:29:57.413892Z",
     "start_time": "2020-11-04T02:29:56.737991Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the store today to buy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I went to the store today to buy a drink. On my way back, the doors closed and I was stuck'}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
