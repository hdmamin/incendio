{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "`# TODO: summary here`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:04.698255Z",
     "start_time": "2020-11-04T01:56:04.680904Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:45:14.851849Z",
     "start_time": "2020-11-05T06:45:14.831536Z"
    }
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from collections.abc import Iterable, Mapping\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer, \\\n",
    "    PegasusTokenizerFast, pipeline\n",
    "\n",
    "from htools import *\n",
    "from incendio.utils import DEVICE, gpu_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T01:56:28.431548Z",
     "start_time": "2020-11-04T01:56:28.422988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:38: UserWarning: Cuda not available.\n",
      "  if not torch.cuda.is_available(): warnings.warn('Cuda not available.')\n",
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/incendio/utils.py:41: UserWarning: Incendio device is not cuda.\n",
      "  warnings.warn('Incendio device is not cuda.')\n"
     ]
    }
   ],
   "source": [
    "gpu_setup(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:08:35.518032Z",
     "start_time": "2020-11-03T05:00:40.657875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92da3ec470d4eb8be89512326ea21d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1142.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bd9a1afd3840b8aac70a9555e3ca4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275437102.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57de7fc53a3548e484a29750e08b7b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60954), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/Users/hmamin/anaconda3/lib/python3.7/socket.py:660: ResourceWarning: unclosed <socket.socket fd=68, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('192.168.1.119', 60955), raddr=('52.216.233.221', 443)>\n",
      "  self._sock = None\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80664141cea4abcbf763e3ffd8d9086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3636536d7c81495baeb06f1e6d76919d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=86.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:69: ResourceWarning: unclosed file <_io.BufferedReader name='/Users/hmamin/.cache/torch/transformers/fa4532c0035b101d7abcd5c0c9c34a83288902b66c5616034db1a47643e05c75.efce77b8dcd2c57b109b0d10170fcdcd53f23c21286974d4f66706536758ab6e'>\n",
      "  m.ParseFromString(open(filename, \"rb\").read())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "version = 'tuner007/pegasus_paraphrase'\n",
    "net = PegasusForConditionalGeneration.from_pretrained(version)\n",
    "tok = PegasusTokenizerFast.from_pretrained(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:23:58.588210Z",
     "start_time": "2020-11-03T05:23:58.575168Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:00.401253Z",
     "start_time": "2020-11-03T05:35:00.396827Z"
    }
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    'Educational games and digital learning materials to provide K-12 '\n",
    "    'students with enriching experiences.',\n",
    "    'The world\\'s largest social network. Helping people build and maintain '\n",
    "    'relationships in a disconnected world.',\n",
    "    'I hate school. I wish my teacher would leave me alone. I don\\'t think '\n",
    "    ' he likes me.',\n",
    "    'Today the president announced new plans to revamp the private '\n",
    "    'healthcare system. Pundits questioned how he would manage to pass the '\n",
    "    'bill.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:09:03.847681Z",
     "start_time": "2020-11-03T05:09:03.824049Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bos_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "Using sep_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'SPECIAL_TOKENS_ATTRIBUTES': 'attribute',\n",
       " 'add_special_tokens': 'method',\n",
       " 'add_tokens': 'method',\n",
       " 'additional_special_tokens': 'attribute',\n",
       " 'additional_special_tokens_ids': 'attribute',\n",
       " 'all_special_ids': 'attribute',\n",
       " 'all_special_tokens': 'attribute',\n",
       " 'all_special_tokens_extended': 'attribute',\n",
       " 'backend_tokenizer': 'attribute',\n",
       " 'batch_decode': 'method',\n",
       " 'batch_encode_plus': 'method',\n",
       " 'bos_token': 'attribute',\n",
       " 'bos_token_id': 'attribute',\n",
       " 'build_inputs_with_special_tokens': 'method',\n",
       " 'clean_up_tokenization': 'method',\n",
       " 'cls_token': 'attribute',\n",
       " 'cls_token_id': 'attribute',\n",
       " 'convert_ids_to_tokens': 'method',\n",
       " 'convert_tokens_to_ids': 'method',\n",
       " 'create_token_type_ids_from_sequences': 'method',\n",
       " 'decode': 'method',\n",
       " 'deprecation_warnings': 'attribute',\n",
       " 'encode': 'method',\n",
       " 'encode_plus': 'method',\n",
       " 'eos_token': 'attribute',\n",
       " 'eos_token_id': 'attribute',\n",
       " 'from_pretrained': 'method',\n",
       " 'get_added_vocab': 'method',\n",
       " 'get_special_tokens_mask': 'method',\n",
       " 'get_vocab': 'method',\n",
       " 'init_inputs': 'attribute',\n",
       " 'init_kwargs': 'attribute',\n",
       " 'is_fast': 'attribute',\n",
       " 'mask_token': 'attribute',\n",
       " 'mask_token_id': 'attribute',\n",
       " 'max_len': 'attribute',\n",
       " 'max_len_sentences_pair': 'attribute',\n",
       " 'max_len_single_sentence': 'attribute',\n",
       " 'max_model_input_sizes': 'attribute',\n",
       " 'model_input_names': 'attribute',\n",
       " 'model_max_length': 'attribute',\n",
       " 'name_or_path': 'attribute',\n",
       " 'num_special_tokens_to_add': 'method',\n",
       " 'offset': 'attribute',\n",
       " 'pad': 'method',\n",
       " 'pad_token': 'attribute',\n",
       " 'pad_token_id': 'attribute',\n",
       " 'pad_token_type_id': 'attribute',\n",
       " 'padding_side': 'attribute',\n",
       " 'prepare_for_model': 'method',\n",
       " 'prepare_seq2seq_batch': 'method',\n",
       " 'pretrained_init_configuration': 'attribute',\n",
       " 'pretrained_vocab_files_map': 'attribute',\n",
       " 'sanitize_special_tokens': 'method',\n",
       " 'save_pretrained': 'method',\n",
       " 'save_vocabulary': 'method',\n",
       " 'sep_token': 'attribute',\n",
       " 'sep_token_id': 'attribute',\n",
       " 'set_truncation_and_padding': 'method',\n",
       " 'slow_tokenizer_class': 'method',\n",
       " 'special_tokens_map': 'attribute',\n",
       " 'special_tokens_map_extended': 'attribute',\n",
       " 'tokenize': 'method',\n",
       " 'truncate_sequences': 'method',\n",
       " 'unk_token': 'attribute',\n",
       " 'unk_token_id': 'attribute',\n",
       " 'verbose': 'attribute',\n",
       " 'vocab_file': 'attribute',\n",
       " 'vocab_files_names': 'attribute',\n",
       " 'vocab_size': 'attribute'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdir(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:06.682140Z",
     "start_time": "2020-11-03T05:11:06.638522Z"
    }
   },
   "outputs": [],
   "source": [
    "res = tok.prepare_seq2seq_batch(texts, truncation=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:11:08.427646Z",
     "start_time": "2020-11-03T05:11:08.403336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[11263,   727,   111,  1016,   761,   917,   112,   319,  1046,  6054,\n",
       "           392,   122, 26838,  1747,   107,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  139,   278,   131,   116,  1368,   525,   952,   107, 22844,   200,\n",
       "           736,   111,  1634,  2074,   115,   114, 20402,   278,   107,     1,\n",
       "             0,     0,     0],\n",
       "        [  125,  4180,   399,   107,   125,  1216,   161,  2118,   192,   858,\n",
       "           213,  1600,   107,   125,   272,   131,   144,   311,   178,  5606,\n",
       "           213,   107,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:13:07.112402Z",
     "start_time": "2020-11-03T05:12:49.471597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 1046, 6054,  392,  137,  207, 2387,  727,  111, 1016,  761,  917,\n",
       "          107,    1,    0,    0,    0],\n",
       "        [   0,  139,  278,  131,  116, 1368,  525,  952,  107,    1,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [   0,  125,  272,  131,  144,  172,  399,  111,  161, 2118,  591,  131,\n",
       "          144,  172,  213,  107,    1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = net.generate(**res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:15:57.224563Z",
     "start_time": "2020-11-03T05:15:57.215548Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K-12 students can use educational games and digital learning materials.',\n",
       " \"The world's largest social network.\",\n",
       " \"I don't like school and my teacher doesn't like me.\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.batch_decode(gen.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:36:34.347485Z",
     "start_time": "2020-11-03T05:36:34.337003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "@add_docstring(net.generate)\n",
    "def paraphrase(text, n=1, temperature=1.5, **gen_kwargs):\n",
    "    batch = tok.prepare_seq2seq_batch([text], truncation=True, \n",
    "                                      padding='longest').to(DEVICE)\n",
    "    paraphrased = net.generate(**batch, num_return_sequences=n,\n",
    "                               temperature=temperature, **gen_kwargs)\n",
    "    return tok.batch_decode(paraphrased.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.051823Z",
     "start_time": "2020-11-03T05:35:21.489262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The president announced plans to reform the private healthcare system.',\n",
       " 'Pundits wondered how the president would pass the bill.',\n",
       " 'Pundits questioned how the president would pass the bill.',\n",
       " 'Pundits were questioning how the president would pass the bill.',\n",
       " 'Pundits questioned how he would get the bill passed.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrase(texts[3], n=5, num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:35:36.113484Z",
     "start_time": "2020-11-03T05:35:36.066617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today the president announced new plans to revamp the private healthcare system. Pundits questioned how he would manage to pass the bill.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-03T05:31:10.784475Z",
     "start_time": "2020-11-03T05:31:10.771992Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <Parameter \"input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_input_ids': <Parameter \"decoder_input_ids: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'max_length': <Parameter \"max_length: Union[int, NoneType] = None\">,\n",
       " 'min_length': <Parameter \"min_length: Union[int, NoneType] = None\">,\n",
       " 'do_sample': <Parameter \"do_sample: Union[bool, NoneType] = None\">,\n",
       " 'early_stopping': <Parameter \"early_stopping: Union[bool, NoneType] = None\">,\n",
       " 'num_beams': <Parameter \"num_beams: Union[int, NoneType] = None\">,\n",
       " 'temperature': <Parameter \"temperature: Union[float, NoneType] = None\">,\n",
       " 'top_k': <Parameter \"top_k: Union[int, NoneType] = None\">,\n",
       " 'top_p': <Parameter \"top_p: Union[float, NoneType] = None\">,\n",
       " 'repetition_penalty': <Parameter \"repetition_penalty: Union[float, NoneType] = None\">,\n",
       " 'bad_words_ids': <Parameter \"bad_words_ids: Union[Iterable[int], NoneType] = None\">,\n",
       " 'bos_token_id': <Parameter \"bos_token_id: Union[int, NoneType] = None\">,\n",
       " 'pad_token_id': <Parameter \"pad_token_id: Union[int, NoneType] = None\">,\n",
       " 'eos_token_id': <Parameter \"eos_token_id: Union[int, NoneType] = None\">,\n",
       " 'length_penalty': <Parameter \"length_penalty: Union[float, NoneType] = None\">,\n",
       " 'no_repeat_ngram_size': <Parameter \"no_repeat_ngram_size: Union[int, NoneType] = None\">,\n",
       " 'num_return_sequences': <Parameter \"num_return_sequences: Union[int, NoneType] = None\">,\n",
       " 'attention_mask': <Parameter \"attention_mask: Union[torch.LongTensor, NoneType] = None\">,\n",
       " 'decoder_start_token_id': <Parameter \"decoder_start_token_id: Union[int, NoneType] = None\">,\n",
       " 'use_cache': <Parameter \"use_cache: Union[bool, NoneType] = None\">,\n",
       " 'model_kwargs': <Parameter \"**model_kwargs\">}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:14:00.223761Z",
     "start_time": "2020-11-04T02:14:00.215949Z"
    }
   },
   "outputs": [],
   "source": [
    "class ParaphrasePipeline:\n",
    "    \n",
    "    name = 'tuner007/pegasus_paraphrase'\n",
    "    \n",
    "    def __init__(self, net=None, tok=None):\n",
    "        self.net = net or PegasusForConditionalGeneration.from_pretrained(\n",
    "            self.name).to(DEVICE)\n",
    "        self.tok = tok or PegasusTokenizerFast.from_pretrained(self.name)\n",
    "        \n",
    "    @add_docstring(PegasusForConditionalGeneration.generate)\n",
    "    def __call__(self, text, n=1, temperature=1.5, **kwargs):\n",
    "        # TODO: not sure how many rows of text can be done in a single batch.\n",
    "        # Maybe look at other pipelines to see what they do. I'm thinking we\n",
    "        # could auto-batch longer sequences (e.g. a list w/ 10_000 strings\n",
    "        # might become 100 batches of 100).\n",
    "        texts = [text] if isinstance(text, str) else text\n",
    "        batch = self.tok.prepare_seq2seq_batch(texts, truncation=True, \n",
    "                                               padding='longest').to(DEVICE)\n",
    "        gen_tokens = self.net.generate(**batch, num_return_sequences=n,\n",
    "                                       temperature=temperature, **kwargs)\n",
    "        gen = self.tok.batch_decode(gen_tokens.tolist(), \n",
    "                                    skip_special_tokens=True)\n",
    "        if not isinstance(text, str) and len(text) > 1: \n",
    "            gen = [gen[i*n:(i+1)*n] for i in range(len(text))]\n",
    "        return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:22:28.637994Z",
     "start_time": "2020-11-06T06:22:28.628384Z"
    }
   },
   "outputs": [],
   "source": [
    "p_pipe = ParaphrasePipeline(net, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:22:49.707154Z",
     "start_time": "2020-11-06T06:22:35.521122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe('It was a beautiful rainy day.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:22:58.925380Z",
     "start_time": "2020-11-06T06:22:53.288989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.',\n",
       " 'It was a nice day.',\n",
       " 'It was raining but it was nice.']"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe('It was a beautiful rainy day.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:06.328322Z",
     "start_time": "2020-11-04T02:12:02.868563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.'], ['The duck was fluffy and yellow.']]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:09.898263Z",
     "start_time": "2020-11-04T02:12:06.330746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There was a beautiful day.',\n",
       "  'It was a nice day.',\n",
       "  'It was raining but it was nice.'],\n",
       " ['The duck was fluffy and yellow.',\n",
       "  'The duck was fluffy.',\n",
       "  'The duck was big and fluffy.']]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe(['It was a beautiful rainy day.', 'The duck was yellow and fluffy.'], \n",
    "     n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-04T02:12:12.933407Z",
     "start_time": "2020-11-04T02:12:09.901067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There was a beautiful day.', 'It was a nice day.']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_pipe(['It was a beautiful rainy day.'], n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:12:16.891666Z",
     "start_time": "2020-11-06T06:12:16.884789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decided to abandon this. Too many ways children differ: paraphrase pipeline\n",
    "# can't create pipe with pipeline(name) because it's not part of huggingface,\n",
    "# paraphrase transform doesn't need to check if listlike because preprocess\n",
    "# does nothing and __call__ literally just calls pipe. Leaving this here as\n",
    "# an examle of init_subclass.\n",
    "class TransformerTransformBase(ABC):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, text, **kwargs):\n",
    "        if listlike(text):\n",
    "            return [self.transform(t, **kwargs) for t in text]\n",
    "        return self.transform(text, **kwargs)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def transform(self, text, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def __init_subclass__(cls, **kwargs):\n",
    "        if not hasattr(cls, 'pipe_name'):\n",
    "            raise RuntimeError(f'{cls} must have class attr \"pipe_name\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:12:17.374202Z",
     "start_time": "2020-11-06T06:12:17.347429Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "<class '__main__.Tmp'> must have class attr \"pipe_name\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-275-f6964c4c85f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerTransformBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"a\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0m_abc_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-274-0481410a8a41>\u001b[0m in \u001b[0;36m__init_subclass__\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init_subclass__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pipe_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{cls} must have class attr \"pipe_name\".'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: <class '__main__.Tmp'> must have class attr \"pipe_name\"."
     ]
    }
   ],
   "source": [
    "class Tmp(TransformerTransformBase):\n",
    "    \"\"\"a\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:13.254628Z",
     "start_time": "2020-11-08T04:46:13.226523Z"
    }
   },
   "outputs": [],
   "source": [
    "@auto_repr\n",
    "class FillMaskTransform:    \n",
    "\n",
    "    MASK = '<mask>'\n",
    "    \n",
    "    def __init__(self, pipe=None, n=3):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('fill-mask', topk=n)\n",
    "        self.n = n\n",
    "        \n",
    "        assert type(self.pipe).__name__ == 'FillMaskPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, min_keep=3, errors='raise'):\n",
    "        \"\"\"\n",
    "        errors: str\n",
    "            If 'warn', we show a warning when min_keep is violated but allow\n",
    "            masking to take place.\n",
    "            \"\"\"\n",
    "        if listlike(text):\n",
    "            return [self._preprocess(row, min_keep, errors) for row in text]\n",
    "        \n",
    "        tokens = text.split()\n",
    "        if len(tokens) < min_keep + 1:\n",
    "            msg = (f'Text \"{text[:25]}...\" is too short to mask while '\n",
    "                   f'enforcing min_keep={min_keep}.')\n",
    "            if errors == 'warn':\n",
    "                warnings.wazzaarn(msg)\n",
    "            else:\n",
    "                raise ValueError(msg)\n",
    "        \n",
    "        idx = np.random.choice(range(len(tokens)))\n",
    "        return ' '.join(self.MASK if i == idx else t \n",
    "                        for i, t in enumerate(tokens))\n",
    "    \n",
    "    def __call__(self, text, n=1, n_mask=1, min_keep=3, return_all=False, \n",
    "                 errors:('warn', 'raise')='raise', \n",
    "                 strategy:('random', 'best')='best'):\n",
    "        \"\"\"\n",
    "        n: int or None\n",
    "            If None, return all generated examples for the given mask count.\n",
    "            This can become very large when n_mask is large. Recall pipeline\n",
    "            can only fill a single mask at a time. e.g. if self.n is\n",
    "            3, n=None, and n_mask is 4, we first mask once and generate 3\n",
    "            samples. Then we mask each of those 3 and generate a total of 9 \n",
    "            samples, then 27, then finally 81 which is what will be returned.\n",
    "            The intermediate samples can be returned with `return_all=True`.\n",
    "        \"\"\"\n",
    "        # Each item will be a list of strings. Each string in res[i]\n",
    "        # will have i words changed. If text is a sequence of strings, we must\n",
    "        # handle each one separately because each is passed through pipeline\n",
    "        # repeatedly.\n",
    "        if listlike(text):\n",
    "            return [self(row, n, n_mask, min_keep, return_all, errors) \n",
    "                    for row in text]\n",
    "        \n",
    "        # topk determines number of sequences generated by each model call.\n",
    "        if n and n > self.pipe.topk:\n",
    "            self.n = n\n",
    "            \n",
    "        res = [[text]]\n",
    "        for i in range(n_mask):\n",
    "            seqs = self.pipe(self._preprocess(res[-1], min_keep=min_keep,\n",
    "                                              errors=errors))\n",
    "            # Transformers returns either list of dicts or list of list of \n",
    "            # dicts depending on whether input list has 1 item or multiple.\n",
    "            if isinstance(seqs[0], list): \n",
    "                seqs = [seq for group in seqs for seq in group]\n",
    "            text = [seq['sequence'].replace('<s>', '').replace('</s>', '') \n",
    "                    for seq in seqs]\n",
    "            \n",
    "            # n=None selects all items when list slicing but only 1 in\n",
    "            # `random.choice` so we check for it explicitly.\n",
    "            if n and strategy == 'random':\n",
    "                text = np.random.choice(text, n, replace=False)\n",
    "            elif strategy == 'best':\n",
    "                text = text[:n]\n",
    "            res.append(text)\n",
    "        if not return_all: res = res[n_mask]\n",
    "        return res\n",
    "    \n",
    "    @property\n",
    "    def n(self):\n",
    "        return self._n\n",
    "    \n",
    "    @n.setter\n",
    "    def n(self, n):\n",
    "        if not isinstance(n, int):\n",
    "            raise TypeError('n must be an integer.')\n",
    "        \n",
    "        self._n = n\n",
    "        self.pipe.topk = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:15.798318Z",
     "start_time": "2020-11-08T04:46:15.792403Z"
    }
   },
   "outputs": [],
   "source": [
    "t = 'I went to the store today to buy eggs.'\n",
    "ts = [t, 'The bird swooped down onto the picnic table and squawked loudly.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:15.977106Z",
     "start_time": "2020-11-08T04:46:15.966549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FillMaskTransform(pipe=<transformers.pipelines.FillMaskPipeline object at 0x1a31ecfb70>)"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# m_pipe = pipeline('fill-mask')\n",
    "m_tfm = FillMaskTransform(m_pipe)\n",
    "m_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:16.272843Z",
     "start_time": "2020-11-08T04:46:16.267780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went to the store today to <mask> eggs.'"
      ]
     },
     "execution_count": 996,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm._preprocess(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:16.479744Z",
     "start_time": "2020-11-08T04:46:16.473596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to <mask> eggs.',\n",
       " 'The bird swooped down onto <mask> picnic table and squawked loudly.']"
      ]
     },
     "execution_count": 997,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm._preprocess(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:16.683221Z",
     "start_time": "2020-11-08T04:46:16.593732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.'],\n",
       " ['I went to the store yesterday to buy eggs.',\n",
       "  'I went to the store intending to buy eggs.',\n",
       "  'I went to the store wanting to buy eggs.']]"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(t, 3, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.010048Z",
     "start_time": "2020-11-08T04:46:16.743538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to another supermarket today to buy eggs.',\n",
       " 'I went to a supermarket today to buy eggs.',\n",
       " 'I went to my supermarket today to buy eggs.']"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(t, 3, n_mask=2, strategy='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.285229Z",
     "start_time": "2020-11-08T04:46:17.013517Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I went to the store myself & buy eggs.',\n",
       "       'I went to the store yesterday & buy eggs.',\n",
       "       'I went to grocery store today and buy eggs.'], dtype='<U43')"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(t, 3, n_mask=2, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.497526Z",
     "start_time": "2020-11-08T04:46:17.287412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'We went to the store today to buy eggs.',\n",
       "  'She went to the store today to buy eggs.'],\n",
       " ['I went to the store today to buy eggs.',\n",
       "  'We went to the store today to buy eggs.',\n",
       "  'She went to the store today to buy eggs.']]"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(t, 3, n_mask=2, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.576194Z",
     "start_time": "2020-11-08T04:46:17.499342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.'],\n",
       " ['I went to the store today to buy eggs.']]"
      ]
     },
     "execution_count": 1002,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(t, 1, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.777398Z",
     "start_time": "2020-11-08T04:46:17.579953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the supermarket today to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table and squawked loudly.']]"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:17.973685Z",
     "start_time": "2020-11-08T04:46:17.779833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to grocery store today to buy eggs.',\n",
       "  'I went to the store today to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped down onto the kitchen table and squawked loudly.']]"
      ]
     },
     "execution_count": 1004,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(ts, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:18.484447Z",
     "start_time": "2020-11-08T04:46:17.978303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the supermarket today to buy eggs.',\n",
       "  'I drove to the supermarket today to buy eggs.',\n",
       "  'I headed to the supermarket today to buy eggs.',\n",
       "  'I went to the store today to buy eggs.',\n",
       "  'I went into the store today to buy eggs.',\n",
       "  'I went through the store today to buy eggs.',\n",
       "  'I went to the grocery today to buy eggs.',\n",
       "  'She went to the grocery today to buy eggs.',\n",
       "  'We went to the grocery today to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped up onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped overhead onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped down onto the kitchen table and squawked loudly.',\n",
       "  'The bird swooped down onto the kitchen floor and squawked loudly.',\n",
       "  'The bird swooped down onto the kitchen counter and squawked loudly.',\n",
       "  'The bird hopped down onto the dining table and squawked loudly.',\n",
       "  'The bird slid down onto the dining table and squawked loudly.',\n",
       "  'The bird climbed down onto the dining table and squawked loudly.']]"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(ts, n=None, n_mask=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T04:46:18.877843Z",
     "start_time": "2020-11-08T04:46:18.488185Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['I went to the store today to buy eggs.'],\n",
       "  ['I went to grocery store today to buy eggs.',\n",
       "   'I went to the store today to buy eggs.',\n",
       "   'I went to my store today to buy eggs.'],\n",
       "  ['I went to grocery store today to buy eggs.',\n",
       "   'I went to the store today to buy eggs.',\n",
       "   'I went to my store today to buy eggs.',\n",
       "   'I went to grocery store today to buy eggs.',\n",
       "   'I went to the store today to buy eggs.',\n",
       "   'I went to my store today to buy eggs.',\n",
       "   'I went to my store today to buy eggs.',\n",
       "   'I went to my supermarket today to buy eggs.',\n",
       "   'I went to my grocer today to buy eggs.']],\n",
       " [['The bird swooped down onto the picnic table and squawked loudly.'],\n",
       "  ['The bird swooped down onto a picnic table and squawked loudly.',\n",
       "   'The bird swooped down onto the picnic table and squawked loudly.',\n",
       "   'The bird swooped down onto another picnic table and squawked loudly.'],\n",
       "  ['The bird hopped down onto a picnic table and squawked loudly.',\n",
       "   'The bird settled down onto a picnic table and squawked loudly.',\n",
       "   'The bird laid down onto a picnic table and squawked loudly.',\n",
       "   'The bird swooped down onto the picnic table and squawked.',\n",
       "   'The bird swooped down onto the picnic table and squawked!',\n",
       "   'The bird swooped down onto the picnic table and squawked:',\n",
       "   'The bird swooped down onto a picnic table and squawked loudly.',\n",
       "   'The bird swooped down onto the picnic table and squawked loudly.',\n",
       "   'The bird swooped down onto another picnic table and squawked loudly.']]]"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tfm(ts, n=None, n_mask=2, return_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:24:00.049115Z",
     "start_time": "2020-11-07T06:24:00.041328Z"
    }
   },
   "outputs": [],
   "source": [
    "@auto_repr\n",
    "class ParaphraseTransform:\n",
    "    \"\"\"Not sure how useful this will really be but this basically just \n",
    "    wraps ParaphrasePipeline to share a more similar interface with the other\n",
    "    NLP transforms.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pipe=None, n=1):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or ParaphrasePipeline()\n",
    "        self.n = n\n",
    "            \n",
    "        assert type(self.pipe).__name__ == 'ParaphrasePipeline'\n",
    "        \n",
    "    def _preprocess(self, text):\n",
    "        return text\n",
    "    \n",
    "    def __call__(self, text, n=None, **kwargs):\n",
    "        return self.pipe(text, n=n or self.n, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:23:14.099343Z",
     "start_time": "2020-11-06T06:23:14.091373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParaphraseTransform(pipe=<__main__.ParaphrasePipeline object at 0x1a47cda198>)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm = ParaphraseTransform(p_pipe)\n",
    "p_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:23:24.441803Z",
     "start_time": "2020-11-06T06:23:17.058658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The beach is crowded.',\n",
       " 'There is a lot of people on the beach.',\n",
       " 'There is a lot of people at the beach.']"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm('The beach is loud and crowded today.', n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:22:36.982196Z",
     "start_time": "2020-11-05T06:22:22.156295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to buy eggs.'], ['The bird swooped down onto the picnic table.']]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:22:44.555755Z",
     "start_time": "2020-11-05T06:22:38.723246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to buy eggs.', 'I went to the store to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table.',\n",
       "  'The bird swooped down on the picnic table.']]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_tfm(ts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:48:03.758403Z",
     "start_time": "2020-11-05T06:48:03.754099Z"
    }
   },
   "outputs": [],
   "source": [
    "def listlike(x):\n",
    "    \"\"\"Checks if an object is a list/tuple/set/array etc. Strings and\n",
    "    mappings (e.g. dicts) are not considered list-like.\n",
    "    \"\"\"\n",
    "    return isinstance(x, Iterable) and not isinstance(x, (str, Mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T06:47:50.367487Z",
     "start_time": "2020-11-05T06:47:50.357976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> False\n",
      "<class 'int'> False\n",
      "<class 'list'> True\n",
      "<class 'tuple'> True\n",
      "<class 'dict'> False\n",
      "<class 'set'> True\n",
      "<class 'list'> True\n",
      "<class 'list'> True\n",
      "<class 'tuple'> True\n",
      "<class 'dict'> False\n",
      "<class 'set'> True\n",
      "<class 'numpy.ndarray'> True\n"
     ]
    }
   ],
   "source": [
    "for obj in ('a', 6, [], (), {}, set(), [3, 4], ['a', 'b'], ('a',), {'a': 'b'},\n",
    "            {'a', 'b'}, np.arange(5)):\n",
    "    print(type(obj), listlike(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:46.196222Z",
     "start_time": "2020-11-07T06:27:46.185868Z"
    }
   },
   "outputs": [],
   "source": [
    "@auto_repr\n",
    "class GenerativeTransform:\n",
    "    \n",
    "    def __init__(self, pipe=None, n=1):\n",
    "        # We let user pass in pipe at least for now since re-instantiating the\n",
    "        # class can be very slow during development. Need to consider whether\n",
    "        # I want this behavior to remain.\n",
    "        self.pipe = pipe or pipeline('text-generation')\n",
    "        self.n = n\n",
    "        \n",
    "        assert type(self.pipe).__name__ == 'TextGenerationPipeline'\n",
    "    \n",
    "    def _preprocess(self, text, drop=None, drop_pct=None, rand_low=None, \n",
    "                    rand_high=None, min_keep=3, return_tuple=False):\n",
    "        \"\"\"Truncate text.\"\"\"\n",
    "        if listlike(text):\n",
    "            return [self._preprocess(row, drop, drop_pct, rand_low, rand_high,\n",
    "                                     min_keep, return_tuple) for row in text]\n",
    "        \n",
    "        tokens = text.split()\n",
    "        if len(tokens) <= min_keep:\n",
    "            n = 0\n",
    "        else:\n",
    "            # Default is to truncate the last 20% of the sequence.\n",
    "            if drop:\n",
    "                n = drop\n",
    "            elif drop_pct:\n",
    "                n = int(drop_pct * len(tokens))\n",
    "            elif rand_low is not None and rand_high is not None:\n",
    "                n = np.random.randint(rand_low, rand_high)\n",
    "            else:\n",
    "                n = int(np.ceil(.2 * len(tokens)))\n",
    "            n = np.clip(n, 0, len(tokens) - min_keep)\n",
    "            tokens = tokens[:-n]\n",
    "        truncated = ' '.join(tokens)\n",
    "        return (truncated, n) if return_tuple else truncated\n",
    "    \n",
    "    def __call__(self, text, n=None, min_length=2, max_length=7, \n",
    "                 **generate_kwargs):\n",
    "        n = n or self.n\n",
    "        if listlike(text):\n",
    "            return [self(row, n, min_length, max_length, **generate_kwargs) \n",
    "                    for row in text]\n",
    "    \n",
    "        # `generate` counts current length as part of min_length. \n",
    "        text = self._preprocess(text)\n",
    "        n_curr = len(self.pipe.tokenizer.tokenize(text))\n",
    "        res = self.pipe(text, min_length=n_curr + min_length,\n",
    "                        max_length=n_curr + max_length,\n",
    "                        num_return_sequences=n, **generate_kwargs)\n",
    "        return [row['generated_text'] for row in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:46.589860Z",
     "start_time": "2020-11-07T06:27:46.583082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerativeTransform(pipe=<transformers.pipelines.TextGenerationPipeline object at 0x1d081425c0>, n=1)"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# g_pipe = pipeline('text-generation')\n",
    "g_tfm = GenerativeTransform(g_pipe)\n",
    "g_tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:47.212987Z",
     "start_time": "2020-11-07T06:27:47.205670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went to the store today to'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm._preprocess(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:47.953718Z",
     "start_time": "2020-11-07T06:27:47.947394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I went to the store today to', 2),\n",
       " ('The bird swooped down onto the picnic table', 3)]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm._preprocess(ts, return_tuple=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:49.224676Z",
     "start_time": "2020-11-07T06:27:48.825361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy a shirt, but I felt']"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:50.906948Z",
     "start_time": "2020-11-07T06:27:50.378713Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy some clothes. The first thing',\n",
       " 'I went to the store today to see where it went and I asked']"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(t, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:52.192960Z",
     "start_time": "2020-11-07T06:27:51.445339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to check out everything. I wanted to'],\n",
       " ['The bird swooped down onto the picnic table so much that two of them noticed']]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:27:55.987724Z",
     "start_time": "2020-11-07T06:27:54.662471Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to pick up my kids, got some',\n",
       "  \"I went to the store today to check out his new book, '\"],\n",
       " ['The bird swooped down onto the picnic table, then proceeded to lay itself down',\n",
       "  'The bird swooped down onto the picnic table, where he and the other dogs']]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_tfm(ts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:18:58.435710Z",
     "start_time": "2020-11-06T06:18:58.422790Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'm now thinking this isn't that useful. It also loses our kwarg names \n",
    "# unless I pull some tricks altering signatures. Don't think this offers \n",
    "# enough benefit to justify that.\n",
    "class TransformerTransform:\n",
    "    \n",
    "    def __init__(self, mode, pipe=None):\n",
    "        self.mode = mode\n",
    "        self._transformer = self._get_transformer(pipe)\n",
    "        \n",
    "    def _preprocess(self, text, **kwargs):\n",
    "        return self._transformer._preprocess(text, **kwargs)\n",
    "    \n",
    "    def __call__(self, text, **kwargs):\n",
    "        return self._transformer(text, **kwargs)\n",
    "    \n",
    "    def _get_transformer(self, pipe):\n",
    "        if self.mode == 'mask':\n",
    "            return FillMaskTransform(pipe)\n",
    "        elif self.mode == 'generate':\n",
    "            return GenerativeTransform(pipe)\n",
    "        elif self.mode == 'paraphrase':\n",
    "            return ParaphraseTransform(pipe)\n",
    "        else:\n",
    "            raise ValueError('mode must be in (mask, generate, paraphrase).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:09.524677Z",
     "start_time": "2020-11-06T06:19:09.520369Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "mt = TransformerTransform('mask', m_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:10.893643Z",
     "start_time": "2020-11-06T06:19:10.875581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I went to <mask> store today to buy eggs.'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt._preprocess(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:11.427649Z",
     "start_time": "2020-11-06T06:19:11.421747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I <mask> to the store today to <mask> eggs.',\n",
       " 'The <mask> swooped down <mask> the picnic table and squawked loudly.']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt._preprocess(ts, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:12.969444Z",
     "start_time": "2020-11-06T06:19:11.982314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the store today to buy eggs.',\n",
       " 'I went into the store today to buy eggs.',\n",
       " 'I went through the store today to buy eggs.',\n",
       " 'I went around the store today to buy eggs.',\n",
       " 'I went in the store today to buy eggs.']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-06T06:19:14.262802Z",
     "start_time": "2020-11-06T06:19:13.982937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I went to the store today to buy eggs.',\n",
       "  'I went into the store today to buy eggs.',\n",
       "  'I went through the store today to buy eggs.',\n",
       "  'I went around the store today to buy eggs.',\n",
       "  'I went in the store today to buy eggs.'],\n",
       " ['The bird swooped down onto the picnic table and squawked loudly.',\n",
       "  'The bird swooped down onto the picnic table, squawked loudly.',\n",
       "  'The bird swooped down onto the picnic table then squawked loudly.',\n",
       "  'The bird swooped down onto the picnic table who squawked loudly.',\n",
       "  'The bird swooped down onto the picnic table but squawked loudly.']]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T05:19:19.026922Z",
     "start_time": "2020-11-07T05:19:18.952229Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9887"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [line.strip() for line \n",
    "         in '\\n'.join(load(f'/Users/hmamin/data/bbc/tech/{n:03}.txt') \n",
    "         for n in range(1, 402)).split('.') if line]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:29:33.595508Z",
     "start_time": "2020-11-07T06:29:27.085884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: Text \"And vice versa...\" is too short to mask while enforcing min_keep=3.\n"
     ]
    }
   ],
   "source": [
    "m_res = m_tfm(lines[:100], errors='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:30:37.216585Z",
     "start_time": "2020-11-07T06:30:37.207024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten(m_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:29:33.606452Z",
     "start_time": "2020-11-07T06:29:33.597326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and fingerprint readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       "  \"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and electronic readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       "  \"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and pen readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       "  \"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and paper readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       "  \"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and ink readers in the country's elections as part of a drive to prevent multiple voting\"],\n",
       " ['This new technology is causing both worries and guarded optimism among different segments of the population',\n",
       "  'This new technology is causing both worries and guarded optimism among different sectors of the population',\n",
       "  'This new technology is causing both worries and guarded optimism among different sections of the population',\n",
       "  'This new technology is causing both worries and guarded optimism among different parts of the population',\n",
       "  'This new technology is causing both worries and guarded optimism among different quarters of the population']]"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_res[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:29:27.034496Z",
     "start_time": "2020-11-07T06:28:50.493856Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    }
   ],
   "source": [
    "g_res = g_tfm(lines[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:30:29.950546Z",
     "start_time": "2020-11-07T06:30:29.942428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten(g_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:30:48.864764Z",
     "start_time": "2020-11-07T06:30:48.857287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ink helps drive democracy in Asia\\n\\nThe Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and ultraviolet readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       " 'This new technology is causing both worries and guarded optimism among different sectors of the population']"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T06:29:33.674019Z",
     "start_time": "2020-11-07T06:29:33.655130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Ink helps drive democracy in Asia The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and ultraviolet readers in the country's elections as an early warning to the rest of\"],\n",
       " ['This new technology is causing both worries and guarded optimism among different groups in Europe about cybersecurity,\" said']]"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_res[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T07:02:05.133625Z",
     "start_time": "2020-11-07T06:59:39.088199Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p_res = p_tfm(lines[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T07:02:08.645487Z",
     "start_time": "2020-11-07T07:02:08.605932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatten(p_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T07:02:09.447401Z",
     "start_time": "2020-11-07T07:02:09.439494Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Ink helps drive democracy in Asia\\n\\nThe Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and ultraviolet readers in the country's elections as part of a drive to prevent multiple voting\",\n",
       " 'This new technology is causing both worries and guarded optimism among different sectors of the population',\n",
       " 'In an effort to live up to its reputation in the 1990s as \"an island of democracy\", the Kyrgyz President, Askar Akaev, pushed through the law requiring the use of ink during the upcoming Parliamentary and Presidential elections',\n",
       " 'The US government agreed to fund all expenses associated with this decision',\n",
       " 'The Kyrgyz Republic is seen by many experts as backsliding from the high point it reached in the mid-1990s with a hastily pushed through referendum in 2003, reducing the legislative branch to one chamber with 75 deputies']"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-07T07:02:11.119963Z",
     "start_time": "2020-11-07T07:02:11.113942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"The Kyrgyz Republic, a small, mountainous state of the former Soviet republic, is using invisible ink and ultraviolet readers in the country's elections as part of a drive to prevent multiple voting.\"],\n",
       " ['There are both worries and guarded optimism among different sectors of the population.'],\n",
       " ['The law requiring the use of ink during the upcoming Parliamentary and Presidential elections was pushed through by the President in an effort to live up to its reputation as an island of democracy.'],\n",
       " ['All expenses associated with this decision will be funded by the US government.'],\n",
       " ['The high point of the Kyrgyz Republic was in the mid 1990s when it had a legislative branch with 75 deputies and was seen by many experts as backsliding.']]"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_res[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: maybe see about adding auto GPU support for ParaphrasePipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
