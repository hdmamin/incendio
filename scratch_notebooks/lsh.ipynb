{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract Attributes\n",
    "\n",
    "Not working yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstractattrs(*attrs):\n",
    "    def wrapper(cls):\n",
    "        \n",
    "        def method(cls, *args, **kwargs):\n",
    "            super().__init_subclass__(*args, **kwargs)\n",
    "            for attr in attrs:\n",
    "                if not hasattr(cls, attr):\n",
    "                    raise RuntimeError(f'Class must have attribute {attr}.') \n",
    "                    \n",
    "        setattr(cls, '__init_subclass__', classmethod(method))\n",
    "        return cls\n",
    "    return wrapper              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "@abstractattrs('name', 'age')\n",
    "class Base:\n",
    "    def __init__(self, age=7):\n",
    "        self.age = age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Child(Base):\n",
    "    a = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(a, b, **kwargs):\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo(3, 4, c=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import lsh, MinHashLSH, MinHash, MinHashLSHForest\n",
    "\n",
    "from htools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(['minhash', 'is', 'a', 'probabilistic', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'datasets'])\n",
    "set2 = set(['minhash', 'is', 'a', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "set3 = set(['minhash', 'is', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "\n",
    "m1 = MinHash(num_perm=128)\n",
    "m2 = MinHash(num_perm=128)\n",
    "m3 = MinHash(num_perm=128)\n",
    "for d in set1:\n",
    "    m1.update(d.encode('utf8'))\n",
    "for d in set2:\n",
    "    m2.update(d.encode('utf8'))\n",
    "for d in set3:\n",
    "    m3.update(d.encode('utf8'))\n",
    "\n",
    "# Create LSH index\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "lsh.insert(\"m2\", m2)\n",
    "lsh.insert(\"m3\", m3)\n",
    "result = lsh.query(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(word, n=3, step=1, drop_last=False):\n",
    "    \"\"\"To get non-overlapping sequences, pass in same value for `step` as `n`.\"\"\"\n",
    "    stop = max(1, step+len(word)-n)\n",
    "    ngrams_ = []\n",
    "    for i in range(0, stop, step):\n",
    "        ngrams_.append(word[i:i+n])\n",
    "    if drop_last and len(ngrams_[-1]) < n: ngrams_ = ngrams_[:-1]\n",
    "    return ngrams_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 'dinosaur'\n",
    "tw = 'I'\n",
    "ws = ['dino', 'rhino', 'dog', 'cat', 'lion', 'tyrannosaurus rex',\n",
    "      'tiger', 'owl', 'rhinocerous', 'kino']\n",
    "s = 'The mailman was running late today, possibly due to the heavy '\\\n",
    "    'snowfall from the previous night.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['din', 'ino', 'nos', 'osa', 'sau', 'aur']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['di', 'in', 'no', 'os', 'sa', 'au', 'ur']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(w, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['din', 'osa', 'ur']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(w, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['din', 'osa']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(w, 3, 3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'he ',\n",
       " 'e m',\n",
       " ' ma',\n",
       " 'mai',\n",
       " 'ail',\n",
       " 'ilm',\n",
       " 'lma',\n",
       " 'man',\n",
       " 'an ',\n",
       " 'n w',\n",
       " ' wa',\n",
       " 'was',\n",
       " 'as ',\n",
       " 's r',\n",
       " ' ru',\n",
       " 'run',\n",
       " 'unn',\n",
       " 'nni',\n",
       " 'nin',\n",
       " 'ing',\n",
       " 'ng ',\n",
       " 'g l',\n",
       " ' la',\n",
       " 'lat',\n",
       " 'ate',\n",
       " 'te ',\n",
       " 'e t',\n",
       " ' to',\n",
       " 'tod',\n",
       " 'oda',\n",
       " 'day',\n",
       " 'ay,',\n",
       " 'y, ',\n",
       " ', p',\n",
       " ' po',\n",
       " 'pos',\n",
       " 'oss',\n",
       " 'ssi',\n",
       " 'sib',\n",
       " 'ibl',\n",
       " 'bly',\n",
       " 'ly ',\n",
       " 'y d',\n",
       " ' du',\n",
       " 'due',\n",
       " 'ue ',\n",
       " 'e t',\n",
       " ' to',\n",
       " 'to ',\n",
       " 'o t',\n",
       " ' th',\n",
       " 'the',\n",
       " 'he ',\n",
       " 'e h',\n",
       " ' he',\n",
       " 'hea',\n",
       " 'eav',\n",
       " 'avy',\n",
       " 'vy ',\n",
       " 'y s',\n",
       " ' sn',\n",
       " 'sno',\n",
       " 'now',\n",
       " 'owf',\n",
       " 'wfa',\n",
       " 'fal',\n",
       " 'all',\n",
       " 'll ',\n",
       " 'l f',\n",
       " ' fr',\n",
       " 'fro',\n",
       " 'rom',\n",
       " 'om ',\n",
       " 'm t',\n",
       " ' th',\n",
       " 'the',\n",
       " 'he ',\n",
       " 'e p',\n",
       " ' pr',\n",
       " 'pre',\n",
       " 'rev',\n",
       " 'evi',\n",
       " 'vio',\n",
       " 'iou',\n",
       " 'ous',\n",
       " 'us ',\n",
       " 's n',\n",
       " ' ni',\n",
       " 'nig',\n",
       " 'igh',\n",
       " 'ght',\n",
       " 'ht.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsh_hash_word(word, num_perm=128, **ngram_kwargs):\n",
    "    mhash = MinHash(num_perm=num_perm)\n",
    "    for ng in ngrams(word, **ngram_kwargs):\n",
    "        mhash.update(ng.encode('utf8'))\n",
    "    return mhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lsh_hash_word(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = MinHashLSHForest(num_perm=128)\n",
    "\n",
    "for i, word in enumerate(ws):\n",
    "    forest.add(i, lsh_hash_word(word))\n",
    "forest.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.query(lsh_hash_word(w), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dino',\n",
       " 'rhino',\n",
       " 'dog',\n",
       " 'cat',\n",
       " 'lion',\n",
       " 'tyrannosaurus rex',\n",
       " 'tiger',\n",
       " 'owl',\n",
       " 'rhinocerous',\n",
       " 'kino']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 0, 5]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = forest.query(lsh_hash_word(w), 3)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dino', 'tyrannosaurus rex', 'rhinocerous']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select(ws, idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
