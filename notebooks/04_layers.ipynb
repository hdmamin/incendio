{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Custom activations, layers, and layer blocks are contained in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.layers import trunc_normal_\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from htools import add_docstring\n",
    "from incendio.data import probabilistic_hash_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for testing only.\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from htools import assert_raises, InvalidArgumentError\n",
    "from incendio.data import probabilistic_hash_item\n",
    "import pandas_htools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GRelu(nn.Module):\n",
    "    \"\"\"Generic ReLU.\"\"\"\n",
    "\n",
    "    def __init__(self, leak=0.0, max=float('inf'), sub=0.0):\n",
    "        super().__init__()\n",
    "        self.leak = leak\n",
    "        self.max = max\n",
    "        self.sub = sub\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Check which operations are necessary to save computation.\"\"\"\n",
    "        x = F.leaky_relu(x, self.leak) if self.leak else F.relu(x)\n",
    "        if self.sub:\n",
    "            x -= self.sub\n",
    "        if self.max:\n",
    "            x = torch.clamp(x, max=self.max)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GReLU(leak={self.leak}, max={self.max}, sub={self.sub})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "JRelu = GRelu(leak=.1, sub=.4, max=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Mish(nn.Module):\n",
    "    \"\"\"OOP form of mish activation.\n",
    "\n",
    "    Mish: A Self Regularized Non-Monotonic Neural Activation Function\n",
    "    https://arxiv.org/pdf/1908.08681v1.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mish(x):\n",
    "    \"\"\"Functional form of mish activation.\n",
    "\n",
    "    Mish: A Self Regularized Non-Monotonic Neural Activation Function\n",
    "    https://arxiv.org/pdf/1908.08681v1.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor[float]\n",
    "        Input tensor.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor[float]: Tensor of same shape as input x.\n",
    "    \"\"\"\n",
    "    return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(z, a, mode='scatter', **kwargs):\n",
    "    \"\"\"Plot an input tensor and its corresponding activations.  Both tensors\n",
    "    will be flattened for plotting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z: tf.Tensor\n",
    "        Tensor containing values to plot on the x axis (we can often think of\n",
    "        this as the output of a linear layer, where z=f(x) and a=mish(z)).\n",
    "    a: tf.Tensor\n",
    "        Tensor containing values to plot on y axis.\n",
    "    mode: str\n",
    "        'scatter' for scatter plot or 'plot' for line plot.\n",
    "    kwargs: Values to be passed to the matplotlib plotting function, such as \n",
    "        's' when in 'scatter' mode or 'lw' in 'plot' mode.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt_func = getattr(plt, mode)\n",
    "    kwargs = kwargs or {}\n",
    "    if mode == 'scatter' and not kwargs:\n",
    "        kwargs = {'s': .75}\n",
    "    plt_func(z.numpy().flatten(), a.numpy().flatten(), **kwargs)\n",
    "    plt.axvline(0, lw=.5, alpha=.5)\n",
    "    plt.axhline(0, lw=.5, alpha=.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-5, 5, .05)\n",
    "a = mish(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_activations(x, a, 'plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Create a convolutional block optionally followed by a batch norm layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, kernel_size=3, norm=True, activation=JRelu,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        c_in: int\n",
    "            # of input channels.\n",
    "        c_out: int\n",
    "            # of output channels.\n",
    "        kernel_size: int\n",
    "            Size of kernel in conv2d layer. An integer argument will be used\n",
    "            as both the height and width.\n",
    "        norm: bool\n",
    "            If True, include a batch norm layer after the conv layer. If False,\n",
    "            no norm layer will be used. Note that batch norm has learnable\n",
    "            affine parameters which remove the need for a bias in the preceding\n",
    "            conv layer. When batch norm is not used, however, the conv layer\n",
    "            will include a bias term.\n",
    "        activation: nn.Module\n",
    "            Activation function to use at the end of the convolutional block.\n",
    "            (In some cases such as our ResBlock implementation, we pass in None\n",
    "            so that an extra addition can be performed before the final\n",
    "            activation.) Do not use the functional form here as it will be\n",
    "            added to a sequential object.\n",
    "        kwargs: any\n",
    "            Additional keyword args are passed to Conv2d. Useful kwargs include\n",
    "            stride, and padding (see pytorch docs for nn.Conv2d).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        layers = [nn.Conv2d(c_in, c_out, kernel_size, bias=not norm, **kwargs)]\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm2d(c_out))\n",
    "        if activation is not None:\n",
    "            layers.append(activation)\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (block): Sequential(\n",
       "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = ConvBlock(3, 5, norm=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 4, 4)\n",
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, activation=JRelu, f=3, stride=1, pad=1,\n",
    "                 skip_size=2, norm=True):\n",
    "        \"\"\"Residual block to be used in CycleGenerator. Note that f, stride,\n",
    "        and pad must be selected such that the height and width of the input\n",
    "        remain the same.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        c_in: int\n",
    "            # of input channels.\n",
    "        activation: callable\n",
    "            Activation function to use.\n",
    "        f: int\n",
    "            Size of filter (f x f) used in convolution. Default 3.\n",
    "        stride: int\n",
    "            # of pixels the filter moves between each convolution. Default 1.\n",
    "        pad: int\n",
    "            Pixel padding around the input. Default 1.\n",
    "        skip_size: int\n",
    "            Number of conv blocks inside the skip connection (default 2).\n",
    "            ResNet paper notes that skipping a single layer did not show\n",
    "            noticeable improvements.\n",
    "        norm: bool\n",
    "            Specifies whether to include a batch norm layer after each conv\n",
    "            layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.skip_size = skip_size\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvBlock(c_in, c_in, norm=norm, activation=None, kernel_size=f,\n",
    "                      stride=stride, padding=pad)\n",
    "            for i in range(skip_size)\n",
    "        ])\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x_out = layer(x_out)\n",
    "\n",
    "            # Final activation must be applied after addition.\n",
    "            if i != self.skip_size - 1:\n",
    "                x_out = self.activation(x_out)\n",
    "\n",
    "        return self.activation(x + x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(4, norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@add_docstring(nn.Conv2d)\n",
    "class ReflectionPaddedConv2d(nn.Module):\n",
    "    \"\"\"Conv2d only allows padding_mode of `zeros` or `circular`. This\n",
    "    layer is a quick way for us to use reflection padding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, padding=1, \n",
    "                 kernel_size=3, **kwargs):\n",
    "        \"\"\"Do not specify a padding mode.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        if 'padding_mode' in kwargs: \n",
    "            raise InvalidArgumentError('Remove `padding_mode` from arguments.')\n",
    "        self.reflect = nn.ReflectionPad2d(padding)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              padding=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reflect(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img.permute(1, 2, 0) / 255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReflectionPaddedConv2d(\n",
       "  (reflect): ReflectionPad2d((2, 2, 2, 2))\n",
       "  (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rconv = ReflectionPaddedConv2d(3, 3, kernel_size=1, padding=2)\n",
    "rconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAODklEQVR4nO3df6yeZX3H8fdHCohSpFAjTakijrgpcxNOEHVxzcAEiKFLZAn+oWAkVSaZGk2GkGBiskxdopnTSBokwmaQDAgcTQ1BweGywKikUApBComjtROlroXhZHXf/XFuzOPx/Or13Od5noPvV/Lkue77vs59fXu1+fT+2aaqkKRD9ZJxFyBpZTI8JDUxPCQ1MTwkNTE8JDUxPCQ1GSo8khyX5I4kj3Xfa+bp96sk27vP9DBjSpoMGeY5jySfA/ZV1WeSXA6sqaq/nqPfs1V19BB1Spoww4bHo8DGqtqbZB3wvap6/Rz9DA/pRWbY8Pivqjq2awf4+QvLs/odBLYDB4HPVNWt8+xvM7AZ4MiXveT09a87qrm2F7t9z/tk8GKOfmbtuEuYeLt//B8/q6pXtvzsqsU6JPkOcMIcm64cXKiqSjLfn+jXVNWeJCcDdybZUVWPz+5UVVuALQCve9PR9blv/fGiv4DfVf/0o+fHXcLE+9O7Lhl3CRPvY5/64I9af3bR8Kiqs+fbluQnSdYNnLY8Nc8+9nTfTyT5HvBm4LfCQ9LKMeyt2mngoq59EXDb7A5J1iQ5smuvBd4OPDzkuJLGbNjw+AzwziSPAWd3yySZSnJN1+cPgG1JHgDuYuaah+EhrXCLnrYspKqeBs6aY/024JKu/W/AHw4zjqTJ4xOmkpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmhgekpoYHpKaGB6SmvQSHknOSfJokl1JLp9j+5FJbuy235vkpD7GlTQ+Q4dHksOALwPnAm8A3pPkDbO6fQD4eVX9HvAF4LPDjitpvPo48jgD2FVVT1TV88A3gE2z+mwCruvaNwFnJUkPY0sakz7CYz3w5MDy7m7dnH2q6iCwHzi+h7EljclEXTBNsjnJtiTbDuw7OO5yJC2gj/DYA2wYWD6xWzdnnySrgFcAT8/eUVVtqaqpqpo65rhVPZQmabn0ER73AackeW2SI4ALgelZfaaBi7r2BcCdVVU9jC1pTIb+672qDia5DLgdOAy4tqp2Jvk0sK2qpoGvAv+YZBewj5mAkbSC9XJuUFVbga2z1l010P4f4C/6GEvSZJioC6aSVg7DQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUhPDQ1ITw0NSE8NDUpNewiPJOUkeTbIryeVzbL84yU+TbO8+l/QxrqTxWTXsDpIcBnwZeCewG7gvyXRVPTyr641Vddmw40maDH0ceZwB7KqqJ6rqeeAbwKYe9itpgg195AGsB54cWN4NvGWOfu9O8g7gh8DHqurJ2R2SbAY2Axx93Kv47u1/10N5L04nf2HvuEuYeFce+8Zxl/CiNqoLpt8ETqqqNwF3ANfN1amqtlTVVFVNHbV6zYhKk9Sij/DYA2wYWD6xW/drVfV0Vf2yW7wGOL2HcSWNUR/hcR9wSpLXJjkCuBCYHuyQZN3A4vnAIz2MK2mMhr7mUVUHk1wG3A4cBlxbVTuTfBrYVlXTwF8lOR84COwDLh52XEnj1ccFU6pqK7B11rqrBtqfBD7Zx1iSJoNPmEpqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGrSS3gkuTbJU0kemmd7knwxya4kDyY5rY9xJY1PX0ceXwPOWWD7ucAp3Wcz8JWexpU0Jr2ER1XdDexboMsm4PqacQ9wbJJ1fYwtaTxGdc1jPfDkwPLubt1vSLI5ybYk237xzM9HVJqkFhN1wbSqtlTVVFVNHbV6zbjLkbSAUYXHHmDDwPKJ3TpJK9SowmMaeF931+VMYH9V7R3R2JKWwao+dpLkBmAjsDbJbuBTwOEAVXU1sBU4D9gFPAe8v49xJY1PL+FRVe9ZZHsBH+5jLEmTYaIumEpaOQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNDA9JTQwPSU0MD0lNegmPJNcmeSrJQ/Ns35hkf5Lt3eeqPsaVND69/EfXwNeALwHXL9Dn+1X1rp7GkzRmvRx5VNXdwL4+9iVpZejryGMp3prkAeDHwCeqaufsDkk2A5sBVq95JS8/8NMRlreyHJi+ZdwlTLybr7h03CVMvHOH+NlRXTC9H3hNVf0R8A/ArXN1qqotVTVVVVMve/kxIypNUouRhEdVHaiqZ7v2VuDwJGtHMbak5TGS8EhyQpJ07TO6cZ8exdiSlkcv1zyS3ABsBNYm2Q18CjgcoKquBi4ALk1yEPgFcGFVVR9jSxqPXsKjqt6zyPYvMXMrV9KLhE+YSmpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIamJ4SGpieEhqYnhIajJ0eCTZkOSuJA8n2ZnkI3P0SZIvJtmV5MEkpw07rqTx6uM/uj4IfLyq7k+yGvhBkjuq6uGBPucCp3SftwBf6b4lrVBDH3lU1d6qur9rPwM8Aqyf1W0TcH3NuAc4Nsm6YceWND69XvNIchLwZuDeWZvWA08OLO/mtwNG0grSW3gkORq4GfhoVR1o3MfmJNuSbHvuv5t2IWlEegmPJIczExxfr6pb5uiyB9gwsHxit+43VNWWqpqqqqmXvfyYPkqTtEz6uNsS4KvAI1X1+Xm6TQPv6+66nAnsr6q9w44taXz6uNvyduC9wI4k27t1VwCvBqiqq4GtwHnALuA54P09jCtpjIYOj6r6VyCL9Cngw8OOJWly+ISppCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCaGh6QmhoekJoaHpCZDh0eSDUnuSvJwkp1JPjJHn41J9ifZ3n2uGnZcSeO1qod9HAQ+XlX3J1kN/CDJHVX18Kx+36+qd/UwnqQJMPSRR1Xtrar7u/YzwCPA+mH3K2mypar621lyEnA3cGpVHRhYvxG4GdgN/Bj4RFXtnOPnNwObu8VTgYd6K64fa4GfjbuIAdazsEmrByavptdX1eqWH+wtPJIcDfwL8DdVdcusbccA/1dVzyY5D/j7qjplkf1tq6qpXorryaTVZD0Lm7R6YPJqGqaeXu62JDmcmSOLr88ODoCqOlBVz3btrcDhSdb2Mbak8ejjbkuArwKPVNXn5+lzQtePJGd04z497NiSxqePuy1vB94L7EiyvVt3BfBqgKq6GrgAuDTJQeAXwIW1+PnSlh5q69uk1WQ9C5u0emDyamqup9cLppJ+d/iEqaQmhoekJhMTHkmOS3JHkse67zXz9PvVwGPu08tQxzlJHk2yK8nlc2w/MsmN3fZ7u2dbltUSaro4yU8H5uWSZazl2iRPJZnzGZzM+GJX64NJTluuWg6hppG9HrHE1zVGOkfL9gpJVU3EB/gccHnXvhz47Dz9nl3GGg4DHgdOBo4AHgDeMKvPXwJXd+0LgRuXeV6WUtPFwJdG9Pv0DuA04KF5tp8HfBsIcCZw7wTUtBH41ojmZx1wWtdeDfxwjt+vkc7REms65DmamCMPYBNwXde+DvjzMdRwBrCrqp6oqueBb3R1DRqs8ybgrBduQ4+xppGpqruBfQt02QRcXzPuAY5Nsm7MNY1MLe11jZHO0RJrOmSTFB6vqqq9Xfs/gVfN0++lSbYluSdJ3wGzHnhyYHk3vz3Jv+5TVQeB/cDxPddxqDUBvLs7BL4pyYZlrGcxS6131N6a5IEk307yxlEM2J3Svhm4d9amsc3RAjXBIc5RH895LFmS7wAnzLHpysGFqqok891Dfk1V7UlyMnBnkh1V9Xjfta4w3wRuqKpfJvkgM0dGfzbmmibJ/cz8uXnh9YhbgQVfjxhW97rGzcBHa+A9r3FapKZDnqORHnlU1dlVdeocn9uAn7xw6NZ9PzXPPvZ0308A32MmRfuyBxj8W/vEbt2cfZKsAl7B8j4tu2hNVfV0Vf2yW7wGOH0Z61nMUuZwpGrEr0cs9roGY5ij5XiFZJJOW6aBi7r2RcBtszskWZPkyK69lpmnW2f/uyHDuA84JclrkxzBzAXR2Xd0Buu8ALizuitOy2TRmmadL5/PzDntuEwD7+vuKJwJ7B84HR2LUb4e0Y2z4OsajHiOllJT0xyN4gr0Eq8IHw98F3gM+A5wXLd+Crima78N2MHMHYcdwAeWoY7zmLka/ThwZbfu08D5XfulwD8Du4B/B04ewdwsVtPfAju7ebkL+P1lrOUGYC/wv8ycq38A+BDwoW57gC93te4ApkYwP4vVdNnA/NwDvG0Za/kToIAHge3d57xxztESazrkOfLxdElNJum0RdIKYnhIamJ4SGpieEhqYnhIamJ4SGpieEhq8v9GUQ+vkdfP+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randint(255, (1, 3, 3, 3)).float()\n",
    "show_img(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2 = rconv.reflect(x)\n",
    "show_img(x2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got InvalidArgumentError(Remove `padding_mode` from arguments.).\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "assert nn.Conv2d.__doc__ in ReflectionPaddedConv2d.__doc__\n",
    "\n",
    "with assert_raises(InvalidArgumentError):\n",
    "    ReflectionPaddedConv2d(3, 3, padding_mode='zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dropin(nn.Module):\n",
    "    \"\"\"Additive dropout. This injects small amounts of noise into a model\n",
    "    in the form of randomly generated floats from a zero-centered\n",
    "    gaussian distribution (variance can be adjusted). This does nothing \n",
    "    in eval mode. Unlike Dropout, this does not scale weights during \n",
    "    training since it does not bias them in any direction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, scale=.5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        scale: float\n",
    "            Used to scale the magnitude of the random noise. Keep in mind \n",
    "            that the scalar term is square rooted, so the relationship\n",
    "            will not be linear. Relatively large values (e.g. 1.0) will have\n",
    "            a stronger regularizing effect, while small values (e.g. 0.1)\n",
    "            will have a slight regularizing effect. There is no max value\n",
    "            enforced, so it's up to the user to select a reasonable value.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.scale = scale\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.training:\n",
    "            return x\n",
    "        \n",
    "        # Storing noise allows us to run diagnostics.\n",
    "        self.noise = torch.randn_like(x) * np.sqrt(self.scale / x.shape[-1])\n",
    "        return x + self.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.drop = Dropin()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.drop(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "x = torch.randn(8, 128, 128, 3)\n",
    "assert np.corrcoef(net(x).flatten(), x.flatten())[0][1] > .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "assert torch.eq(net(x), x).all()\n",
    "assert not net.drop.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_activation_stats(scale=1.0, trials=10_000):\n",
    "    act_stats = defaultdict(list)\n",
    "    noise_stats = defaultdict(list)\n",
    "    \n",
    "    drop = Dropin(scale)\n",
    "    for _ in range(trials):\n",
    "        x = torch.randn(3, 4, dtype=torch.float)\n",
    "        z = drop(x)\n",
    "        noise = drop.noise\n",
    "        noise_stats['mean'].append(noise.mean())\n",
    "        noise_stats['std'].append(noise.std())\n",
    "        noise_stats['act_corr'].append(\n",
    "            np.corrcoef(z.flatten(), noise.flatten())[0][1]\n",
    "        )\n",
    "        \n",
    "        act_stats['mean'].append(z.mean())\n",
    "        act_stats['std'].append(z.std())\n",
    "        act_stats['x_corr'].append(\n",
    "            np.corrcoef(z.flatten(), x.flatten())[0][1]\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(dict(\n",
    "        act={k: np.mean(v).round(4) for k, v in act_stats.items()}, \n",
    "        noise={k: np.mean(v).round(4) for k, v in noise_stats.items()}\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.8189</td>\n",
       "      <td>1.5192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.5324</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0141</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0921</td>\n",
       "      <td>0.4870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.8855</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.75\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0015</td>\n",
       "      <td>0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0633</td>\n",
       "      <td>0.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.9100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0558</td>\n",
       "      <td>0.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.9409</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0098</td>\n",
       "      <td>-0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0013</td>\n",
       "      <td>0.2461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.9667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>noise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0057</td>\n",
       "      <td>-0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.9969</td>\n",
       "      <td>0.1533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_corr</th>\n",
       "      <td>0.9868</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act_corr</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for scale in [10, 1, .75, .5, .25, .1]:\n",
    "    print('\\n', scale)\n",
    "    simulate_activation_stats(scale, 1_000).pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@add_docstring(nn.Embedding)\n",
    "def PaddedEmbedding(num_embeddings, embedding_dim, padding_idx=None, **kwargs):\n",
    "    \"\"\"Patched version of Fastai `embedding` that allows us to specify a row of\n",
    "    zeros for a padding token.\n",
    "    \"\"\"\n",
    "    emb = nn.Embedding(num_embeddings, embedding_dim, padding_idx, **kwargs)\n",
    "    with torch.no_grad():\n",
    "        trunc_normal_(emb.weight, std=.01)\n",
    "        if padding_idx is not None:\n",
    "            torch.zero_(emb.weight[0])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0145, -0.0067, -0.0038],\n",
       "        [-0.0176, -0.0179,  0.0010],\n",
       "        [-0.0042, -0.0020,  0.0027]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PaddedEmbedding(4, 3, 0).weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BloomEmbedding(nn.Module):\n",
    "    \"\"\"Bloom Embedding layer for memory-efficient word representations.\n",
    "    Each word is encoded by a combination of rows of the embedding\n",
    "    matrix. The number of rows can therefore be far lower than the number\n",
    "    of words in our vocabulary while still providing unique representations.\n",
    "    The reduction in rows allows us to use memory in other ways: a larger\n",
    "    embedding dimension, more or larger layers after the embedding,\n",
    "    larger batch sizes, etc.\n",
    "    \n",
    "    Note that if hashing is done in the Dataset, we could use a simple\n",
    "    nn.EmbeddingBag to achieve the same thing. Many users have reported \n",
    "    poor performance with this layer though (especially on CPU, but in some\n",
    "    cases on GPU) so I stick with the standard Embedding. We also bake in\n",
    "    the truncated normal intialization provided by fastai, with a slight tweak\n",
    "    to allow a row for padding.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_emb=251, emb_dim=100, n_hashes=4, padding_idx=0,\n",
    "                 pre_hashed=False):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_emb: int\n",
    "            Number of rows to create in the embedding matrix. A prime\n",
    "            number is recommended. Lower numbers will be more \n",
    "            memory-efficient but increase the chances of collisions.\n",
    "        emb_dim: int\n",
    "            Size of each embedding. If emb_dim=100, each word will\n",
    "            be represented by a 100-dimensional vector.\n",
    "        n_hashes: int\n",
    "            This determines the number of hashes that will be taken\n",
    "            for each word index, and as a result, the number of rows\n",
    "            that will be summed to create each unique representation.\n",
    "            The higher the number, the lower the chances of a collision.\n",
    "        padding_idx: int or None\n",
    "            If an integer is provided, this will set aside the corresponding\n",
    "            row in the embedding matrix as a vector of zeros. If None, no\n",
    "            padding vector will be allocated.\n",
    "        pre_hashed: bool\n",
    "            Pass in True if the input tensor will already be hashed by the time \n",
    "            it enters this layer (you may prefer pre-compute the hashes in the\n",
    "            Dataset to save computation time during training). In this\n",
    "            scenario, the layer is a simple embedding bag with mode \"sum\". \n",
    "            Pass in False if the inputs will be word indices that have not yet\n",
    "            been hashed. In this case, hashing will be done inside the \n",
    "            `forward` call.\n",
    "            \n",
    "        Suggested values for a vocab size of ~30,000:\n",
    "        \n",
    "        | n_emb | n_hashes | unique combos |\n",
    "        |-------|----------|---------------|\n",
    "        | 127   | 5        | 29,998        |\n",
    "        | 251   | 4        | 29,996        |\n",
    "        | 997   | 3        | 29,997        |\n",
    "        | 5,003 | 2        | 29,969        |\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_emb = n_emb\n",
    "        self.emb = PaddedEmbedding(n_emb, emb_dim, padding_idx=padding_idx)\n",
    "        self.n_hashes = n_hashes\n",
    "        self.pad_idx = padding_idx\n",
    "        self.pre_hashed = pre_hashed\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.LongTensor\n",
    "            Input tensor of word indices (bs x seq_len) if pre_hashed is False.\n",
    "            Hashed indices (bs x seq_len x n_hashes) if pre_hashed is False.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.FloatTensor: Words encoded with combination of embeddings.\n",
    "            (bs x seq_len x emb_dim)\n",
    "        \"\"\"\n",
    "        if not self.pre_hashed:\n",
    "            # (bs, seq_len) -> hash -> (bs, seq_len, n_hashes)\n",
    "            hashed = probabilistic_hash_tensor(x, \n",
    "                                               self.n_emb,\n",
    "                                               self.n_hashes,\n",
    "                                               self.pad_idx)\n",
    "        # (bs, seq_len, n_hashes, emb_dim) -> sum -> (bs, seq_len, emb_dim)\n",
    "        return self.emb(hashed).sum(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, labels, seq_len):\n",
    "        x = [s.split(' ') for s in sentences]\n",
    "        self.w2i = self.make_w2i(x)\n",
    "        self.seq_len = seq_len\n",
    "        self.x = self.encode(x)\n",
    "        self.y = torch.tensor(labels)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def make_w2i(self, tok_rows):\n",
    "        return {k: i for i, (k, v) in \n",
    "                enumerate(Counter(chain(*tok_rows)).most_common(), 1)}\n",
    "    \n",
    "    def encode(self, tok_rows):\n",
    "        enc = np.zeros((len(tok_rows), self.seq_len), dtype=int)\n",
    "        for i, row in enumerate(tok_rows):\n",
    "            trunc = [self.w2i.get(w, 0) for w in row[:self.seq_len]]\n",
    "            enc[i, :len(trunc)] = trunc\n",
    "        return torch.tensor(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    'I walked to the store so I hope it is not closed.',\n",
    "    'The theater is closed today and the sky is grey.',\n",
    "    'His dog is brown while hers is grey.'\n",
    "]\n",
    "labels = [0, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4]), tensor(1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Data(sents, labels, 10)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]), tensor([0, 1, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=3)\n",
    "x, y = next(iter(dl))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]), tensor([0, 1, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0054, -0.0142, -0.0027, -0.0052],\n",
       "        [ 0.0097,  0.0003, -0.0098, -0.0082],\n",
       "        [ 0.0049,  0.0084,  0.0028, -0.0158],\n",
       "        [ 0.0035,  0.0056, -0.0106, -0.0135],\n",
       "        [ 0.0088, -0.0058,  0.0105, -0.0072],\n",
       "        [-0.0003, -0.0004, -0.0012,  0.0142],\n",
       "        [ 0.0089, -0.0114, -0.0001,  0.0037],\n",
       "        [ 0.0089,  0.0007,  0.0076,  0.0034],\n",
       "        [-0.0039,  0.0119,  0.0090, -0.0077],\n",
       "        [ 0.0040, -0.0154,  0.0072, -0.0024]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be = BloomEmbedding(11, 4)\n",
    "be.emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (bs x seq_len) -> (bs -> seq_len -> emb_size)\n",
    "y = be(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0363, -0.0098,  0.0052,  0.0023],\n",
       "        [ 0.0337, -0.0130, -0.0147, -0.0183],\n",
       "        [ 0.0075, -0.0316,  0.0120,  0.0236],\n",
       "        [ 0.0304, -0.0328,  0.0388, -0.0240],\n",
       "        [ 0.0144,  0.0004, -0.0022,  0.0019],\n",
       "        [ 0.0084,  0.0117,  0.0089, -0.0284],\n",
       "        [ 0.0363, -0.0098,  0.0052,  0.0023],\n",
       "        [ 0.0177, -0.0087,  0.0344, -0.0139],\n",
       "        [ 0.0272, -0.0108, -0.0036,  0.0130],\n",
       "        [ 0.0035, -0.0162,  0.0048,  0.0260]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show by step how to get from x to y. This is meant to demonstrate the basic mechanism, not to show how PyTorch actually implements this under the hood. Let's look at a single row of x, corresponding to 1 sentence where each word is mapped to its index in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we hash each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 2, 7, 8],\n",
       " [2, 8, 1, 2],\n",
       " [6, 6, 10, 10],\n",
       " [10, 5, 5, 5],\n",
       " [6, 9, 7, 2],\n",
       " [5, 9, 4, 0],\n",
       " [8, 2, 7, 8],\n",
       " [5, 10, 8, 9],\n",
       " [7, 8, 6, 2],\n",
       " [6, 10, 6, 0]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed = [probabilistic_hash_item(i.item(), 11, int, 4) for i in x[0]]\n",
    "hashed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use each row of hashed integers to index into the embedding weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0089,  0.0007,  0.0076,  0.0034],\n",
       "         [ 0.0097,  0.0003, -0.0098, -0.0082],\n",
       "         [ 0.0089, -0.0114, -0.0001,  0.0037],\n",
       "         [ 0.0089,  0.0007,  0.0076,  0.0034]],\n",
       "\n",
       "        [[ 0.0097,  0.0003, -0.0098, -0.0082],\n",
       "         [ 0.0089,  0.0007,  0.0076,  0.0034],\n",
       "         [ 0.0054, -0.0142, -0.0027, -0.0052],\n",
       "         [ 0.0097,  0.0003, -0.0098, -0.0082]]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = []\n",
    "for row in hashed:\n",
    "    row_out = be.emb.weight[row]\n",
    "    output.append(row_out)\n",
    "output = torch.stack(output)\n",
    "print(output.shape)\n",
    "output[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we sum up the embedding rows. Above, each word is represented by four rows of the embedding matrix. After summing, we get a single vector for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0363, -0.0098,  0.0052,  0.0023],\n",
       "        [ 0.0337, -0.0130, -0.0147, -0.0183],\n",
       "        [ 0.0075, -0.0316,  0.0120,  0.0236],\n",
       "        [ 0.0304, -0.0328,  0.0388, -0.0240],\n",
       "        [ 0.0144,  0.0004, -0.0022,  0.0019],\n",
       "        [ 0.0084,  0.0117,  0.0089, -0.0284],\n",
       "        [ 0.0363, -0.0098,  0.0052,  0.0023],\n",
       "        [ 0.0177, -0.0087,  0.0344, -0.0139],\n",
       "        [ 0.0272, -0.0108, -0.0036,  0.0130],\n",
       "        [ 0.0035, -0.0162,  0.0048,  0.0260]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = output.sum(-2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice that the values now match the output of our embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.isclose(output, y[0]).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
