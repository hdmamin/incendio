{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "\n",
    "> Custom activations, layers, and layer blocks are contained in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in notebook but not needed in package.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class GRelu(nn.Module):\n",
    "    \"\"\"Generic ReLU.\"\"\"\n",
    "\n",
    "    def __init__(self, leak=0.0, max=float('inf'), sub=0.0):\n",
    "        super().__init__()\n",
    "        self.leak = leak\n",
    "        self.max = max\n",
    "        self.sub = sub\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Check which operations are necessary to save computation.\"\"\"\n",
    "        x = F.leaky_relu(x, self.leak) if self.leak else F.relu(x)\n",
    "        if self.sub:\n",
    "            x -= self.sub\n",
    "        if self.max:\n",
    "            x = torch.clamp(x, max=self.max)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'GReLU(leak={self.leak}, max={self.max}, sub={self.sub})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "JRelu = GRelu(leak=.1, sub=.4, max=6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Mish(nn.Module):\n",
    "    \"\"\"OOP form of mish activation.\n",
    "\n",
    "    Mish: A Self Regularized Non-Monotonic Neural Activation Function\n",
    "    https://arxiv.org/pdf/1908.08681v1.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def mish(x):\n",
    "    \"\"\"Functional form of mish activation.\n",
    "\n",
    "    Mish: A Self Regularized Non-Monotonic Neural Activation Function\n",
    "    https://arxiv.org/pdf/1908.08681v1.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor[float]\n",
    "        Input tensor.\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor[float]: Tensor of same shape as input x.\n",
    "    \"\"\"\n",
    "    return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activations(z, a, mode='scatter', **kwargs):\n",
    "    \"\"\"Plot an input tensor and its corresponding activations.  Both tensors\n",
    "    will be flattened for plotting.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    z: tf.Tensor\n",
    "        Tensor containing values to plot on the x axis (we can often think of\n",
    "        this as the output of a linear layer, where z=f(x) and a=mish(z)).\n",
    "    a: tf.Tensor\n",
    "        Tensor containing values to plot on y axis.\n",
    "    mode: str\n",
    "        'scatter' for scatter plot or 'plot' for line plot.\n",
    "    kwargs: Values to be passed to the matplotlib plotting function, such as \n",
    "        's' when in 'scatter' mode or 'lw' in 'plot' mode.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt_func = getattr(plt, mode)\n",
    "    kwargs = kwargs or {}\n",
    "    if mode == 'scatter' and not kwargs:\n",
    "        kwargs = {'s': .75}\n",
    "    plt_func(z.numpy().flatten(), a.numpy().flatten(), **kwargs)\n",
    "    plt.axvline(0, lw=.5, alpha=.5)\n",
    "    plt.axhline(0, lw=.5, alpha=.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(-5, 5, .05)\n",
    "a = mish(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_activations(x, a, 'plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"Create a convolutional block optionally followed by a batch norm layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c_in, c_out, kernel_size=3, norm=True, activation=JRelu,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        -----------\n",
    "        c_in: int\n",
    "            # of input channels.\n",
    "        c_out: int\n",
    "            # of output channels.\n",
    "        kernel_size: int\n",
    "            Size of kernel in conv2d layer. An integer argument will be used\n",
    "            as both the height and width.\n",
    "        norm: bool\n",
    "            If True, include a batch norm layer after the conv layer. If False,\n",
    "            no norm layer will be used. Note that batch norm has learnable\n",
    "            affine parameters which remove the need for a bias in the preceding\n",
    "            conv layer. When batch norm is not used, however, the conv layer\n",
    "            will include a bias term.\n",
    "        activation: nn.Module\n",
    "            Activation function to use at the end of the convolutional block.\n",
    "            (In some cases such as our ResBlock implementation, we pass in None\n",
    "            so that an extra addition can be performed before the final\n",
    "            activation.) Do not use the functional form here as it will be\n",
    "            added to a sequential object.\n",
    "        kwargs: any\n",
    "            Additional keyword args are passed to Conv2d. Useful kwargs include\n",
    "            stride, and padding (see pytorch docs for nn.Conv2d).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.norm = norm\n",
    "        layers = [nn.Conv2d(c_in, c_out, kernel_size, bias=not norm, **kwargs)]\n",
    "        if norm:\n",
    "            layers.append(nn.BatchNorm2d(c_out))\n",
    "        if activation is not None:\n",
    "            layers.append(activation)\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvBlock(\n",
       "  (block): Sequential(\n",
       "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv = ConvBlock(3, 5, norm=False)\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 2, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 4, 4)\n",
    "conv(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ResBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, activation=JRelu, f=3, stride=1, pad=1,\n",
    "                 skip_size=2, norm=True):\n",
    "        \"\"\"Residual block to be used in CycleGenerator. Note that f, stride,\n",
    "        and pad must be selected such that the height and width of the input\n",
    "        remain the same.\n",
    "\n",
    "        Parameters\n",
    "        -----------\n",
    "        c_in: int\n",
    "            # of input channels.\n",
    "        activation: callable\n",
    "            Activation function to use.\n",
    "        f: int\n",
    "            Size of filter (f x f) used in convolution. Default 3.\n",
    "        stride: int\n",
    "            # of pixels the filter moves between each convolution. Default 1.\n",
    "        pad: int\n",
    "            Pixel padding around the input. Default 1.\n",
    "        skip_size: int\n",
    "            Number of conv blocks inside the skip connection (default 2).\n",
    "            ResNet paper notes that skipping a single layer did not show\n",
    "            noticeable improvements.\n",
    "        norm: bool\n",
    "            Specifies whether to include a batch norm layer after each conv\n",
    "            layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.skip_size = skip_size\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvBlock(c_in, c_in, norm=norm, activation=None, kernel_size=f,\n",
    "                      stride=stride, padding=pad)\n",
    "            for i in range(skip_size)\n",
    "        ])\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x_out = layer(x_out)\n",
    "\n",
    "            # Final activation must be applied after addition.\n",
    "            if i != self.skip_size - 1:\n",
    "                x_out = self.activation(x_out)\n",
    "\n",
    "        return self.activation(x + x_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ResBlock(4, norm=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
