{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import gc\n",
    "from operator import add\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from htools import InvalidArgumentError\n",
    "from incendio.core import BaseModel\n",
    "from incendio.layers import JRelu, GRelu, mish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting\n",
    "\n",
    "Maybe skip connections could be useful for tabular data? Apparently usually not useful, maybe if network is very deep. Similar idea may be used here: https://arxiv.org/abs/1708.05123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DenseLinear(BaseModel):\n",
    "    \n",
    "#     def __init__(self, x_dim, hidden_dim, activation=mish, skip_size=2):\n",
    "#         super().__init__()\n",
    "#         assert hidden_dim >= 2 ** (skip_size-1), ('Increase hidden dimension '\n",
    "#                                                   'or decrease skip size.')\n",
    "        \n",
    "#         self.activation = activation\n",
    "#         self.skip_size = skip_size\n",
    "#         self.layers = nn.ModuleList([nn.Linear(x_dim, hidden_dim)])\n",
    "        \n",
    "#         prev_dim = hidden_dim\n",
    "#         for i in range(1, skip_size):\n",
    "#             new_dim = prev_dim // 2\n",
    "#             new_layer = nn.Linear(prev_dim, new_dim)\n",
    "#             self.layers.append(new_layer)\n",
    "#             prev_dim = new_dim\n",
    "            \n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "#         for i, layer in enumerate(self.layers):\n",
    "#             out = layer(out)\n",
    "#             if i != self.skip_size - 1:\n",
    "#                 out = self.activation(out)\n",
    "#         return self.activation(torch.cat((x, out), dim=1))\n",
    "\n",
    "class DenseLinear(BaseModel):\n",
    "    \n",
    "    def __init__(self, x_dim, layer_dims, activation=mish):\n",
    "        super().__init__()\n",
    "        self.skip_size = len(layer_dims)\n",
    "        self.activation = activation\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for d_in, d_out\n",
    "                                     in zip([x_dim]+list(layer_dims), layer_dims)])\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            out = layer(out)\n",
    "            if i < self.skip_size: out = self.activation(out)\n",
    "        return self.activation(torch.cat((x, out), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(*args, dim=-1):\n",
    "    return torch.cat(args, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearSkipBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_dim, layer_dims, op, activation=mish):\n",
    "        super().__init__()\n",
    "        self.skip_size = len(layer_dims)\n",
    "        self.activation = activation\n",
    "        self.layers = nn.ModuleList([nn.Linear(d_in, d_out) for d_in, d_out\n",
    "                                     in zip([x_dim]+list(layer_dims), layer_dims)])\n",
    "        self.op = op\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for i, layer in enumerate(self.layers, 1):\n",
    "            out = layer(out)\n",
    "            if i < self.skip_size: out = self.activation(out)\n",
    "        print(self.op(x, out))\n",
    "        return self.activation(self.op(x, out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResLinear(BaseModel):\n",
    "    \n",
    "#     def __init__(self, x_dim, hidden_dims, activation=JRelu):\n",
    "#         super().__init__()\n",
    "#         self.skip_size = len(hidden_dims)\n",
    "#         self.activation = activation\n",
    "#         self.layers = nn.ModuleList([\n",
    "#             nn.Linear(in_dim, out_dim) for in_dim, out_dim \n",
    "#             in zip([x_dim] + list(hidden_dims), list(hidden_dims) + [x_dim])\n",
    "#         ])\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         out = x\n",
    "#         for i, layer in enumerate(self.layers):\n",
    "#             out = layer(out)\n",
    "#             if i != self.skip_size - 1:\n",
    "#                 out = self.activation(out)\n",
    "#         return self.activation(x + out)\n",
    "\n",
    "class LinearResBlock(LinearSkipBlock):\n",
    "    \n",
    "    def __init__(self, x_dim, hidden_dims, activation=mish):\n",
    "        if hidden_dims[-1] != x_dim:\n",
    "            raise InvalidArgumentError(\n",
    "                'Last hidden dimension must match input dimension.'\n",
    "            )\n",
    "        super().__init__(x_dim, hidden_dims, add, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDenseBlock(LinearSkipBlock):\n",
    "    \n",
    "    def __init__(self, x_dim, hidden_dims, activation=mish):\n",
    "        super().__init__(x_dim, hidden_dims, concat, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3]],\n",
       "\n",
       "        [[5]],\n",
       "\n",
       "        [[1]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([3, 5, 1])\n",
    "i = [1]*2\n",
    "x.view(-1, *i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg(*args, weights):\n",
    "    weights = torch.tensor(weights)\n",
    "    total = weights.sum().float()\n",
    "    if total != 1: weights = weights / total\n",
    "    res = torch.stack(args)\n",
    "    weights_shape = [-1 if i == 0 else 1 for i, _ in enumerate(range(res.ndim))]\n",
    "    return torch.mean(res * weights.view(*weights_shape), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4.]) tensor([1., 1., 1., 1., 1.]) tensor([-0.9681,  0.8185,  0.4446,  0.6494,  1.6390])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(5).float()\n",
    "t2 = torch.ones(5).float()\n",
    "t3 = torch.randn(5).float()\n",
    "print(t1, t2, t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.3333,  0.6667,  1.0000,  1.3333],\n",
      "        [ 0.5556,  0.5556,  0.5556,  0.5556,  0.5556],\n",
      "        [-0.1076,  0.0909,  0.0494,  0.0722,  0.1821]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1493, 0.3266, 0.4239, 0.5426, 0.6903])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg(t1, t2,  t3, weights=[3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[-0.8853, -0.8809],\n",
      "        [ 0.5187, -0.9115],\n",
      "        [-1.2926,  0.5497]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.arange(6).view(3, 2).float()\n",
    "t2 = torch.ones(3, 2).float()\n",
    "t3 = torch.randn(3, 2).float()\n",
    "print(t1, t2, t3, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.3333],\n",
      "         [ 0.6667,  1.0000],\n",
      "         [ 1.3333,  1.6667]],\n",
      "\n",
      "        [[ 0.5556,  0.5556],\n",
      "         [ 0.5556,  0.5556],\n",
      "         [ 0.5556,  0.5556]],\n",
      "\n",
      "        [[-0.0984, -0.0979],\n",
      "         [ 0.0576, -0.1013],\n",
      "         [-0.1436,  0.0611]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1524, 0.2637],\n",
       "        [0.4266, 0.4848],\n",
       "        [0.5818, 0.7611]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_avg(t1, t2,  t3, weights=[3, 5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[0.3333],\n",
    "        [0.5556],\n",
    "        [0.1111]]).shape\n",
    "# * torch.tensor([[[ 0.0000,  1.0000],\n",
    "#          [ 2.0000,  3.0000],\n",
    "#          [ 4.0000,  5.0000]],\n",
    "\n",
    "#         [[ 1.0000,  1.0000],\n",
    "#          [ 1.0000,  1.0000],\n",
    "#          [ 1.0000,  1.0000]],\n",
    "\n",
    "#         [[-1.5408, -0.7166],\n",
    "#          [ 0.6646,  0.2769],\n",
    "#          [-0.3888,  0.1351]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 0., 0., 0., 4.],\n",
       "        [4., 0., 3., 1., 1., 4.],\n",
       "        [2., 4., 0., 1., 3., 4.],\n",
       "        [2., 1., 0., 2., 0., 4.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "feature_dim = 6\n",
    "hidden_dim = 16\n",
    "\n",
    "model = LinearDenseBlock(feature_dim, [hidden_dim, 9, 3, 5])\n",
    "x = torch.randint(5, size=(bs, feature_dim)).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDenseBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=9, bias=True)\n",
       "    (2): Linear(in_features=9, out_features=3, bias=True)\n",
       "    (3): Linear(in_features=3, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0000e+00,  2.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          4.0000e+00, -1.7781e-01,  3.1595e-03,  2.1543e-01, -4.4647e-01,\n",
      "         -4.8824e-01],\n",
      "        [ 4.0000e+00,  0.0000e+00,  3.0000e+00,  1.0000e+00,  1.0000e+00,\n",
      "          4.0000e+00, -1.7555e-01, -3.0404e-03,  2.7364e-01, -3.9930e-01,\n",
      "         -4.9190e-01],\n",
      "        [ 2.0000e+00,  4.0000e+00,  0.0000e+00,  1.0000e+00,  3.0000e+00,\n",
      "          4.0000e+00, -2.3689e-01, -1.3044e-02,  2.6283e-01, -4.1826e-01,\n",
      "         -4.2047e-01],\n",
      "        [ 2.0000e+00,  1.0000e+00,  0.0000e+00,  2.0000e+00,  0.0000e+00,\n",
      "          4.0000e+00, -2.0205e-01, -2.1700e-03,  2.3462e-01, -4.3416e-01,\n",
      "         -4.6056e-01]], grad_fn=<CatBackward>)\n",
      "torch.Size([4, 11])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9440e+00,  1.9440e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          3.9974e+00, -9.6526e-02,  1.8989e-03,  1.4385e-01, -2.0443e-01,\n",
       "         -2.1730e-01],\n",
       "        [ 3.9974e+00,  0.0000e+00,  2.9865e+00,  8.6510e-01,  8.6510e-01,\n",
       "          3.9974e+00, -9.5423e-02, -1.8213e-03,  1.8756e-01, -1.8867e-01,\n",
       "         -2.1838e-01],\n",
       "        [ 1.9440e+00,  3.9974e+00,  0.0000e+00,  8.6510e-01,  2.9865e+00,\n",
       "          3.9974e+00, -1.2411e-01, -7.7718e-03,  1.7930e-01, -1.9516e-01,\n",
       "         -1.9591e-01],\n",
       "        [ 1.9440e+00,  8.6510e-01,  0.0000e+00,  1.9440e+00,  0.0000e+00,\n",
       "          3.9974e+00, -1.0811e-01, -1.3005e-03,  1.5804e-01, -2.0044e-01,\n",
       "         -2.0888e-01]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(x)\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((16, 6), True),\n",
       " ((16,), True),\n",
       " ((9, 16), True),\n",
       " ((9,), True),\n",
       " ((3, 9), True),\n",
       " ((3,), True),\n",
       " ((5, 3), True),\n",
       " ((5,), True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16, 6), (16,), (8, 16), (8,)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 0., 0., 1., 2., 2.],\n",
       "        [4., 0., 1., 0., 2., 3.],\n",
       "        [0., 3., 3., 0., 3., 1.],\n",
       "        [2., 0., 4., 4., 0., 4.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 4., 0., 4., 1., 3.],\n",
       "        [1., 0., 2., 0., 0., 1.],\n",
       "        [4., 0., 0., 3., 3., 3.],\n",
       "        [2., 0., 0., 0., 4., 3.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "feature_dim = 6\n",
    "hidden_dim = 16\n",
    "\n",
    "model = ResLinear(feature_dim, [hidden_dim, 12])\n",
    "x = torch.randint(5, size=(bs, feature_dim)).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResLinear(\n",
       "  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=12, bias=True)\n",
       "    (2): Linear(in_features=12, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 2., 4., 1., 3., 0.],\n",
       "        [4., 3., 4., 4., 0., 4.],\n",
       "        [4., 1., 0., 3., 2., 3.],\n",
       "        [1., 2., 1., 3., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "feature_dim = 6\n",
    "hidden_dim = 16\n",
    "\n",
    "model = LinearResBlock(feature_dim, [hidden_dim, hidden_dim//4])\n",
    "x = torch.randint(5, size=(bs, feature_dim)).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=6, out_features=16, bias=True)\n",
       "    (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "    (2): Linear(in_features=4, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.1386,  1.9666,  3.6655,  0.9114,  3.2314, -0.0582],\n",
      "        [ 4.0349,  3.1004,  3.5271,  3.9476,  0.2363,  3.9812],\n",
      "        [ 4.1243,  1.1191, -0.3778,  2.7918,  2.3451,  2.6615],\n",
      "        [ 1.1321,  2.1452,  0.5129,  2.9463,  0.3553,  0.8902]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 2., 3., 1., 0., 0.],\n",
      "        [2., 2., 3., 0., 4., 4.],\n",
      "        [4., 0., 1., 2., 2., 0.],\n",
      "        [2., 0., 1., 0., 0., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearResBlock(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "feature_dim = 6\n",
    "hidden_dim = 16\n",
    "\n",
    "model = LinearResBlock(feature_dim, [feature_dim])\n",
    "x = torch.randint(5, size=(bs, feature_dim)).float()\n",
    "print(x)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.5540,  1.9176,  3.6411,  0.9371, -1.8513, -1.2901],\n",
      "        [ 3.8365,  1.4948,  1.5441, -1.9474,  2.3734,  2.9981],\n",
      "        [ 4.3015,  0.4406, -0.1710,  2.4975,  0.8048, -0.8525],\n",
      "        [ 2.2441,  1.1571,  0.2686, -0.5091, -0.8571,  1.4604]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissecting model components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedModel(BaseModel):\n",
    "    \n",
    "    def __init__(self, c_in, hidden_dims):\n",
    "        super().__init__(locals())\n",
    "        self.fc = nn.Linear(c_in, hidden_dims[0])\n",
    "        self.relu = nn.ReLU()\n",
    "        linears = [nn.Linear(d0, d1) for d0, d1 in zip(hidden_dims, \n",
    "                                                       hidden_dims[1:])]\n",
    "        linears = list(zip(linears, [nn.LeakyReLU() \n",
    "                                     for i in range(len(linears))]))\n",
    "        self.seq = nn.Sequential(*[arg for pair in linears for arg in pair])\n",
    "        self.mod = nn.ModuleList([nn.MaxPool1d(3), \n",
    "                                  nn.Linear(hidden_dims[-1]//3, 3)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc(x))\n",
    "        x = self.seq(x).unsqueeze(1)\n",
    "        print(x)\n",
    "        for layer in self.mod:\n",
    "            x = layer(x)\n",
    "            print(x)\n",
    "            if 'Linear' in str(type(layer)):\n",
    "                x = F.softmax(x, dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 5., 2., 5., 9., 2.],\n",
      "        [9., 0., 6., 3., 1., 3.],\n",
      "        [2., 3., 9., 1., 2., 0.],\n",
      "        [3., 3., 5., 9., 8., 5.]])\n",
      "tensor([[[ 6.4326e-02,  3.1435e-02, -2.5885e-03,  3.9018e-01, -9.5811e-04,\n",
      "           3.1741e-01]],\n",
      "\n",
      "        [[-2.4429e-03,  5.3331e-02, -2.8642e-03,  5.5245e-01, -1.1792e-03,\n",
      "           3.9474e-01]],\n",
      "\n",
      "        [[-5.9604e-04,  1.5087e-01, -2.1209e-03,  3.9323e-01, -1.7153e-03,\n",
      "           2.8635e-01]],\n",
      "\n",
      "        [[-4.7646e-04,  9.2174e-02, -2.9102e-03,  4.3538e-01, -7.5166e-04,\n",
      "           3.6905e-01]]], grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[[0.0643, 0.3902]],\n",
      "\n",
      "        [[0.0533, 0.5525]],\n",
      "\n",
      "        [[0.1509, 0.3932]],\n",
      "\n",
      "        [[0.0922, 0.4354]]], grad_fn=<SqueezeBackward1>)\n",
      "tensor([[[-0.5289,  0.7264,  0.1837]],\n",
      "\n",
      "        [[-0.5338,  0.7737,  0.1986]],\n",
      "\n",
      "        [[-0.5653,  0.7254,  0.2313]],\n",
      "\n",
      "        [[-0.5432,  0.7389,  0.2047]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1527, 0.5359, 0.3114]],\n",
       "\n",
       "        [[0.1476, 0.5455, 0.3069]],\n",
       "\n",
       "        [[0.1459, 0.5304, 0.3236]],\n",
       "\n",
       "        [[0.1489, 0.5366, 0.3145]]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(10, (4, 6)).float()\n",
    "print(x)\n",
    "\n",
    "mod = NestedModel(6, [12, 10, 8, 6])\n",
    "mod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NestedModel(\n",
       "  (fc): Linear(in_features=6, out_features=12, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (mod): ModuleList(\n",
       "    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=6, out_features=12, bias=True),\n",
       " ReLU(),\n",
       " Linear(in_features=12, out_features=10, bias=True),\n",
       " LeakyReLU(negative_slope=0.01),\n",
       " Linear(in_features=10, out_features=8, bias=True),\n",
       " LeakyReLU(negative_slope=0.01),\n",
       " Linear(in_features=8, out_features=6, bias=True),\n",
       " LeakyReLU(negative_slope=0.01),\n",
       " MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False),\n",
       " Linear(in_features=2, out_features=3, bias=True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gets list of all layers, extracting them from within modules and \n",
    "# sequentials. Don't think we typically need to do this though. \n",
    "layers = []\n",
    "for c in mod.children():\n",
    "    children = list(c.children())\n",
    "    if not children:\n",
    "        layers.append(c)\n",
    "    else:\n",
    "        layers.extend(children)\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(torch.Size([12, 6]), True), (torch.Size([12]), True)]\n",
      "[]\n",
      "[(torch.Size([10, 12]), True), (torch.Size([10]), True), (torch.Size([8, 10]), True), (torch.Size([8]), True), (torch.Size([6, 8]), True), (torch.Size([6]), True)]\n",
      "[(torch.Size([3, 2]), True), (torch.Size([3]), True)]\n"
     ]
    }
   ],
   "source": [
    "for c in mod.children():\n",
    "    print([(p.shape, p.requires_grad) for p in c.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(torch.Size([12, 6]), True),\n",
       " (torch.Size([12]), True),\n",
       " (torch.Size([10, 12]), True),\n",
       " (torch.Size([10]), True),\n",
       " (torch.Size([8, 10]), True),\n",
       " (torch.Size([8]), True),\n",
       " (torch.Size([6, 8]), True),\n",
       " (torch.Size([6]), True),\n",
       " (torch.Size([3, 2]), True),\n",
       " (torch.Size([3]), True)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.parameters() seems to automatically iterate through each param in each\n",
    "# child, same as in the cell above. Recurse=False oddly returns empty list?\n",
    "[(p.shape, p.requires_grad) for p in mod.parameters(recurse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Linear(in_features=6, out_features=12, bias=True),\n",
      " ReLU(),\n",
      " Sequential(\n",
      "  (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=8, out_features=6, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "),\n",
      " ModuleList(\n",
      "  (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (1): Linear(in_features=2, out_features=3, bias=True)\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "pprint(list(mod.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NestedModel(\n",
      "  (fc): Linear(in_features=6, out_features=12, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (seq): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=10, out_features=8, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Linear(in_features=8, out_features=6, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (mod): ModuleList(\n",
      "    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Linear(in_features=2, out_features=3, bias=True)\n",
      "  )\n",
      "),\n",
      " Linear(in_features=6, out_features=12, bias=True),\n",
      " ReLU(),\n",
      " Sequential(\n",
      "  (0): Linear(in_features=12, out_features=10, bias=True)\n",
      "  (1): LeakyReLU(negative_slope=0.01)\n",
      "  (2): Linear(in_features=10, out_features=8, bias=True)\n",
      "  (3): LeakyReLU(negative_slope=0.01)\n",
      "  (4): Linear(in_features=8, out_features=6, bias=True)\n",
      "  (5): LeakyReLU(negative_slope=0.01)\n",
      "),\n",
      " Linear(in_features=12, out_features=10, bias=True),\n",
      " LeakyReLU(negative_slope=0.01),\n",
      " Linear(in_features=10, out_features=8, bias=True),\n",
      " LeakyReLU(negative_slope=0.01),\n",
      " Linear(in_features=8, out_features=6, bias=True),\n",
      " LeakyReLU(negative_slope=0.01),\n",
      " ModuleList(\n",
      "  (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "  (1): Linear(in_features=2, out_features=3, bias=True)\n",
      "),\n",
      " MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False),\n",
      " Linear(in_features=2, out_features=3, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "# Seems to start at high level and then dive deeper into model. So first item\n",
    "# is whole model; then we get single layers, sequentials, and module lists; \n",
    "# then linear layers in the sequentials and module lists.\n",
    "# Not sure when this would be useful.\n",
    "pprint(list(mod.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: Parameter containing:\n",
      "tensor([[ 0.0099,  0.0274, -0.3193,  0.0329,  0.0444, -0.0355],\n",
      "        [-0.1402,  0.0693, -0.2843,  0.1135,  0.2485, -0.3240],\n",
      "        [ 0.3001,  0.2224,  0.3611, -0.2890, -0.1202,  0.2756],\n",
      "        [ 0.2442, -0.2935,  0.3827, -0.1233,  0.0305,  0.3249],\n",
      "        [-0.0148, -0.3202, -0.2059, -0.3465,  0.3627,  0.0037],\n",
      "        [ 0.2162, -0.2803, -0.0667, -0.1019,  0.2888,  0.1954],\n",
      "        [-0.1414,  0.0042, -0.2206,  0.3683, -0.1271,  0.3424],\n",
      "        [ 0.3351, -0.0391, -0.0489,  0.0146,  0.3899, -0.1330],\n",
      "        [ 0.1441,  0.3223, -0.2437,  0.2658, -0.3622, -0.2808],\n",
      "        [-0.2277,  0.2159,  0.1413,  0.0822, -0.2127, -0.3655],\n",
      "        [ 0.1330, -0.0927, -0.1883,  0.1051,  0.2737, -0.3455],\n",
      "        [-0.3727, -0.3064,  0.1242,  0.2320,  0.1606, -0.3888]],\n",
      "       requires_grad=True),\n",
      " 1: Parameter containing:\n",
      "tensor([-0.3684, -0.1282, -0.3694, -0.3890, -0.1481, -0.0204, -0.0075, -0.3795,\n",
      "         0.0747, -0.3468, -0.3417,  0.3524], requires_grad=True),\n",
      " 2: Parameter containing:\n",
      "tensor([[ 0.1218, -0.0761, -0.0120,  0.0730,  0.2812,  0.2723, -0.2831,  0.0307,\n",
      "          0.1458,  0.0535,  0.1407,  0.0326],\n",
      "        [ 0.0956, -0.0056, -0.2243,  0.2006, -0.0331,  0.0396,  0.0297, -0.1867,\n",
      "          0.0730,  0.0936,  0.2092, -0.0216],\n",
      "        [ 0.1340,  0.0692,  0.0893,  0.2082, -0.1712,  0.0070,  0.1338,  0.0725,\n",
      "          0.0661, -0.1325, -0.2492,  0.2249],\n",
      "        [ 0.2326, -0.0943,  0.0143,  0.0548, -0.1819, -0.2451, -0.0165, -0.2134,\n",
      "         -0.0264, -0.1255,  0.1310, -0.1273],\n",
      "        [ 0.1956, -0.0349,  0.2513,  0.2321, -0.0313,  0.0090,  0.1948,  0.1912,\n",
      "          0.1067, -0.1999,  0.1750,  0.1220],\n",
      "        [-0.1931, -0.2380,  0.1895,  0.0183,  0.2548,  0.0775, -0.1535, -0.2706,\n",
      "          0.2450, -0.0042, -0.2272,  0.1963],\n",
      "        [-0.1117,  0.2865,  0.1624, -0.0923, -0.2090, -0.2283,  0.1598,  0.0226,\n",
      "          0.0706,  0.1944, -0.0590, -0.1806],\n",
      "        [ 0.1509,  0.2629, -0.0122,  0.2163,  0.1838, -0.1217,  0.1874,  0.1182,\n",
      "         -0.0430, -0.1105,  0.1791, -0.0754],\n",
      "        [ 0.0030, -0.2304, -0.0721,  0.1958,  0.2722, -0.1599, -0.2681, -0.2423,\n",
      "         -0.0797, -0.1292, -0.0545,  0.2021],\n",
      "        [ 0.1640, -0.0687,  0.1112, -0.2076, -0.1312, -0.2439,  0.2274, -0.2404,\n",
      "         -0.1419,  0.0797, -0.0663, -0.1577]], requires_grad=True),\n",
      " 3: Parameter containing:\n",
      "tensor([ 0.1346,  0.0102,  0.1094,  0.1869,  0.2584, -0.0750,  0.0970, -0.1234,\n",
      "         0.2273, -0.2064], requires_grad=True),\n",
      " 4: Parameter containing:\n",
      "tensor([[ 0.0136, -0.2747, -0.2321,  0.0125,  0.1407, -0.1759, -0.0683, -0.2617,\n",
      "         -0.2084,  0.2241],\n",
      "        [-0.0144,  0.3063,  0.2932,  0.2269, -0.2087, -0.0757, -0.0802, -0.2231,\n",
      "         -0.2876,  0.0129],\n",
      "        [-0.0723, -0.1356,  0.2138,  0.0837,  0.0761,  0.1815, -0.0679, -0.0009,\n",
      "         -0.3145, -0.0566],\n",
      "        [ 0.1749, -0.0709, -0.1534, -0.0685, -0.0100, -0.1924,  0.0904, -0.1376,\n",
      "          0.0298, -0.0786],\n",
      "        [-0.0408, -0.1029, -0.0200, -0.2492, -0.0109,  0.2911,  0.0210, -0.1113,\n",
      "          0.3098, -0.2203],\n",
      "        [ 0.0453, -0.2374,  0.2246,  0.3039,  0.0717,  0.2330, -0.3061,  0.0568,\n",
      "         -0.1814,  0.2802],\n",
      "        [-0.1517, -0.0314, -0.1753,  0.0360, -0.0018,  0.1814, -0.1370,  0.1212,\n",
      "         -0.0021,  0.0842],\n",
      "        [ 0.2843, -0.0906,  0.0303, -0.3052, -0.0215,  0.1676,  0.0957,  0.1913,\n",
      "          0.0906,  0.1857]], requires_grad=True),\n",
      " 5: Parameter containing:\n",
      "tensor([ 0.0237,  0.2515,  0.2972, -0.0931,  0.1398,  0.2505, -0.1615, -0.0918],\n",
      "       requires_grad=True),\n",
      " 6: Parameter containing:\n",
      "tensor([[-0.0911, -0.0017, -0.1301, -0.1094, -0.1342, -0.2672, -0.1154, -0.3215],\n",
      "        [-0.2693, -0.1723,  0.2728, -0.0590,  0.3465, -0.0345,  0.0120, -0.3030],\n",
      "        [ 0.1827,  0.3301,  0.3213, -0.3359,  0.2034, -0.3083, -0.2250,  0.1050],\n",
      "        [ 0.1521,  0.0442,  0.0285, -0.3250, -0.1369,  0.1280, -0.2510,  0.2786],\n",
      "        [ 0.0467, -0.1751,  0.1018,  0.1364, -0.2758, -0.0378,  0.3034, -0.1265],\n",
      "        [-0.2261, -0.2045,  0.0899, -0.0072, -0.2106,  0.0735, -0.0334, -0.0052]],\n",
      "       requires_grad=True),\n",
      " 7: Parameter containing:\n",
      "tensor([ 0.2792, -0.0338, -0.3071,  0.2837, -0.1006,  0.2528],\n",
      "       requires_grad=True),\n",
      " 8: Parameter containing:\n",
      "tensor([[-0.4191, -0.0590],\n",
      "        [-0.0212,  0.2901],\n",
      "        [ 0.5463,  0.1291]], requires_grad=True),\n",
      " 9: Parameter containing:\n",
      "tensor([-0.4789,  0.6145,  0.0982], requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "# Also have named_parameters() which is almost identical, but each item is a\n",
    "# tuple of name_str and weights.\n",
    "pprint(dict(enumerate(mod.parameters())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NestedModel(\n",
       "  (fc): Linear(in_features=6, out_features=12, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (mod): ModuleList(\n",
       "    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze(x):\n",
    "    for p in x.parameters(): \n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((12, 6), True),\n",
      " ((12,), True),\n",
      " ((10, 12), True),\n",
      " ((10,), True),\n",
      " ((8, 10), True),\n",
      " ((8,), True),\n",
      " ((6, 8), True),\n",
      " ((6,), True),\n",
      " ((3, 2), True),\n",
      " ((3,), True)]\n",
      "\n",
      "[((12, 6), False),\n",
      " ((12,), False),\n",
      " ((10, 12), False),\n",
      " ((10,), False),\n",
      " ((8, 10), False),\n",
      " ((8,), False),\n",
      " ((6, 8), False),\n",
      " ((6,), False),\n",
      " ((3, 2), False),\n",
      " ((3,), False)]\n"
     ]
    }
   ],
   "source": [
    "for p in mod.parameters():\n",
    "    p.requires_grad = True\n",
    "    \n",
    "pprint(mod.trainable())\n",
    "mod.apply(freeze)\n",
    "print()\n",
    "pprint(mod.trainable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TYPE <class 'torch.nn.modules.linear.Linear'> [Parameter containing:\n",
      "tensor([[-0.3656,  0.0783,  0.0917, -0.2374,  0.0969,  0.3274],\n",
      "        [-0.3152,  0.1356,  0.3497, -0.0860, -0.3696, -0.2798],\n",
      "        [-0.2190, -0.2395,  0.3667, -0.0832,  0.3711,  0.3256],\n",
      "        [-0.3963,  0.1195,  0.0215,  0.1382, -0.1302,  0.3039],\n",
      "        [ 0.2511,  0.3575,  0.1222,  0.3794, -0.3783, -0.1140],\n",
      "        [ 0.1015,  0.1762,  0.2396,  0.0652,  0.2090,  0.0854],\n",
      "        [ 0.0255,  0.3808, -0.0934, -0.1005,  0.2855,  0.0401],\n",
      "        [-0.1884, -0.2917,  0.2465,  0.2880,  0.1670, -0.1933],\n",
      "        [-0.1640,  0.2293,  0.1941,  0.3935,  0.2173, -0.0118],\n",
      "        [ 0.3743, -0.3663, -0.2443,  0.1506, -0.2140,  0.3509],\n",
      "        [-0.3813,  0.3435, -0.3736,  0.2517,  0.1702,  0.2703],\n",
      "        [-0.0246, -0.2631, -0.0188,  0.2428, -0.2185, -0.2560]]), Parameter containing:\n",
      "tensor([-0.2712,  0.3741,  0.0636,  0.1773, -0.1028, -0.2567, -0.3787,  0.1860,\n",
      "        -0.0886, -0.1423,  0.1464, -0.0419])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.activation.ReLU'> [] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.linear.Linear'> [Parameter containing:\n",
      "tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,\n",
      "          0.2061, -0.0768,  0.2724, -0.1730],\n",
      "        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,\n",
      "          0.2709,  0.1090,  0.1634,  0.2299],\n",
      "        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,\n",
      "         -0.0259,  0.0829, -0.2655,  0.1763],\n",
      "        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,\n",
      "          0.1057, -0.0431,  0.0209,  0.0338],\n",
      "        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,\n",
      "         -0.1545,  0.0360, -0.0649,  0.1500],\n",
      "        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,\n",
      "          0.2144, -0.0529, -0.0212, -0.1253],\n",
      "        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,\n",
      "          0.0639, -0.1279,  0.1157,  0.1313],\n",
      "        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,\n",
      "         -0.0682,  0.2860, -0.2305,  0.0628],\n",
      "        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,\n",
      "          0.0679, -0.2104, -0.1249,  0.0936],\n",
      "        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,\n",
      "         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:\n",
      "tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,\n",
      "         0.0292, -0.2681])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.activation.LeakyReLU'> [] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.linear.Linear'> [Parameter containing:\n",
      "tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,\n",
      "          0.1507, -0.0261],\n",
      "        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,\n",
      "         -0.1080, -0.1217],\n",
      "        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,\n",
      "         -0.2130,  0.0930],\n",
      "        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,\n",
      "         -0.2225,  0.0426],\n",
      "        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,\n",
      "         -0.2736, -0.1497],\n",
      "        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,\n",
      "          0.1581, -0.2330],\n",
      "        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,\n",
      "          0.0059,  0.0456],\n",
      "        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,\n",
      "          0.2920,  0.0589]]), Parameter containing:\n",
      "tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.activation.LeakyReLU'> [] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.linear.Linear'> [Parameter containing:\n",
      "tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],\n",
      "        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],\n",
      "        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],\n",
      "        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],\n",
      "        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],\n",
      "        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:\n",
      "tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.activation.LeakyReLU'> [] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.container.Sequential'> [Parameter containing:\n",
      "tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,\n",
      "          0.2061, -0.0768,  0.2724, -0.1730],\n",
      "        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,\n",
      "          0.2709,  0.1090,  0.1634,  0.2299],\n",
      "        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,\n",
      "         -0.0259,  0.0829, -0.2655,  0.1763],\n",
      "        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,\n",
      "          0.1057, -0.0431,  0.0209,  0.0338],\n",
      "        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,\n",
      "         -0.1545,  0.0360, -0.0649,  0.1500],\n",
      "        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,\n",
      "          0.2144, -0.0529, -0.0212, -0.1253],\n",
      "        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,\n",
      "          0.0639, -0.1279,  0.1157,  0.1313],\n",
      "        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,\n",
      "         -0.0682,  0.2860, -0.2305,  0.0628],\n",
      "        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,\n",
      "          0.0679, -0.2104, -0.1249,  0.0936],\n",
      "        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,\n",
      "         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:\n",
      "tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,\n",
      "         0.0292, -0.2681]), Parameter containing:\n",
      "tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,\n",
      "          0.1507, -0.0261],\n",
      "        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,\n",
      "         -0.1080, -0.1217],\n",
      "        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,\n",
      "         -0.2130,  0.0930],\n",
      "        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,\n",
      "         -0.2225,  0.0426],\n",
      "        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,\n",
      "         -0.2736, -0.1497],\n",
      "        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,\n",
      "          0.1581, -0.2330],\n",
      "        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,\n",
      "          0.0059,  0.0456],\n",
      "        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,\n",
      "          0.2920,  0.0589]]), Parameter containing:\n",
      "tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084]), Parameter containing:\n",
      "tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],\n",
      "        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],\n",
      "        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],\n",
      "        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],\n",
      "        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],\n",
      "        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:\n",
      "tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.pooling.MaxPool1d'> [] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.linear.Linear'> [Parameter containing:\n",
      "tensor([[-1.3405e-04,  6.5233e-01],\n",
      "        [-3.6495e-01,  1.0810e-01],\n",
      "        [-2.5539e-01, -4.3903e-01]]), Parameter containing:\n",
      "tensor([-0.3769,  0.5977, -0.0545])] \n",
      "\n",
      "TYPE <class 'torch.nn.modules.container.ModuleList'> [Parameter containing:\n",
      "tensor([[-1.3405e-04,  6.5233e-01],\n",
      "        [-3.6495e-01,  1.0810e-01],\n",
      "        [-2.5539e-01, -4.3903e-01]]), Parameter containing:\n",
      "tensor([-0.3769,  0.5977, -0.0545])] \n",
      "\n",
      "TYPE <class '__main__.NestedModel'> [Parameter containing:\n",
      "tensor([[-0.3656,  0.0783,  0.0917, -0.2374,  0.0969,  0.3274],\n",
      "        [-0.3152,  0.1356,  0.3497, -0.0860, -0.3696, -0.2798],\n",
      "        [-0.2190, -0.2395,  0.3667, -0.0832,  0.3711,  0.3256],\n",
      "        [-0.3963,  0.1195,  0.0215,  0.1382, -0.1302,  0.3039],\n",
      "        [ 0.2511,  0.3575,  0.1222,  0.3794, -0.3783, -0.1140],\n",
      "        [ 0.1015,  0.1762,  0.2396,  0.0652,  0.2090,  0.0854],\n",
      "        [ 0.0255,  0.3808, -0.0934, -0.1005,  0.2855,  0.0401],\n",
      "        [-0.1884, -0.2917,  0.2465,  0.2880,  0.1670, -0.1933],\n",
      "        [-0.1640,  0.2293,  0.1941,  0.3935,  0.2173, -0.0118],\n",
      "        [ 0.3743, -0.3663, -0.2443,  0.1506, -0.2140,  0.3509],\n",
      "        [-0.3813,  0.3435, -0.3736,  0.2517,  0.1702,  0.2703],\n",
      "        [-0.0246, -0.2631, -0.0188,  0.2428, -0.2185, -0.2560]]), Parameter containing:\n",
      "tensor([-0.2712,  0.3741,  0.0636,  0.1773, -0.1028, -0.2567, -0.3787,  0.1860,\n",
      "        -0.0886, -0.1423,  0.1464, -0.0419]), Parameter containing:\n",
      "tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,\n",
      "          0.2061, -0.0768,  0.2724, -0.1730],\n",
      "        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,\n",
      "          0.2709,  0.1090,  0.1634,  0.2299],\n",
      "        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,\n",
      "         -0.0259,  0.0829, -0.2655,  0.1763],\n",
      "        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,\n",
      "          0.1057, -0.0431,  0.0209,  0.0338],\n",
      "        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,\n",
      "         -0.1545,  0.0360, -0.0649,  0.1500],\n",
      "        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,\n",
      "          0.2144, -0.0529, -0.0212, -0.1253],\n",
      "        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,\n",
      "          0.0639, -0.1279,  0.1157,  0.1313],\n",
      "        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,\n",
      "         -0.0682,  0.2860, -0.2305,  0.0628],\n",
      "        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,\n",
      "          0.0679, -0.2104, -0.1249,  0.0936],\n",
      "        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,\n",
      "         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:\n",
      "tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,\n",
      "         0.0292, -0.2681]), Parameter containing:\n",
      "tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,\n",
      "          0.1507, -0.0261],\n",
      "        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,\n",
      "         -0.1080, -0.1217],\n",
      "        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,\n",
      "         -0.2130,  0.0930],\n",
      "        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,\n",
      "         -0.2225,  0.0426],\n",
      "        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,\n",
      "         -0.2736, -0.1497],\n",
      "        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,\n",
      "          0.1581, -0.2330],\n",
      "        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,\n",
      "          0.0059,  0.0456],\n",
      "        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,\n",
      "          0.2920,  0.0589]]), Parameter containing:\n",
      "tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084]), Parameter containing:\n",
      "tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],\n",
      "        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],\n",
      "        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],\n",
      "        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],\n",
      "        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],\n",
      "        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:\n",
      "tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343]), Parameter containing:\n",
      "tensor([[-1.3405e-04,  6.5233e-01],\n",
      "        [-3.6495e-01,  1.0810e-01],\n",
      "        [-2.5539e-01, -4.3903e-01]]), Parameter containing:\n",
      "tensor([-0.3769,  0.5977, -0.0545])] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedModel(\n",
       "  (fc): Linear(in_features=6, out_features=12, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (seq): Sequential(\n",
       "    (0): Linear(in_features=12, out_features=10, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=10, out_features=8, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "    (4): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (mod): ModuleList(\n",
       "    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Linear(in_features=2, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uses outputs of model.children()\n",
    "mod.apply(lambda x: print('TYPE', type(x), list(x.parameters()), '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More freezing: module list of sequentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestedSequentials(BaseModel):\n",
    "    \n",
    "    def __init__(self, x_dim, dims):\n",
    "        super().__init__(locals())\n",
    "        self.enc = nn.Sequential(nn.Linear(x_dim, dims[0]),\n",
    "                                 nn.LeakyReLU(),\n",
    "                                 nn.Linear(dims[0], dims[1]),\n",
    "                                 nn.LeakyReLU())\n",
    "        self.trans = nn.Sequential(nn.MaxPool1d(3),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(dims[1]//3, 4),\n",
    "                                   nn.ReLU())\n",
    "        self.dec = nn.Sequential(nn.Linear(4, 3),\n",
    "                                 nn.Softmax(-1))\n",
    "        self.blocks = nn.ModuleList([self.enc, self.trans, self.dec])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            if i == 1:\n",
    "                x = x.unsqueeze(1)\n",
    "            x = block(x)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 2., 1., 2., 5.],\n",
      "        [1., 1., 4., 3., 0.],\n",
      "        [4., 5., 1., 1., 1.],\n",
      "        [0., 5., 1., 1., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NestedSequentials(\n",
       "  (enc): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=8, out_features=6, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (trans): Sequential(\n",
       "    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2, out_features=4, bias=True)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (dec): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=3, bias=True)\n",
       "    (1): Softmax(dim=-1)\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=5, out_features=8, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=8, out_features=6, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2, out_features=4, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=3, bias=True)\n",
       "      (1): Softmax(dim=-1)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 4\n",
    "x_dim = 5\n",
    "dims = [8, 6]\n",
    "\n",
    "x = torch.randint(6, size=(bs, x_dim), dtype=torch.float)\n",
    "print(x)\n",
    "nested = NestedSequentials(x_dim, dims)\n",
    "nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_dim': 5, 'dims': [8, 6]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested._init_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2564, 0.3047, 0.4389],\n",
       "        [0.2811, 0.2976, 0.4213],\n",
       "        [0.2688, 0.2922, 0.4390],\n",
       "        [0.2694, 0.3175, 0.4131]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.033, 0.282),\n",
       " (0.075, 0.213),\n",
       " (-0.004, 0.193),\n",
       " (0.078, 0.224),\n",
       " (0.178, 0.512),\n",
       " (0.041, 0.604),\n",
       " (-0.055, 0.213),\n",
       " (-0.19, 0.17)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested.weight_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 5]) False\n",
      "torch.Size([8, 5]) True \n",
      "\n",
      "torch.Size([8]) False\n",
      "torch.Size([8]) True \n",
      "\n",
      "torch.Size([6, 8]) False\n",
      "torch.Size([6, 8]) True \n",
      "\n",
      "torch.Size([6]) False\n",
      "torch.Size([6]) True \n",
      "\n",
      "torch.Size([4, 2]) False\n",
      "torch.Size([4, 2]) True \n",
      "\n",
      "torch.Size([4]) False\n",
      "torch.Size([4]) True \n",
      "\n",
      "torch.Size([3, 4]) False\n",
      "torch.Size([3, 4]) True \n",
      "\n",
      "torch.Size([3]) False\n",
      "torch.Size([3]) True \n",
      "\n",
      "--------------------\n",
      "torch.Size([8, 5]) False\n",
      "torch.Size([8]) False\n",
      "torch.Size([6, 8]) False\n",
      "torch.Size([6]) False\n",
      "torch.Size([4, 2]) False\n",
      "torch.Size([4]) False\n",
      "torch.Size([3, 4]) False\n",
      "torch.Size([3]) False\n"
     ]
    }
   ],
   "source": [
    "for p in nested.parameters():\n",
    "    p.requires_grad = False\n",
    "    print(p.shape, p.requires_grad)\n",
    "    p.requires_grad = True\n",
    "    print(p.shape, p.requires_grad, '\\n')\n",
    "\n",
    "print('-'*20)\n",
    "nested.apply(freeze)\n",
    "for p in nested.parameters():\n",
    "    print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved from epoch 11.\n"
     ]
    }
   ],
   "source": [
    "nested.save(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 weights loaded from data/model_11.pth.\n",
      "Model parameters: {'x_dim': 5, 'dims': [8, 6]}\n",
      "Currently in eval mode.\n"
     ]
    }
   ],
   "source": [
    "model = NestedSequentials.from_path('data/model_11.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2564, 0.3047, 0.4389],\n",
       "        [0.2811, 0.2976, 0.4213],\n",
       "        [0.2688, 0.2922, 0.4390],\n",
       "        [0.2694, 0.3175, 0.4131]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.033, 0.282),\n",
       " (0.075, 0.213),\n",
       " (-0.004, 0.193),\n",
       " (0.078, 0.224),\n",
       " (0.178, 0.512),\n",
       " (0.041, 0.604),\n",
       " (-0.055, 0.213),\n",
       " (-0.19, 0.17)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_lr_optimizer(groups, lrs, optimizer=torch.optim.Adam, **kwargs):\n",
    "    \"\"\"Get an optimizer that uses different learning rates for different layer\n",
    "    groups. Additional keyword arguments can be used to alter momentum and/or\n",
    "    weight decay, for example, but for the sake of simplicity these values \n",
    "    will be the same across layer groups. \n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    groups: nn.ModuleList\n",
    "        For this use case, the model should contain a ModuleList of layer \n",
    "        groups in the form of Sequential objects. This variable is then passed\n",
    "        in so each group can receive its own learning rate.\n",
    "    lrs: list[float]\n",
    "        A list containing the learning rates to use for each layer group. This \n",
    "        should be the same length as the number of layer groups in the model.\n",
    "        At times, we may want to use the same learning rate for all groups, \n",
    "        and can achieve this by passing in a list containing a single float.\n",
    "    optimizer: torch optimizer\n",
    "        The Torch optimizer to be created (Adam by default). \n",
    "        \n",
    "    Examples\n",
    "    ---------\n",
    "    optim = variable_lr_optimizer(model.groups, [3e-3, 3e-2, 1e-1])\n",
    "    \"\"\"\n",
    "    if len(lrs) == 1:\n",
    "        lrs *= len(groups)\n",
    "        \n",
    "    data = [{'params': group.parameters(), 'lr': lr} \n",
    "            for group, lr in zip(groups, lrs)]\n",
    "    return optimizer(data, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.5\n",
       "    weight_decay: 0.75\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.05\n",
       "    weight_decay: 0.75\n",
       "\n",
       "Parameter Group 2\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.005\n",
       "    weight_decay: 0.75\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lr_optimizer(nested.blocks, [.5, .05, .005], weight_decay=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, epoch, dir_='data', file_pre='model', verbose=True, **kwargs):\n",
    "    \"\"\"Save model weights.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    epoch: int\n",
    "        The epoch of training the weights correspond to.\n",
    "    dir_: str\n",
    "        The directory which will contain the output file.\n",
    "    file_pre: str\n",
    "        The first part of the file name to save the weights to. The epoch\n",
    "        and file extension will be added automatically.\n",
    "    verbose: bool\n",
    "        If True, print message to notify user that weights have been saved.\n",
    "    **kwargs: any type\n",
    "        User can optionally provide additional information to save \n",
    "        (e.g. optimizer state dict).\n",
    "    \"\"\"\n",
    "    os.makedirs(dir_, exist_ok=True)\n",
    "    file = f'{file_pre}_{epoch}.pth'\n",
    "    path = os.path.join(dir_, file)\n",
    "    \n",
    "    data = dict(weights=self.state_dict(),\n",
    "                epoch=epoch,\n",
    "                params=self._init_variables)\n",
    "    data = {**data, **kwargs}\n",
    "    torch.save(data, path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Weights saved from epoch {epoch}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@classmethod\n",
    "def from_path(cls, path, verbose=True):\n",
    "    \"\"\"Factory method to load a model from a file containing saved weights.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    path: str\n",
    "        File path to load weights from.\n",
    "    verbose: bool\n",
    "        If True, print message notifying user which weights have been loaded\n",
    "        and what mode the model is in.\n",
    "    \"\"\"\n",
    "    data = torch.load(path)\n",
    "    model = cls(**data['params'])\n",
    "    model.load_state_dict(data['weights'])\n",
    "    model.eval()\n",
    "\n",
    "    if verbose:\n",
    "        print(f'Weights loaded from epoch {data[\"epoch\"]}. '\n",
    "              'Currently in eval mode.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hooks\n",
    "\n",
    "Related notes:  \n",
    "-leaf variable - tensor defined by user (see x2 below)  \n",
    "    -non-leaf - result of tensor operation (see y below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from htools.ml import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_plot_gradients(grads):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.hist(grads.flatten().numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_gradients(grads):\n",
    "    return torch.clamp(grads, -1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(y):\n",
    "    \"\"\"Arbitrarily chosen.\"\"\"\n",
    "    return y.sum(-1).var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8., 4., 5., 7., 4., 8., 2., 3.],\n",
       "        [2., 0., 1., 8., 7., 5., 3., 9.],\n",
       "        [2., 4., 3., 9., 2., 0., 6., 0.],\n",
       "        [6., 1., 3., 0., 4., 0., 5., 5.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.randint(0, 10, (4, 8)).float()\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9228,  1.0944],\n",
       "        [ 0.7592,  0.1647],\n",
       "        [-1.0077,  0.5434],\n",
       "        [ 1.0515, -0.9802],\n",
       "        [-0.1555, -0.0869],\n",
       "        [-1.1046,  1.9011],\n",
       "        [-1.2100, -1.3748],\n",
       "        [ 0.3485,  0.4592]], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((8, 2), requires_grad=True)\n",
    "w.register_hook(hook_plot_gradients)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(79.9269, grad_fn=<VarBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x2 @ w\n",
    "cost = penalty(y)\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 21.9028,  21.9028],\n",
       "        [ -3.5688,  -3.5688],\n",
       "        [  4.8685,   4.8685],\n",
       "        [ 18.6997,  18.6997],\n",
       "        [ 23.7503,  23.7503],\n",
       "        [ 68.9819,  68.9819],\n",
       "        [-32.5070, -32.5070],\n",
       "        [ 33.5617,  33.5617]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(hooks, iters=5, lr=.1):\n",
    "    x = torch.randint(6, (4, 128), dtype=torch.float)\n",
    "    w = torch.randn((128, 2), requires_grad=True)\n",
    "\n",
    "#     w.register_hook(hook_plot_gradients)\n",
    "#     w.register_hook(lambda x: print(stats(x)))\n",
    "    for hook in hooks:\n",
    "        w.register_hook(hook)\n",
    "\n",
    "    for i in range(iters):\n",
    "        if w.grad is not None: w.grad.zero_()\n",
    "        y = x @ w\n",
    "        cost = penalty(y)\n",
    "        cost.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= lr * w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.8818, 31.2236)\n",
      "tensor(-0.8818) tensor(31.2236)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPC0lEQVR4nO3df6xkZX3H8fenuyDGHwXkQrYs24vJxohJRXtDaWyaFvyBYApNtMGYZlNJNqnaatqkXUtiY9omoEk1piZ2U03XxB8gaqASq9stxDZRcFHExRV3QaobNixWqPqP7eq3f8yzMrvM5c7cO3N/PLxfyWTOec4593yfO+d87rnnzJxJVSFJ6scvrXUBkqTpMtglqTMGuyR1xmCXpM4Y7JLUmc2rubJzzjmn5ufnV3OVkrTh3XPPPT+oqrlx51/VYJ+fn2f//v2ruUpJ2vCS/Nck83sqRpI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHVmrLc7JnkY+DHwM+B4VS0kORu4CZgHHgb+oKoen02ZkqRxTXLE/rtVdXFVLbTxXcC+qtoO7GvjkqQ1tpJTMVcDe9rwHuCalZcjSVqpcT95WsAXkxTwj1W1Gzivqo4CVNXRJOeOWjDJTmAnwLZt26ZQsno2v+v2NVnvwzdctSbrlWZh3GB/RVU90sJ7b5Jvj7uC9kdgN8DCwoJf1yRJMzbWqZiqeqQ9HwM+C1wCPJpkC0B7PjarIiVJ41sy2JM8J8nzTgwDrwYOALcBO9psO4BbZ1WkJGl845yKOQ/4bJIT83+8qv41yVeBm5NcB3wPeMPsypQkjWvJYK+qh4CXjmj/b+DyWRQlSVo+P3kqSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTPj3rZX6tpa3QcevBe8ps8jdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOjB3sSTYl+XqSz7XxC5PcleRQkpuSnD67MiVJ45rkiP3twMGh8RuB91XVduBx4LppFiZJWp6xgj3JVuAq4J/aeIDLgFvaLHuAa2ZRoCRpMuMesb8f+Avg5238BcATVXW8jR8Bzh+1YJKdSfYn2f/YY4+tqFhJ0tKWDPYkrwOOVdU9w80jZq1Ry1fV7qpaqKqFubm5ZZYpSRrX5jHmeQXwe0muBM4Ans/gCP7MJJvbUftW4JHZlSlJGteSR+xV9c6q2lpV88C1wL9X1ZuAO4DXt9l2ALfOrEpJ0thW8j72vwT+LMlhBufcPzydkiRJKzHOqZhfqKo7gTvb8EPAJdMvSZK0En7yVJI6Y7BLUmcmOhUjqR/zu25fs3U/fMNVa7buZwKP2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnfGLNvQUa/kFDJJWziN2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHVmyWBPckaSu5N8I8n9Sd7d2i9McleSQ0luSnL67MuVJC1lnCP2nwKXVdVLgYuBK5JcCtwIvK+qtgOPA9fNrkxJ0riWDPYa+EkbPa09CrgMuKW17wGumUmFkqSJjHWOPcmmJPcCx4C9wIPAE1V1vM1yBDh/NiVKkiYxVrBX1c+q6mJgK3AJ8OJRs41aNsnOJPuT7H/ssceWX6kkaSwTvSumqp4A7gQuBc5McuIbmLYCjyyyzO6qWqiqhbm5uZXUKkkawzjviplLcmYbfjbwSuAgcAfw+jbbDuDWWRUpSRrfON95ugXYk2QTgz8EN1fV55J8C/hkkr8Fvg58eIZ1SpLGtGSwV9V9wMtGtD/E4Hy7JGkd8ZOnktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmfG+TJrSZqq+V23r8l6H77hqjVZ72rziF2SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzSwZ7kguS3JHkYJL7k7y9tZ+dZG+SQ+35rNmXK0layjhH7MeBP6+qFwOXAm9NchGwC9hXVduBfW1ckrTGlgz2qjpaVV9rwz8GDgLnA1cDe9pse4BrZlWkJGl8E33RRpJ54GXAXcB5VXUUBuGf5NxFltkJ7ATYtm3bSmp9xlmrLyOQtLGNffE0yXOBTwPvqKofjbtcVe2uqoWqWpibm1tOjZKkCYwV7ElOYxDqH6uqz7TmR5NsadO3AMdmU6IkaRLjvCsmwIeBg1X190OTbgN2tOEdwK3TL0+SNKlxzrG/AvhD4JtJ7m1tfwXcANyc5Drge8AbZlOiJGkSSwZ7Vf0nkEUmXz7dciRJK+UnTyWpMwa7JHVmovexS5o+P6+gafOIXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpM0sGe5KPJDmW5MBQ29lJ9iY51J7Pmm2ZkqRxjXPE/s/AFae07QL2VdV2YF8blyStA0sGe1V9CfjhKc1XA3va8B7gminXJUlaps3LXO68qjoKUFVHk5y72IxJdgI7AbZt27bM1cH8rtuXvexKPHzDVWuyXknT90zJkZlfPK2q3VW1UFULc3Nzs16dJD3jLTfYH02yBaA9H5teSZKklVhusN8G7GjDO4Bbp1OOJGmlxnm74yeALwMvSnIkyXXADcCrkhwCXtXGJUnrwJIXT6vqjYtMunzKtUiSpsBPnkpSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ1Z7hdtPGOs1Y35JWm5PGKXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6syKgj3JFUkeSHI4ya5pFSVJWr5lB3uSTcAHgdcCFwFvTHLRtAqTJC3PSo7YLwEOV9VDVfW/wCeBq6dTliRpuTavYNnzge8PjR8BfuPUmZLsBHa20Z8keWAF6zzVOcAPpvjz1pJ9Wb966o99WQO5cazZnq4/vzrJ+lYS7BnRVk9pqNoN7F7BehYvINlfVQuz+Nmrzb6sXz31x76sX9Psz0pOxRwBLhga3wo8srJyJEkrtZJg/yqwPcmFSU4HrgVum05ZkqTlWvapmKo6nuRtwBeATcBHqur+qVU2npmc4lkj9mX96qk/9mX9mlp/UvWU0+KSpA3MT55KUmcMdknqzLoN9iR/k+S+JPcm+WKSX2ntSfKBdhuD+5K8fGiZHUkOtceOofZfT/LNtswHkox6q+Ys+/LeJN9u9X42yZlD097Z6nogyWuG2kferqFdrL6r9fGmduF6VSV5Q5L7k/w8ycIp0zZcfxazUW6ZkeQjSY4lOTDUdnaSve33ujfJWa194v1nlftyQZI7khxs29jbN2p/kpyR5O4k32h9eXdrH7nNJ3lWGz/cps8P/ayR+9WiqmpdPoDnDw3/KfChNnwl8HkG76O/FLirtZ8NPNSez2rDZ7VpdwO/2Zb5PPDaVe7Lq4HNbfhG4MY2fBHwDeBZwIXAgwwuRG9qwy8ETm/zXNSWuRm4tg1/CPjjNXhtXgy8CLgTWBhq35D9WaSPi9a83h7AbwMvBw4Mtb0H2NWGdw1tcxPvP6vcly3Ay9vw84DvtO1qw/Wn1fTcNnwacFerceQ2D7yFJ3PuWuCmNjxyv3q6da/bI/aq+tHQ6HN48sNPVwMfrYGvAGcm2QK8BthbVT+sqseBvcAVbdrzq+rLNfgtfRS4ZvV6AlX1xao63ka/wuA9/yf68smq+mlVfRc4zOBWDSNv19D+07gMuKUtv4dV7gtAVR2sqlGfIN6Q/VnEhrllRlV9CfjhKc1XM/h9wsm/14n2n9lXf7KqOlpVX2vDPwYOMviU+4brT6vpJ230tPYoFt/mh/t4C3B520cW268WtW6DHSDJ3yX5PvAm4F2tedStDM5fov3IiPa18mYGRxgweV9eADwx9Edirftyqp76s1jNG8V5VXUUBmEJnNvaJ32N1kw7FfEyBke6G7I/STYluRc4xuCPy4Msvs3/ouY2/X8Y7CMT92VNgz3JvyU5MOJxNUBVXV9VFwAfA952YrERP6qW0T5VS/WlzXM9cJxBf1hGzavSFxivP6MWW6S+Ne/PMqzn2lZiQ7wWSZ4LfBp4xyn/vT9l1hFt66Y/VfWzqrqYwX/plzA4jfmU2drz1PqyknvFrFhVvXLMWT8O3A78NYvfyuAI8DuntN/Z2reOmH+qlupLu3jzOuDydkoInv62DKPaf8DgX83N7S/6zG7jMMFrM2zd9mcZNvotMx5NsqWqjrZTE8da+6T7z6pLchqDUP9YVX2mNW/Y/gBU1RNJ7mRwjn2xbf5EX44k2Qz8MoNTbJNvi6t5MWHCCw/bh4b/BLilDV/FyRdL7q4nL5Z8l8GFkrPa8Nlt2lfbvCcunl65yn25AvgWMHdK+0s4+aLIQwwu2m1uwxfy5IW7l7RlPsXJF17esoav0Z2cfPF0Q/fnlL4tWvN6fADznHzx9L2cfLHxPW144v1nlfsRBtfB3n9K+4brDzAHnNmGnw38B4ODu5HbPPBWTr54enMbHrlfPe2613qDfJpfyqeBA8B9wL8A5w+98B9kcK7qm6cEy5sZXFg4DPzRUPtC+1kPAv9A+8TtKvblMINzZPe2x4eGpl3f6nqAoXfrMLja/5027fqh9hcyeJfP4baBPGsNXpvfZ3AU8VPgUeALG7k/T9PPkTWvtwfwCeAo8H/tdbmOwbnZfcCh9nziIGfi/WeV+/JbDE4z3De0v1y5EfsD/Brw9daXA8C7WvvIbR44o40fbtNfOPSzRu5Xiz28pYAkdWZdvytGkjQ5g12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR15v8BMFBVJ2+0eJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33.1751, 1318.7448)\n",
      "tensor(6.9012) tensor(798.8826)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-193.5696, 31778.0195)\n",
      "tensor(43.3803) tensor(998.2910)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1093.7861, 11979.1465)\n",
      "tensor(-104.1612) tensor(982.8121)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3164.0146, 35859.3125)\n",
      "tensor(81.5004) tensor(991.8568)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1254.1228, 13872.3652)\n",
      "tensor(-105.7121) tensor(984.0605)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3300.1748, 37887.875)\n",
      "tensor(83.0058) tensor(991.3549)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1059.9579, 14192.6484)\n",
      "tensor(-82.3730) tensor(986.9633)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2753.9849, 37713.6133)\n",
      "tensor(80.4163) tensor(996.7465)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAN8UlEQVR4nO3df6jd9X3H8ed7iT863JZEr5IluhshFC1s6i7O0jGG1s2aMi20oJQRViGwtptlgy2Z0FG2QWxhlbIyDVOWgas67dBVissywzYYsbFGjU3TROfWYDCRNuv6T7e07/1xPqnn3pybc86959x73vH5gMP9ns/5fs/3/c79fl/3m+/3fs+NzESSVM9PLHcBkqSFMcAlqSgDXJKKMsAlqSgDXJKKWrmUK7vkkktyenp6KVcpSeU9//zzb2Xm1NzxJQ3w6elp9u3bt5SrlKTyIuI/e417CkWSijLAJakoA1ySijLAJakoA1ySijLAJakoA1ySijLAJakoA1ySilrSOzFVw/TWp5dt3a9v37Rs65aq8QhckooywCWpKANckooywCWpKANckooywCWpKANckooywCWpKG/kmWDLeUONpMnnEbgkFWWAS1JRBrgkFWWAS1JRBrgkFTVwgEfEioh4ISK+0p5viIi9EXE4Ih6NiPPHV6Ykaa5hjsDvBg52Pb8X+HxmbgS+C9w1ysIkSWc3UIBHxHpgE/BX7XkANwKPt1l2ArePo0BJUm+DHoHfB/wB8KP2/GLgZGaeas+PAutGXJsk6Sz6BnhEfBA4npnPdw/3mDXnWX5LROyLiH0nTpxYYJmSpLkGOQJ/H/AbEfE68AidUyf3Aasi4vSt+OuBN3otnJk7MnMmM2empqZGULIkCQYI8MzclpnrM3MauAP458z8KPAs8OE222bgybFVKUk6w2J+D/wPgd+LiCN0zok/OJqSJEmDGOrTCDNzD7CnTb8GXD/6kiRJg/BOTEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqaqhPI5TOVdNbn162db++fdOyrVu1eQQuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlH9SrY/l/FNbemdYrm3MP+VWn0fgklSUAS5JRRngklSUAS5JRRngklRU3wCPiAsj4rmIeDEiXomIz7TxDRGxNyIOR8SjEXH++MuVJJ02yBH4D4AbM/MXgGuAWyLiBuBe4POZuRH4LnDX+MqUJM3VN8Cz4/vt6XntkcCNwONtfCdw+1gqlCT1NNA58IhYERH7gePALuBV4GRmnmqzHAXWjadESVIvAwV4Zv4wM68B1gPXA1f1mq3XshGxJSL2RcS+EydOLLxSSdIsQ/0WSmaeBPYANwCrIuL0rfjrgTfmWWZHZs5k5szU1NRiapUkdRnkt1CmImJVm34X8H7gIPAs8OE222bgyXEVKUk60yAfZrUW2BkRK+gE/mOZ+ZWI+AbwSET8KfAC8OAY65QkzdE3wDPzJeDaHuOv0TkfLklaBt6JKUlFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklFGeCSVJQBLklF9Q3wiLg8Ip6NiIMR8UpE3N3G10TErog43L6uHn+5kqTTBjkCPwX8fmZeBdwAfCIirga2ArszcyOwuz2XJC2RvgGemccy8+tt+n+Ag8A64DZgZ5ttJ3D7uIqUJJ1p5TAzR8Q0cC2wF7gsM49BJ+Qj4tJ5ltkCbAG44oorFlOr3gGmtz693CW8Yyznv/Xr2zct27rPJQNfxIyIi4AngE9l5vcGXS4zd2TmTGbOTE1NLaRGSVIPAwV4RJxHJ7wfzswvt+E3I2Jte30tcHw8JUqSehnkt1ACeBA4mJl/3vXSU8DmNr0ZeHL05UmS5jPIOfD3Ab8JvBwR+9vYHwHbgcci4i7gv4CPjKdESVIvfQM8M/8NiHlevmm05UiSBuWdmJJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUZ4JJUlAEuSUUN9Rd5JGkUluuvAZ1rfwnII3BJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKsoAl6SiDHBJKqpvgEfEQxFxPCIOdI2tiYhdEXG4fV093jIlSXMNcgT+18Atc8a2ArszcyOwuz2XJC2hvgGemf8CfGfO8G3Azja9E7h9xHVJkvpY6DnwyzLzGED7eul8M0bElojYFxH7Tpw4scDVSZLmGvtFzMzckZkzmTkzNTU17tVJ0jvGQgP8zYhYC9C+Hh9dSZKkQSw0wJ8CNrfpzcCToylHkjSoQX6N8EvAvwPvjoijEXEXsB24OSIOAze355KkJbSy3wyZeec8L9004lokSUPwTkxJKsoAl6SiDHBJKqrvOXBJOldMb316Wdb7+vZNY3lfj8AlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqSgDXJKKMsAlqagyd2Iu1x1UkjSpPAKXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqygCXpKIMcEkqalEBHhG3RMShiDgSEVtHVZQkqb8FB3hErAC+CHwAuBq4MyKuHlVhkqSzW8wR+PXAkcx8LTP/F3gEuG00ZUmS+lm5iGXXAd/uen4U+KW5M0XEFmBLe/r9iDjUpi8B3lrE+ieN/Uw2+5ls53Q/ce+i3+/neg0uJsCjx1ieMZC5A9hxxsIR+zJzZhHrnyj2M9nsZ7LZz8Is5hTKUeDyrufrgTcWV44kaVCLCfCvARsjYkNEnA/cATw1mrIkSf0s+BRKZp6KiE8CzwArgIcy85Uh3uKM0yrF2c9ks5/JZj8LEJlnnLaWJBXgnZiSVJQBLklFjSzAI+JPIuKliNgfEf8YET/bxiMivtBut38pIq7rWmZzRBxuj81d478YES+3Zb4QEdHG10TErjb/rohYPar6e/TzuYj4Zqv57yNiVddr21pthyLi17vGe360QLvQu7fV/Wi76EtEXNCeH2mvT4+xn49ExCsR8aOImJnzWrl+BjXJH/cQEQ9FxPGIONA11nMbH+V+NMZ+Lo+IZyPiYNvW7q7cU0RcGBHPRcSLrZ/PtPGht/9h97GBZeZIHsBPd03/LnB/m74V+Cqd3xu/AdjbxtcAr7Wvq9v06vbac8B72zJfBT7Qxj8LbG3TW4F7R1V/j35+DVjZpu89vS46HxvwInABsAF4lc5F3BVt+krg/DbP1W2Zx4A72vT9wG+36Y93/TvdATw6xn6uAt4N7AFmusZL9jNgz/P2MAkP4FeA64ADXWM9t/FR7kdj7GctcF2b/ingW237KtlTW8dFbfo8YG+rc6jtfyH72MA1jqnxbcBftukHgDu7XjvUvtF3Ag90jT/QxtYC3+wa//F8p5ft2lgOLdGO9iHg4a7etnW99kzboN4LPDPn32Bb2wje4u0fBj+e7/SybXplmy/G3MseZgd46X769Nqzh+WqZ54ap5kd4D238VHuR0vY25PAzedCT8BPAl+nc7f5UNv/sPvYMHWN9Bx4RPxZRHwb+Cjw6Tbc65b7dX3Gj/YYB7gsM48BtK+XjrL+s/gYnZ/2MHw/FwMnM/PUnPFZ79Ve/+82/1I61/rpNl8Pk2y+bXyU+9HYtdMH19I5ai3bU0SsiIj9wHFgF50j5mG3/2H7HNhQAR4R/xQRB3o8bmtF35OZlwMPA588vViPt8oFjI9cv37aPPcAp+j0xFnqW0g/I+11kH56LTZPDcvezwhMWj2LMbH70VwRcRHwBPCpzPze2WbtMTZRPWXmDzPzGjp3ml9P51TkfDUseT9D3ciTme8fcNa/BZ4G/pj5b7k/CvzqnPE9bXx9j/kB3oyItZl5LCLW0vmpuGD9+mkXTz4I3JTt/zic/SMEeo2/BayKiJXtp3L3/Kff62hErAR+BvjOuPqZx8T2MwIVP+5hvm18lPvR2ETEeXTC++HM/HIbLt0TQGaejIg9dM6BD7v9D7uPDVXYqM4Rbeya/h3g8Ta9idkXKp5r42uA/6BzkWJ1m17TXvtam/f0hYpb2/jnmH0x5LNjPOd1C/ANYGrO+HuYfUHiNToXI1a26Q28fUHiPW2Zv2P2RY+Pt+lPMPuix2NLcC5vD7PPgZfup0+v8/YwKQ/OPAfecxsf5X40xl4C+BvgvjnjJXsCpoBVbfpdwL/SOaAbavtfyD42cI0jbPYJ4ADwEvAPwLqub+oX6Zw7epnZ4fEx4Eh7/FbX+Ex7r1eBv+DtO0YvBnYDh9vXNWP85h2hc35qf3vc3/XaPa22Q3RdBadzVf1b7bV7usavpHP1/Ej75l/Qxi9sz4+0168cYz8fonMk8APgTWZfPCnXzxB99+xhEh7Al4BjwP+1781d823jo9yPxtjPL9M5BfBS135za9WegJ8HXmj9HAA+vdDtf9h9bNCHt9JLUlHeiSlJRRngklSUAS5JRRngklSUAS5JRRngklSUAS5JRf0/1l6ccFR4RWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-934.8754, 14230.0137)\n",
      "tensor(-98.5673) tensor(985.5751)\n"
     ]
    }
   ],
   "source": [
    "hooks = [hook_plot_gradients, \n",
    "         lambda x: print(stats(x)),\n",
    "         clip_gradients,\n",
    "         lambda x: print(torch.mean(x), torch.std(x))]\n",
    "\n",
    "train(hooks, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
