{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from incendio.core import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(BaseModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pad = nn.ReflectionPad2d(2)\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=5)\n",
    "        self.adapt = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(self.pad(x))\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.conv2(self.pad(x))\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.adapt(x)\n",
    "        x = self.fc(x.squeeze())\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "    \n",
    "class Model2(BaseModel):\n",
    "\n",
    "    def __init__(self, c_in, c_outs):\n",
    "        super().__init__()\n",
    "        dims = [c_in] + c_outs\n",
    "        self.enc = nn.Sequential(*[nn.Sequential(nn.ReflectionPad2d(2),\n",
    "                                   nn.Conv2d(*(c_in, c_out), kernel_size=5),\n",
    "                                   nn.LeakyReLU())\n",
    "                                   for c_in, c_out in zip(dims, dims[1:])])\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(c_outs[-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.enc(x)\n",
    "        x = self.pool(x)\n",
    "        print(x.shape)\n",
    "        x = x.squeeze()\n",
    "        print(x.shape)\n",
    "        return torch.sigmoid(self.fc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model2(\n",
       "  (enc): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (1): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ReflectionPad2d((2, 2, 2, 2))\n",
       "      (1): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (2): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "  )\n",
       "  (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = Model2(3, [8, 16, 32])\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (pad): ReflectionPad2d((2, 2, 2, 2))\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (adapt): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = Model()\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  6., 210., 214.,  38.],\n",
       "          [176., 197.,  80., 112.],\n",
       "          [168.,  81., 106., 252.],\n",
       "          [202.,  38., 147., 102.]],\n",
       "\n",
       "         [[ 28.,  64., 112., 143.],\n",
       "          [152.,  87., 219., 151.],\n",
       "          [123., 154.,  79.,  27.],\n",
       "          [127., 198., 100., 223.]],\n",
       "\n",
       "         [[253., 150., 155., 243.],\n",
       "          [222.,  96., 219.,  40.],\n",
       "          [ 75., 251., 234., 149.],\n",
       "          [112., 234., 204.,  13.]]],\n",
       "\n",
       "\n",
       "        [[[248., 236., 113., 144.],\n",
       "          [223.,  34., 192., 156.],\n",
       "          [248., 183.,  35.,  35.],\n",
       "          [101.,  64.,  25., 203.]],\n",
       "\n",
       "         [[ 23., 145.,  52., 237.],\n",
       "          [119., 254., 116., 180.],\n",
       "          [ 70., 199., 149.,   5.],\n",
       "          [ 78.,  58.,  22.,  34.]],\n",
       "\n",
       "         [[221., 226.,  48., 109.],\n",
       "          [212., 146.,  67.,   0.],\n",
       "          [ 65.,  45., 175.,  85.],\n",
       "          [233., 187., 190.,  22.]]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(255, (2, 3, 4, 4)).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    plt.imshow(img.permute(1, 2, 0) / 255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 8, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = nn.ReflectionPad2d(2)\n",
    "x_pad = pad(x)\n",
    "x_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(x_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectionPaddedConv2d(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, padding=1, \n",
    "                 kernel_size=3, stride=1, bias=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.reflect = nn.ReflectionPad2d(padding)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                              stride, padding=0, bias=bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.reflect(x)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = ReflectionPaddedConv2d(in_channels=3, out_channels=3)\n",
    "nn.init.constant_(rc.conv.weight, 1)\n",
    "nn.init.constant_(rc.conv.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = nn.Conv2d(3, 3, kernel_size=3, padding=1, padding_mode='zeros', bias=True)\n",
    "nn.init.constant_(r.weight, 1)\n",
    "nn.init.constant_(r.bias, 0)\n",
    "x_p = r(x)\n",
    "x_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applies a 2D convolution over an input signal composed of several input\n",
      "    planes.\n",
      "\n",
      "    In the simplest case, the output value of the layer with input size\n",
      "    :math:`(N, C_{\\text{in}}, H, W)` and output :math:`(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})`\n",
      "    can be precisely described as:\n",
      "\n",
      "    .. math::\n",
      "        \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
      "        \\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k)\n",
      "\n",
      "\n",
      "    where :math:`\\star` is the valid 2D `cross-correlation`_ operator,\n",
      "    :math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
      "    :math:`H` is a height of input planes in pixels, and :math:`W` is\n",
      "    width in pixels.\n",
      "\n",
      "    * :attr:`stride` controls the stride for the cross-correlation, a single\n",
      "      number or a tuple.\n",
      "\n",
      "    * :attr:`padding` controls the amount of implicit zero-paddings on both\n",
      "      sides for :attr:`padding` number of points for each dimension.\n",
      "\n",
      "    * :attr:`dilation` controls the spacing between the kernel points; also\n",
      "      known as the Ã  trous algorithm. It is harder to describe, but this `link`_\n",
      "      has a nice visualization of what :attr:`dilation` does.\n",
      "\n",
      "    * :attr:`groups` controls the connections between inputs and outputs.\n",
      "      :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
      "      :attr:`groups`. For example,\n",
      "\n",
      "        * At groups=1, all inputs are convolved to all outputs.\n",
      "        * At groups=2, the operation becomes equivalent to having two conv\n",
      "          layers side by side, each seeing half the input channels,\n",
      "          and producing half the output channels, and both subsequently\n",
      "          concatenated.\n",
      "        * At groups= :attr:`in_channels`, each input channel is convolved with\n",
      "          its own set of filters, of size:\n",
      "          :math:`\\left\\lfloor\\frac{out\\_channels}{in\\_channels}\\right\\rfloor`.\n",
      "\n",
      "    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:\n",
      "\n",
      "        - a single ``int`` -- in which case the same value is used for the height and width dimension\n",
      "        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,\n",
      "          and the second `int` for the width dimension\n",
      "\n",
      "    .. note::\n",
      "\n",
      "         Depending of the size of your kernel, several (of the last)\n",
      "         columns of the input might be lost, because it is a valid `cross-correlation`_,\n",
      "         and not a full `cross-correlation`_.\n",
      "         It is up to the user to add proper padding.\n",
      "\n",
      "    .. note::\n",
      "\n",
      "        When `groups == in_channels` and `out_channels == K * in_channels`,\n",
      "        where `K` is a positive integer, this operation is also termed in\n",
      "        literature as depthwise convolution.\n",
      "\n",
      "        In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,\n",
      "        a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments\n",
      "        :math:`(in\\_channels=C_{in}, out\\_channels=C_{in} \\times K, ..., groups=C_{in})`.\n",
      "\n",
      "    .. include:: cudnn_deterministic.rst\n",
      "\n",
      "    Args:\n",
      "        in_channels (int): Number of channels in the input image\n",
      "        out_channels (int): Number of channels produced by the convolution\n",
      "        kernel_size (int or tuple): Size of the convolving kernel\n",
      "        stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
      "        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0\n",
      "        padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`\n",
      "        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1\n",
      "        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
      "        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
      "\n",
      "    Shape:\n",
      "        - Input: :math:`(N, C_{in}, H_{in}, W_{in})`\n",
      "        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where\n",
      "\n",
      "          .. math::\n",
      "              H_{out} = \\left\\lfloor\\frac{H_{in}  + 2 \\times \\text{padding}[0] - \\text{dilation}[0]\n",
      "                        \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1\\right\\rfloor\n",
      "\n",
      "          .. math::\n",
      "              W_{out} = \\left\\lfloor\\frac{W_{in}  + 2 \\times \\text{padding}[1] - \\text{dilation}[1]\n",
      "                        \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1\\right\\rfloor\n",
      "\n",
      "    Attributes:\n",
      "        weight (Tensor): the learnable weights of the module of shape\n",
      "                         :math:`(\\text{out\\_channels}, \\frac{\\text{in\\_channels}}{\\text{groups}},`\n",
      "                         :math:`\\text{kernel\\_size[0]}, \\text{kernel\\_size[1]})`.\n",
      "                         The values of these weights are sampled from\n",
      "                         :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "                         :math:`k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      "        bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,\n",
      "                         then the values of these weights are\n",
      "                         sampled from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
      "                         :math:`k = \\frac{1}{C_\\text{in} * \\prod_{i=0}^{1}\\text{kernel\\_size}[i]}`\n",
      "\n",
      "    Examples::\n",
      "\n",
      "        >>> # With square kernels and equal stride\n",
      "        >>> m = nn.Conv2d(16, 33, 3, stride=2)\n",
      "        >>> # non-square kernels and unequal stride and with padding\n",
      "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
      "        >>> # non-square kernels and unequal stride and with padding and dilation\n",
      "        >>> m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
      "        >>> input = torch.randn(20, 16, 50, 100)\n",
      "        >>> output = m(input)\n",
      "\n",
      "    .. _cross-correlation:\n",
      "        https://en.wikipedia.org/wiki/Cross-correlation\n",
      "\n",
      "    .. _link:\n",
      "        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nn.Conv2d.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
