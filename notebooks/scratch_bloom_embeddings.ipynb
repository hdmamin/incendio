{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import mmh3\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from htools import hdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.chain at 0x1215dc310>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.from_iterable(row.split(' ') for row in sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\n",
    "    'I walked to the store so I hope it is not closed.',\n",
    "    'The theater is closed today and the sky is grey.',\n",
    "    'His dog is brown while hers is grey.'\n",
    "]\n",
    "labels = [0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, just convert int to str and take hash. Another option that is meant for ints is Knuth's multiplicative method:\n",
    "\n",
    "hash(i) = i*2654435761 mod 2^32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3530670207"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmh3.hash('0', signed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 2, 30, 4, 50, 6, 70, 8, 90]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i if i % 2 == 0 else i*10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_int(x, n_buckets, n_hashes=3):\n",
    "    \"\"\"Slightly hacky way to probabilistically hash an integer by\n",
    "    first converting it to a string.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: int\n",
    "        The integer to hash.\n",
    "    n_buckets: int\n",
    "        The number of buckets that items will be mapped to. Typically \n",
    "        this would occur outside the hashing function, but since \n",
    "        the intended use case is so narrow here it makes sense to me \n",
    "        to include it here.\n",
    "    n_hashes: int\n",
    "        The number of times to hash x, each time with a different seed.\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list[int]: A list of integers with length `n_hashes`, where each integer\n",
    "        is in [0, n_buckets).\n",
    "    \"\"\"\n",
    "    assert isinstance(x, int), 'Input `x` must have type int.'\n",
    "    return [mmh3.hash(str(x), i, signed=False) % n_buckets for i in range(n_hashes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_int_tensor(x_r2, n_buckets, n_hashes=3, pad_idx=0):\n",
    "    \"\"\"Hash a rank 2 LongTensor.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x_r2: torch.LongTensor\n",
    "        Rank 2 tensor of integers. Shape: (bs, seq_len)\n",
    "    n_buckets: int\n",
    "        Number of buckets to hash items into (i.e. the number of \n",
    "        rows in the embedding matrix). Typically a moderately large\n",
    "        prime number, like 251 or 997.\n",
    "    n_hashes: int\n",
    "        Number of hashes to take for each input index. This determines\n",
    "        the number of rows of the embedding matrix that will be summed\n",
    "        to get the representation for each word. Typically 2-5.\n",
    "    pad_idx: int or None\n",
    "        If you want to pad sequences with vectors of zeros, pass in an\n",
    "        integer (same as the `padding_idx` argument to nn.Embedding).\n",
    "        If None, no padding index will be used. The sequences must be\n",
    "        padded before passing them into this function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.LongTensor: Tensor of indices where each row corresponds\n",
    "        to one of the input indices. Shape: (bs, seq_len, n_hashes)\n",
    "    \"\"\"\n",
    "    return torch.tensor(\n",
    "        [[hash_int(x.item(), n_buckets, n_hashes) \n",
    "          if x != pad_idx else [pad_idx]*n_hashes for x in row]\n",
    "         for row in x_r2]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1])\n",
      "\n",
      "[2, 5, 6, 3, 7, 8, 2, 9, 10, 1]\n",
      "tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4])\n",
      "\n",
      "[13, 14, 1, 15, 16, 17, 3, 18, 1, 4]\n",
      "tensor([19, 20,  1, 21, 22, 23,  1,  4,  0,  0])\n",
      "\n",
      "[19, 20, 1, 21, 22, 23, 1, 4, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for row in x:\n",
    "    print(row, end='\\n\\n')\n",
    "    print([x.item() for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_int_tensor(x, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8,  2,  7],\n",
       "         [ 2,  8,  1],\n",
       "         [ 6,  6, 10],\n",
       "         [10,  5,  5],\n",
       "         [ 6,  9,  7],\n",
       "         [ 5,  9,  4],\n",
       "         [ 8,  2,  7],\n",
       "         [ 5, 10,  8],\n",
       "         [ 7,  8,  6],\n",
       "         [ 6, 10,  6]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_int_tensor(x[0, None], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2, 10,  6],\n",
       "         [ 1,  7,  8],\n",
       "         [ 6, 10,  6],\n",
       "         [ 2,  7,  1],\n",
       "         [ 9,  4,  8],\n",
       "         [ 5,  3,  3],\n",
       "         [ 6, 10,  6],\n",
       "         [ 4,  8,  6],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_int_tensor(x[2,  None], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 2, 7],\n",
       " [2, 8, 1],\n",
       " [6, 6, 10],\n",
       " [10, 5, 5],\n",
       " [6, 9, 7],\n",
       " [5, 9, 4],\n",
       " [8, 2, 7],\n",
       " [5, 10, 8],\n",
       " [7, 8, 6],\n",
       " [6, 10, 6]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hash_int(n.item(), 11) for n in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 1]\n",
      "[2, 6, 9]\n",
      "[8, 2, 7]\n",
      "[2, 5, 7]\n",
      "[10, 10, 2]\n",
      "[0, 10, 4]\n",
      "[3, 8, 4]\n",
      "[6, 5, 0]\n",
      "[6, 10, 8]\n",
      "[4, 4, 0]\n",
      "[7, 1, 0]\n",
      "[10, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 200, 17):\n",
    "    print(hash_int(i, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences, labels, seq_len):\n",
    "        x = [s.split(' ') for s in sentences]\n",
    "        self.w2i = self.make_w2i(x)\n",
    "        self.seq_len = seq_len\n",
    "        self.x = self.encode(x)\n",
    "        self.y = torch.tensor(labels)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def make_w2i(self, tok_rows):\n",
    "        return {k: i for i, (k, v) in \n",
    "                enumerate(Counter(chain(*tok_rows)).most_common(), 1)}\n",
    "    \n",
    "    def encode(self, tok_rows):\n",
    "        enc = np.zeros((len(tok_rows), self.seq_len), dtype=int)\n",
    "        for i, row in enumerate(tok_rows):\n",
    "            trunc = [self.w2i.get(w, 0) for w in row[:self.seq_len]]\n",
    "            enc[i, :len(trunc)] = trunc\n",
    "        return torch.tensor(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4]), tensor(1))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Data(sents, labels, 10)\n",
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]), tensor([0, 1, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=3)\n",
    "x, y = next(iter(dl))\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 1,\n",
       " 'I': 2,\n",
       " 'the': 3,\n",
       " 'grey.': 4,\n",
       " 'walked': 5,\n",
       " 'to': 6,\n",
       " 'store': 7,\n",
       " 'so': 8,\n",
       " 'hope': 9,\n",
       " 'it': 10,\n",
       " 'not': 11,\n",
       " 'closed.': 12,\n",
       " 'The': 13,\n",
       " 'theater': 14,\n",
       " 'closed': 15,\n",
       " 'today': 16,\n",
       " 'and': 17,\n",
       " 'sky': 18,\n",
       " 'His': 19,\n",
       " 'dog': 20,\n",
       " 'brown': 21,\n",
       " 'while': 22,\n",
       " 'hers': 23}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.w2i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do:\n",
    "- [x] maybe handle padding differently (i.e. just a row of zeros as usual. Should this happen in hash_int, hash_int_tensor, or BloomEmbedding?)\n",
    "- maybe use fastai embedding() instead of nn.Embedding? Check if the weight init method might help for this.\n",
    "- maybe use nn.embeddingbag?\n",
    "- experiment with different numbers of embeddings and hashes. Try to find guidelines for what reasonable choices are to prevent collisions. \n",
    "    - Eventually, maybe better to let user input vocab size and choose prob of collision, then automatically select values for n_emb and n_hashes. \n",
    "- check to make sure indices are working correctly after switching hash_int_tensor to take only 2d tensors. Also consider if this is the preferred way to do this.\n",
    "- should we let user choose between mean and sum? Wonder if mean would be better bc we could try different values of n_hashes while still loading pre-trained embeddings (bc scale is standardized)? But that probably doesn't work bc the hashes will be different anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BloomEmbedding(nn.Module):\n",
    "    \"\"\"Bloom Embedding layer for memory-efficient word representations.\n",
    "    Each word is encoded by a combination of rows of the embedding\n",
    "    matrix. The number of rows can therefore be far lower than the number\n",
    "    of words in our vocabulary while still providing unique representations.\n",
    "    \n",
    "    The reduction in rows allows us to use memory in other ways: \n",
    "    a larger embedding dimension, more or larger layers after the embedding,\n",
    "    or larger batch sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_emb=251, emb_dim=100, n_hashes=4, padding_idx=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_emb: int\n",
    "            Number of rows to create in the embedding matrix. A prime\n",
    "            number is recommended. Lower numbers will be more \n",
    "            memory-efficient but increase the chances of collisions.\n",
    "        emb_dim: int\n",
    "            Size of each embedding. If emb_dim=100, each word will\n",
    "            be represented by a 100-dimensional vector.\n",
    "        n_hashes: int\n",
    "            This determines the number of hashes that will be taken\n",
    "            for each word index, and as a result, the number of rows\n",
    "            that will be summed to create each unique representation.\n",
    "            The higher the number, the lower the chances of a collision.\n",
    "        padding_idx: int or None\n",
    "            If an integer is provided, this will set aside the corresponding\n",
    "            row in the embedding matrix as a vector of zeros. If None, no\n",
    "            padding vector will be allocated.\n",
    "            \n",
    "        Suggested values for a vocab size of ~30,000:\n",
    "        \n",
    "        | n_emb | n_hashes | unique combos |\n",
    "        |-------|----------|---------------|\n",
    "        | 127   | 5        | 29,998        |\n",
    "        | 251   | 4        | 29,996        |\n",
    "        | 997   | 3        | 29,997        |\n",
    "        | 5,003 | 2        | 29,969        |\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_emb = n_emb\n",
    "        self.emb = nn.Embedding(n_emb, emb_dim, padding_idx=padding_idx)\n",
    "        self.n_hashes = n_hashes\n",
    "        self.pad_idx = padding_idx\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.LongTensor\n",
    "            Input tensor of word indices. (bs x seq_len)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.FloatTensor: Words encoded with combination of embeddings.\n",
    "            (bs x seq_len x emb_dim)\n",
    "        \"\"\"\n",
    "        # (bs, seq_len, n_hashes)\n",
    "        hashed = hash_int_tensor(x, self.n_emb, self.n_hashes, self.pad_idx)\n",
    "        # (bs, seq_len, n_hashes, emb_dim) -> sum -> (bs, seq_len, emb_dim)\n",
    "        return self.emb(hashed).sum(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "        [-2.0462e+00,  5.2716e-01, -1.8577e-01,  2.0636e-01],\n",
       "        [-2.7725e+00, -4.0539e-02, -1.2162e-01, -1.5453e+00],\n",
       "        [ 1.4179e-01, -1.5752e+00,  1.1838e+00,  6.2302e-01],\n",
       "        [ 6.3845e-01,  9.6330e-01,  1.0995e+00, -6.4528e-01],\n",
       "        [-8.0821e-01,  1.3410e+00,  2.0342e-03, -1.4437e+00],\n",
       "        [ 5.3196e-01,  4.9610e-01,  2.4020e-01,  9.6942e-01],\n",
       "        [ 6.7312e-01, -1.6300e+00, -1.0742e+00, -4.6747e-01],\n",
       "        [ 7.8946e-02, -1.1476e+00, -9.0362e-02,  3.1300e-01],\n",
       "        [ 1.0806e+00, -9.5686e-01,  3.3655e-01, -2.7509e-01],\n",
       "        [ 5.7283e-01,  7.7029e-01,  8.0080e-01,  2.0770e+00]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be = BloomEmbedding(11, 4)\n",
    "be.emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],\n",
       "        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],\n",
       "        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 8, 1]\n",
      "[6, 10, 6]\n",
      "[8, 2, 7]\n",
      "[10, 5, 5]\n",
      "[4, 8, 6]\n",
      "[2, 8, 1]\n",
      "[6, 6, 10]\n",
      "[6, 9, 7]\n",
      "[5, 9, 4]\n",
      "[5, 10, 8]\n",
      "[7, 8, 6]\n",
      "[7, 9, 2]\n",
      "[1, 7, 3]\n",
      "[2, 5, 1]\n",
      "[9, 8, 8]\n",
      "[8, 1, 10]\n",
      "[6, 3, 9]\n",
      "[2, 6, 9]\n",
      "[10, 5, 0]\n",
      "[2, 10, 6]\n",
      "[1, 7, 8]\n",
      "[2, 7, 1]\n",
      "[9, 4, 8]\n",
      "[5, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for i in range(24):\n",
    "    print(hash_int(i, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = be(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9414e+00, -3.9658e+00, -1.3765e+00, -1.3868e+00],\n",
       "        [-7.5122e+00, -7.0155e-01, -5.1937e-01, -2.5713e+00],\n",
       "        [ 2.2096e+00,  2.5328e+00,  2.0820e+00,  6.0929e+00],\n",
       "        [-1.8518e+00,  4.7934e+00,  8.0690e-01, -2.2542e+00],\n",
       "        [-4.8675e-01, -2.1313e+00, -6.1906e-01, -1.3185e+00],\n",
       "        [ 9.1088e-01,  1.3475e+00,  1.4381e+00, -2.3641e+00],\n",
       "        [-1.9414e+00, -3.9658e+00, -1.3765e+00, -1.3868e+00],\n",
       "        [ 9.2421e-01,  6.8116e-03,  1.0490e+00,  6.7120e-01],\n",
       "        [-1.4884e+00, -2.3221e+00, -1.0460e+00, -7.3039e-01],\n",
       "        [ 1.6367e+00,  1.7625e+00,  1.2812e+00,  4.0159e+00]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.3994,  1.7871, -0.4270, -4.3281],\n",
       "        [ 1.7705, -2.7560,  0.3960,  1.3203],\n",
       "        [ 1.6367,  1.7625,  1.2812,  4.0159],\n",
       "        [-1.2527, -1.4254,  1.7085,  3.2194],\n",
       "        [ 1.7544, -2.0360,  1.7605,  1.3173],\n",
       "        [-1.1599, -0.5013,  0.4551, -0.8510],\n",
       "        [-1.8518,  4.7934,  0.8069, -2.2542],\n",
       "        [-3.0078,  2.0708,  0.6812, -0.9121],\n",
       "        [ 1.6367,  1.7625,  1.2812,  4.0159],\n",
       "        [-1.5231,  0.2712,  1.1277, -0.9082]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0948,  1.9961,  1.7202,  3.5781],\n",
       "        [-0.7622, -1.7544, -1.1101,  1.0213],\n",
       "        [ 1.6367,  1.7625,  1.2812,  4.0159],\n",
       "        [-3.5071, -0.1801, -0.2821, -2.4517],\n",
       "        [ 2.3300, -0.6451,  1.5859,  0.3620],\n",
       "        [-0.4457, -2.9571,  2.2792,  0.1153],\n",
       "        [ 1.6367,  1.7625,  1.2812,  4.0159],\n",
       "        [-1.5231,  0.2712,  1.1277, -0.9082],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is 1 [1.6367457 1.7624942 1.2811998 4.0158687]\n",
      "I 2 [-1.9414458 -3.9658241 -1.3765308 -1.3868113]\n",
      "the 3 [-1.851784   4.793353   0.8069003 -2.254175 ]\n",
      "grey. 4 [-1.5230992  0.2712285  1.1277255 -0.9082023]\n",
      "walked 5 [-7.5122128  -0.70155233 -0.5193659  -2.5713277 ]\n",
      "to 6 [2.2095788 2.5327837 2.0819974 6.0928936]\n",
      "store 7 [-0.48674607 -2.131305   -0.6190572  -1.3184783 ]\n",
      "so 8 [ 0.91088253  1.3474642   1.438086   -2.364105  ]\n",
      "hope 9 [0.9242083  0.00681156 1.0490168  0.67120016]\n",
      "it 10 [-1.4884353  -2.3220832  -1.0459671  -0.73038846]\n",
      "not 11 [-0.34558553 -4.257416   -1.9334465  -2.7553678 ]\n",
      "closed. 12 [-0.6585116 -1.9077785  0.7246287  2.4389334]\n",
      "The 13 [-8.399364    1.7871077  -0.42696917 -4.32806   ]\n",
      "theater 14 [ 1.7704833  -2.7560353   0.39602363  1.3203299 ]\n",
      "closed 15 [-1.2526826 -1.4254087  1.7084544  3.2194   ]\n",
      "today 16 [ 1.7543795 -2.0359812  1.7605362  1.3173498]\n",
      "and 17 [-1.159863  -0.5012967  0.455131  -0.8510109]\n",
      "sky 18 [-3.0078273   2.0707722   0.6812143  -0.91205084]\n",
      "His 19 [-1.094832   1.9961429  1.7201787  3.578129 ]\n",
      "dog 20 [-0.76223046 -1.7543812  -1.1101178   1.0213115 ]\n",
      "brown 21 [-3.507134   -0.18008012 -0.28206968 -2.4517334 ]\n",
      "while 22 [ 2.3299904  -0.64509344  1.5858905   0.36204934]\n",
      "hers 23 [-0.44568363 -2.9570632   2.2792468   0.11530283]\n"
     ]
    }
   ],
   "source": [
    "for w, i in ds.w2i.items():\n",
    "    print(w, i, be(torch.tensor([[i]])).detach().numpy().squeeze())\n",
    "#           .emb.weight[hash_int(i, be.n_emb)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[5, 3, 3, 8]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashed = hash_int_tensor(torch.tensor([23]).unsqueeze(0), 11, 4)\n",
    "hashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4457, -2.9571,  2.2792,  0.1153]]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be.emb.weight[hashed].sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_combos(tups):\n",
    "    return len(set(tuple(sorted(x)) for x in tups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_all_idx(vocab_size, n_buckets, n_hashes):\n",
    "    return [hash_int(i, n_buckets, n_hashes) for i in range(vocab_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets: 127 Hashes: 5 Unique combos: 29998 % unique: 0.99993\n",
      "Buckets: 251 Hashes: 4 Unique combos: 29996 % unique: 0.99987\n",
      "Buckets: 997 Hashes: 3 Unique combos: 29997 % unique: 0.9999\n",
      "Buckets: 5003 Hashes: 2 Unique combos: 29969 % unique: 0.99897\n"
     ]
    }
   ],
   "source": [
    "buckets2hashes = {127: 5,\n",
    "                  251: 4,\n",
    "                  997: 3,\n",
    "                  5_003: 2}\n",
    "for b, h in buckets2hashes.items():\n",
    "    tups = hash_all_idx(30_000, b,  h)\n",
    "    unique = unique_combos(tups)\n",
    "    print('Buckets:', b, 'Hashes:', h, 'Unique combos:', unique,\n",
    "          '% unique:', round(unique/30_000, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_n_buckets(vocab_size, hash_sizes, bucket_sizes):\n",
    "    for bs in bucket_sizes:\n",
    "        for hs in hash_sizes:\n",
    "            tups = hash_all_idx(vocab_size, bs, hs)\n",
    "            unique = unique_combos(tups)\n",
    "            print(bs, hs, round(unique/vocab_size, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 2 0.1875\n",
      "5 3 0.3625\n",
      "5 4 0.5375\n",
      "5 5 0.625\n",
      "11 2 0.625\n",
      "11 3 0.875\n",
      "11 4 0.975\n",
      "11 5 1.0\n",
      "19 2 0.85\n",
      "19 3 0.975\n",
      "19 4 1.0\n",
      "19 5 1.0\n",
      "29 2 0.9375\n",
      "29 3 0.9875\n",
      "29 4 1.0\n",
      "29 5 1.0\n",
      "37 2 0.925\n",
      "37 3 1.0\n",
      "37 4 1.0\n",
      "37 5 1.0\n"
     ]
    }
   ],
   "source": [
    "eval_n_buckets(80, range(2, 6), [5, 11, 19, 29, 37])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 100])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(0, 30_000, (64, 100))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.6 ms ± 3.83 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "hashed = hash_int_tensor(x, 127, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.6 ms ± 2.54 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "hashed = hash_int_tensor(x, 251, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.9 ms ± 3.67 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "hashed = hash_int_tensor(x, 997, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.6 ms ± 3.26 ms per loop (mean ± std. dev. of 5 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 5 -r 5\n",
    "hashed = hash_int_tensor(x, 5_003, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
