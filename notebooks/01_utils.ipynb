{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> Basic utilities with few dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At training time, we will typically want to put the model and the current mini batch on the GPU. When developing on a CPU, a GPU isn't available, so we define a variable that will automatically find the right device. This goes in utils rather than core to avoid circular imports with the callbacks module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hasarg(func, arg):\n",
    "    \"\"\"Checks if a function has a given argument.\n",
    "    Works with args and kwargs as well if you exclude the\n",
    "    stars. See example below.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func: function\n",
    "    arg: str\n",
    "        Name of argument to look for.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    def foo(a, b=6, *args):\n",
    "        return\n",
    "\n",
    "    >>> hasarg(foo, 'b')\n",
    "    True\n",
    "\n",
    "    >>> hasarg(foo, 'args')\n",
    "    True\n",
    "\n",
    "    >>> hasarg(foo, 'c')\n",
    "    False\n",
    "    \"\"\"\n",
    "    return arg in inspect.signature(func).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def quick_stats(x, digits=3):\n",
    "    \"\"\"Quick wrapper to get mean and standard deviation of a tensor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: torch.Tensor\n",
    "    digits: int\n",
    "        Number of digits to round mean and standard deviation to.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float]\n",
    "    \"\"\"\n",
    "    return round(x.mean().item(), digits), round(x.std().item(), digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def concat(*args, dim=-1):\n",
    "    \"\"\"Wrapper to torch.cat which accepts tensors as non-keyword\n",
    "    arguments rather than requiring them to be wrapped in a list.\n",
    "    This can be useful if we've built some generalized functionality\n",
    "    where parameters must be passed in a consistent manner.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args: torch.tensor\n",
    "        Multiple tensors to concatenate.\n",
    "    dim: int\n",
    "        Dimension to concatenate on (last dimension by default).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor\n",
    "    \"\"\"\n",
    "    return torch.cat(args, dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def weighted_avg(*args, weights):\n",
    "    \"\"\"Compute a weighted average of multiple tensors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args: torch.tensor\n",
    "        Multiple tensors with the same dtype and shape that you want to average.\n",
    "    weights: list\n",
    "        Ints or floats to weight each input tensor. The length of this list must\n",
    "        match the number of tensors passed in: the first weight will be multiplied \n",
    "        by the first tensor, the second weight by the second tensor, etc. If your\n",
    "        weights don't sum to 1, they will be normalized automatically.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    torch.tensor: Same dtype and shape as each of the input tensors.\n",
    "    \"\"\"\n",
    "    weights = torch.tensor(weights)\n",
    "    total = weights.sum().float()\n",
    "    if total != 1: weights = weights / total\n",
    "    res = torch.stack(args)\n",
    "    weights_shape = [-1 if i == 0 else 1 for i, _ in enumerate(range(res.ndim))]\n",
    "    return torch.mean(res * weights.view(*weights_shape), axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
