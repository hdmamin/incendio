---

title: Layers

keywords: fastai
sidebar: home_sidebar

summary: "Custom activations, layers, and layer blocks are contained in this module."
description: "Custom activations, layers, and layer blocks are contained in this module."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/04_layers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/hmamin/incendio/incendio/callbacks.py:26: UserWarning: Accio not available.
  warnings.warn(&#39;Accio not available.&#39;)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/hmamin/anaconda3/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.
  and should_run_async(code)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Used for testing only.</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">chain</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">htools</span> <span class="kn">import</span> <span class="n">assert_raises</span><span class="p">,</span> <span class="n">InvalidArgumentError</span><span class="p">,</span> <span class="n">smap</span>
<span class="kn">from</span> <span class="nn">incendio.data</span> <span class="kn">import</span> <span class="n">probabilistic_hash_item</span>
<span class="kn">import</span> <span class="nn">pandas_htools</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;ends&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;ends&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;filter_by_count&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;grouped_mode&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;impute&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;target_encode&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;top_categories&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;vcounts&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;pprint&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;pprint&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;lambda_sort&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;lambda_sort&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:31: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_dataframe_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;coalesce&#39; for type &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; is overriding a preexisting attribute with the same name.
  register_dataframe_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;stringify&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
/Users/hmamin/anaconda3/lib/python3.7/site-packages/pandas_flavor/register.py:53: UserWarning: registration of accessor &lt;class &#39;pandas_flavor.register.register_series_method.&lt;locals&gt;.inner.&lt;locals&gt;.AccessorMethod&#39;&gt; under name &#39;is_list_col&#39; for type &lt;class &#39;pandas.core.series.Series&#39;&gt; is overriding a preexisting attribute with the same name.
  register_series_accessor(method.__name__)(AccessorMethod)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Activations">Activations<a class="anchor-link" href="#Activations"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="GRelu" class="doc_header"><code>class</code> <code>GRelu</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L25" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>GRelu</code>(<strong><code>leak</code></strong>=<em><code>0.0</code></em>, <strong><code>max</code></strong>=<em><code>inf</code></em>, <strong><code>sub</code></strong>=<em><code>0.0</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Generic ReLU.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Mish" class="doc_header"><code>class</code> <code>Mish</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L52" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Mish</code>() :: <code>Module</code></p>
</blockquote>

<pre><code>OOP form of mish activation.

Mish: A Self Regularized Non-Monotonic Neural Activation Function
https://arxiv.org/pdf/1908.08681v1.pdf</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="mish" class="doc_header"><code>mish</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L67" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>mish</code>(<strong><code>x</code></strong>)</p>
</blockquote>

<pre><code>Functional form of mish activation.

Mish: A Self Regularized Non-Monotonic Neural Activation Function
https://arxiv.org/pdf/1908.08681v1.pdf

Parameters
----------
x: torch.Tensor[float]
    Input tensor.
Returns
-------
torch.Tensor[float]: Tensor of same shape as input x.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">plot_activations</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;scatter&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot an input tensor and its corresponding activations.  Both tensors</span>
<span class="sd">    will be flattened for plotting.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    z: tf.Tensor</span>
<span class="sd">        Tensor containing values to plot on the x axis (we can often think of</span>
<span class="sd">        this as the output of a linear layer, where z=f(x) and a=mish(z)).</span>
<span class="sd">    a: tf.Tensor</span>
<span class="sd">        Tensor containing values to plot on y axis.</span>
<span class="sd">    mode: str</span>
<span class="sd">        &#39;scatter&#39; for scatter plot or &#39;plot&#39; for line plot.</span>
<span class="sd">    kwargs: Values to be passed to the matplotlib plotting function, such as </span>
<span class="sd">        &#39;s&#39; when in &#39;scatter&#39; mode or &#39;lw&#39; in &#39;plot&#39; mode.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plt_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">plt</span><span class="p">,</span> <span class="n">mode</span><span class="p">)</span>
    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;scatter&#39;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">:</span> <span class="o">.</span><span class="mi">75</span><span class="p">}</span>
    <span class="n">plt_func</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">lw</span><span class="o">=.</span><span class="mi">5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">05</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">mish</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_activations</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="s1">&#39;plot&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Layer-Blocks">Layer Blocks<a class="anchor-link" href="#Layer-Blocks"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ConvBlock" class="doc_header"><code>class</code> <code>ConvBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L85" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ConvBlock</code>(<strong><code>c_in</code></strong>, <strong><code>c_out</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>norm</code></strong>=<em><code>True</code></em>, <strong><code>activation</code></strong>=<em><code>GReLU(leak=0.1, max=6.0, sub=0.4)</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>

<pre><code>Create a convolutional block optionally followed by a batch norm layer.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">conv</span> <span class="o">=</span> <span class="n">ConvBlock</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">conv</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ConvBlock(
  (block): Sequential(
    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))
    (1): GReLU(leak=0.1, max=6.0, sub=0.4)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 5, 2, 2])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResBlock" class="doc_header"><code>class</code> <code>ResBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L131" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResBlock</code>(<strong><code>c_in</code></strong>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong><code>norm</code></strong>=<em><code>True</code></em>, <strong><code>activation</code></strong>=<em><code>GReLU(leak=0.1, max=6.0, sub=0.4)</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>padding</code></strong>=<em><code>1</code></em>, <strong><code>skip_size</code></strong>=<em><code>2</code></em>, <strong>**<code>kwargs</code></strong>) :: <code>Module</code></p>
</blockquote>

<pre><code>Base class for all neural network modules.

Your models should also subclass this class.

Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::

    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
        def __init__(self):
            super(Model, self).__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

        def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))

Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:`to`, etc.

:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ResBlock</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ResBlock(
  (layers): ModuleList(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ResBlock</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ResBlock(
  (layers): ModuleList(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ReflectionPaddedConv2d" class="doc_header"><code>ReflectionPaddedConv2d</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L189" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ReflectionPaddedConv2d</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>padding</code></strong>=<em><code>1</code></em>, <strong><code>kernel_size</code></strong>=<em><code>3</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>

<pre><code>Conv2d only allows padding_mode of `zeros` or `circular`. This
    layer is a quick way for us to use reflection padding.


Applies a 2D convolution over an input signal composed of several input
    planes.

    In the simplest case, the output value of the layer with input size
    :math:`(N, C_{\text{in}}, H, W)` and output :math:`(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})`
    can be precisely described as:

    .. math::
        \text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
        \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)


    where :math:`\star` is the valid 2D `cross-correlation`_ operator,
    :math:`N` is a batch size, :math:`C` denotes a number of channels,
    :math:`H` is a height of input planes in pixels, and :math:`W` is
    width in pixels.

    This module supports :ref:`TensorFloat32&lt;tf32_on_ampere&gt;`.

    * :attr:`stride` controls the stride for the cross-correlation, a single
      number or a tuple.

    * :attr:`padding` controls the amount of implicit zero-paddings on both
      sides for :attr:`padding` number of points for each dimension.

    * :attr:`dilation` controls the spacing between the kernel points; also
      known as the Ã  trous algorithm. It is harder to describe, but this `link`_
      has a nice visualization of what :attr:`dilation` does.

    * :attr:`groups` controls the connections between inputs and outputs.
      :attr:`in_channels` and :attr:`out_channels` must both be divisible by
      :attr:`groups`. For example,

        * At groups=1, all inputs are convolved to all outputs.
        * At groups=2, the operation becomes equivalent to having two conv
          layers side by side, each seeing half the input channels,
          and producing half the output channels, and both subsequently
          concatenated.
        * At groups= :attr:`in_channels`, each input channel is convolved with
          its own set of filters, of size:
          :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`.

    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

        - a single ``int`` -- in which case the same value is used for the height and width dimension
        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
          and the second `int` for the width dimension

    Note:

         Depending of the size of your kernel, several (of the last)
         columns of the input might be lost, because it is a valid `cross-correlation`_,
         and not a full `cross-correlation`_.
         It is up to the user to add proper padding.

    Note:

        When `groups == in_channels` and `out_channels == K * in_channels`,
        where `K` is a positive integer, this operation is also termed in
        literature as depthwise convolution.

        In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,
        a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments
        :math:`(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})`.

    Note:
        In some circumstances when using the CUDA backend with CuDNN, this operator
        may select a nondeterministic algorithm to increase performance. If this is
        undesirable, you can try to make the operation deterministic (potentially at
        a performance cost) by setting ``torch.backends.cudnn.deterministic =
        True``.
        Please see the notes on :doc:`/notes/randomness` for background.


    Args:
        in_channels (int): Number of channels in the input image
        out_channels (int): Number of channels produced by the convolution
        kernel_size (int or tuple): Size of the convolving kernel
        stride (int or tuple, optional): Stride of the convolution. Default: 1
        padding (int or tuple, optional): Zero-padding added to both sides of
            the input. Default: 0
        padding_mode (string, optional): ``'zeros'``, ``'reflect'``,
            ``'replicate'`` or ``'circular'``. Default: ``'zeros'``
        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1
        groups (int, optional): Number of blocked connections from input
            channels to output channels. Default: 1
        bias (bool, optional): If ``True``, adds a learnable bias to the
            output. Default: ``True``

    Shape:
        - Input: :math:`(N, C_{in}, H_{in}, W_{in})`
        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where

          .. math::
              H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
                        \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

          .. math::
              W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
                        \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

    Attributes:
        weight (Tensor): the learnable weights of the module of shape
            :math:`(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},`
            :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]})`.
            The values of these weights are sampled from
            :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
            :math:`k = \frac{groups}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`
        bias (Tensor):   the learnable bias of the module of shape
            (out_channels). If :attr:`bias` is ``True``,
            then the values of these weights are
            sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
            :math:`k = \frac{groups}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`

    Examples:

        &gt;&gt;&gt; # With square kernels and equal stride
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, 3, stride=2)
        &gt;&gt;&gt; # non-square kernels and unequal stride and with padding
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
        &gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
        &gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)
        &gt;&gt;&gt; output = m(input)

    .. _cross-correlation:
        https://en.wikipedia.org/wiki/Cross-correlation

    .. _link:
        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_img</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rconv</span> <span class="o">=</span> <span class="n">ReflectionPaddedConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">rconv</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ReflectionPaddedConv2d(
  (reflect): ReflectionPad2d((2, 2, 2, 2))
  (conv): Conv2d(3, 3, kernel_size=(1, 1), stride=(1, 1))
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">show_img</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">rconv</span><span class="o">.</span><span class="n">reflect</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">show_img</span><span class="p">(</span><span class="n">x2</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Tests</span>
<span class="k">assert</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="o">.</span><span class="vm">__doc__</span> <span class="ow">in</span> <span class="n">ReflectionPaddedConv2d</span><span class="o">.</span><span class="vm">__doc__</span>

<span class="k">with</span> <span class="n">assert_raises</span><span class="p">(</span><span class="n">InvalidArgumentError</span><span class="p">):</span>
    <span class="n">ReflectionPaddedConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>As expected, got InvalidArgumentError(Remove `padding_mode` from arguments.).
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SmoothSoftmaxBase" class="doc_header"><code>class</code> <code>SmoothSoftmaxBase</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L211" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SmoothSoftmaxBase</code>(<strong><code>log</code></strong>=<em><code>False</code></em>, <strong><code>temperature</code></strong>=<em><code>'auto'</code></em>, <strong><code>dim</code></strong>=<em><code>-1</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Parent class of SmoothSoftmax and SmoothLogSoftmax (softmax or log
softmax with temperature baked in). There shouldn't be a need to
instantiate this class directly.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SmoothSoftmax" class="doc_header"><code>class</code> <code>SmoothSoftmax</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L265" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SmoothSoftmax</code>(<strong><code>temperature</code></strong>=<em><code>'auto'</code></em>, <strong><code>dim</code></strong>=<em><code>-1</code></em>) :: <a href="/incendio/layers#SmoothSoftmaxBase"><code>SmoothSoftmaxBase</code></a></p>
</blockquote>

<pre><code>Parent class of SmoothSoftmax and SmoothLogSoftmax (softmax or log
softmax with temperature baked in). There shouldn't be a need to
instantiate this class directly.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SmoothLogSoftmax" class="doc_header"><code>class</code> <code>SmoothLogSoftmax</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L272" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SmoothLogSoftmax</code>(<strong><code>temperature</code></strong>=<em><code>'auto'</code></em>, <strong><code>dim</code></strong>=<em><code>-1</code></em>) :: <a href="/incendio/layers#SmoothSoftmaxBase"><code>SmoothSoftmaxBase</code></a></p>
</blockquote>

<pre><code>Parent class of SmoothSoftmax and SmoothLogSoftmax (softmax or log
softmax with temperature baked in). There shouldn't be a need to
instantiate this class directly.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SpatialSoftmax" class="doc_header"><code>class</code> <code>SpatialSoftmax</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L279" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SpatialSoftmax</code>(<strong><code>temperature</code></strong>=<em><code>'auto'</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Apply softmax over the height and width dimensions of a batch of image
tensors (or image-like tensors). Concretely, inputs will usually have
shape (batch size, channels, height, width), while outputs will have the
same shape but values for each feature map will now sum to 1. Essentially,
we now have a heatmap of what region in each image to focus on.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Dropin" class="doc_header"><code>class</code> <code>Dropin</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L298" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Dropin</code>(<strong><code>scale</code></strong>=<em><code>0.5</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Additive dropout. This injects small amounts of noise into a model
in the form of randomly generated floats from a zero-centered
gaussian distribution (variance can be adjusted). This does nothing
in eval mode. Unlike Dropout, this does not scale weights during
training since it does not bias them in any direction.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">drop</span> <span class="o">=</span> <span class="n">Dropin</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="o">.</span><span class="mi">9</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">net</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
<span class="k">assert</span> <span class="ow">not</span> <span class="n">net</span><span class="o">.</span><span class="n">drop</span><span class="o">.</span><span class="n">training</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">simulate_activation_stats</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">trials</span><span class="o">=</span><span class="mi">10_000</span><span class="p">):</span>
    <span class="n">act_stats</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">noise_stats</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    
    <span class="n">drop</span> <span class="o">=</span> <span class="n">Dropin</span><span class="p">(</span><span class="n">scale</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">trials</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">drop</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">drop</span><span class="o">.</span><span class="n">noise</span>
        <span class="n">noise_stats</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">noise_stats</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">noise</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
        <span class="n">noise_stats</span><span class="p">[</span><span class="s1">&#39;act_corr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">noise</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>
        
        <span class="n">act_stats</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">act_stats</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">std</span><span class="p">())</span>
        <span class="n">act_stats</span><span class="p">[</span><span class="s1">&#39;x_corr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">corrcoef</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">())[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span>
        <span class="n">act</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">act_stats</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span> 
        <span class="n">noise</span><span class="o">=</span><span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="p">)</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">noise_stats</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">scale</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">.</span><span class="mi">75</span><span class="p">,</span> <span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">25</span><span class="p">,</span> <span class="o">.</span><span class="mi">1</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
    <span class="n">simulate_activation_stats</span><span class="p">(</span><span class="n">scale</span><span class="p">,</span> <span class="mi">1_000</span><span class="p">)</span><span class="o">.</span><span class="n">pprint</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 10
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.0132</td>
      <td>0.0094</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.8189</td>
      <td>1.5192</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.5324</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.8304</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 1
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>-0.0141</td>
      <td>0.0034</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.0921</td>
      <td>0.4870</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.8855</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.4282</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 0.75
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>-0.0015</td>
      <td>0.0022</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.0633</td>
      <td>0.4240</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.9100</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.3899</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 0.5
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.0107</td>
      <td>0.0008</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.0558</td>
      <td>0.3442</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.9409</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.3235</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 0.25
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>0.0098</td>
      <td>-0.0057</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.0013</td>
      <td>0.2461</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.9667</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.2298</td>
    </tr>
  </tbody>
</table>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>
 0.1
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>act</th>
      <th>noise</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>mean</th>
      <td>-0.0057</td>
      <td>-0.0014</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.9969</td>
      <td>0.1533</td>
    </tr>
    <tr>
      <th>x_corr</th>
      <td>0.9868</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>act_corr</th>
      <td>NaN</td>
      <td>0.1394</td>
    </tr>
  </tbody>
</table>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LinearSkipBlock" class="doc_header"><code>class</code> <code>LinearSkipBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L331" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LinearSkipBlock</code>(<strong><code>x_dim</code></strong>, <strong><code>layer_dims</code></strong>, <strong><code>op</code></strong>, <strong><code>activation</code></strong>=<em><code>'mish'</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>This lets us easily create residual block equivalents with linear
layers.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LinearResBlock" class="doc_header"><code>class</code> <code>LinearResBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L371" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LinearResBlock</code>(<strong><code>x_dim</code></strong>, <strong><code>hidden_dims</code></strong>, <strong><code>activation</code></strong>=<em><code>'mish'</code></em>) :: <a href="/incendio/layers#LinearSkipBlock"><code>LinearSkipBlock</code></a></p>
</blockquote>

<pre><code>Equivalent of ResNet block with linear layers.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LinearDenseBlock" class="doc_header"><code>class</code> <code>LinearDenseBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L383" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LinearDenseBlock</code>(<strong><code>x_dim</code></strong>, <strong><code>hidden_dims</code></strong>, <strong><code>activation</code></strong>=<em><code>'mish'</code></em>) :: <a href="/incendio/layers#LinearSkipBlock"><code>LinearSkipBlock</code></a></p>
</blockquote>

<pre><code>Equivalent of DenseNet block with linear layers.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="WeightedLinearResBlock" class="doc_header"><code>class</code> <code>WeightedLinearResBlock</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L391" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>WeightedLinearResBlock</code>(<strong><code>x_dim</code></strong>, <strong><code>hidden_dims</code></strong>, <strong><code>weights</code></strong>=<em><code>(0.25, 0.75)</code></em>, <strong><code>activation</code></strong>=<em><code>'mish'</code></em>) :: <a href="/incendio/layers#LinearSkipBlock"><code>LinearSkipBlock</code></a></p>
</blockquote>

<pre><code>Like a LinearResBlock but takes a weighted average of the input and
output rather than adding them. Addition gives them equal weight and we
may want to weight the output more heavily.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SkipConnection" class="doc_header"><code>class</code> <code>SkipConnection</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L405" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SkipConnection</code>(<strong><code>block</code></strong>, <strong><code>op</code></strong>=<em><code>'add'</code></em>, <strong><code>input_weight</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>More generalized version of skip connection. Eventually maybe rewrite
various res/dense/weighted conv blocks with this.

Examples
--------
&gt;&gt; x = torch.randn(3, 4)
&gt;&gt; dense = nn.Linear(4, 2)
&gt;&gt; dense(x).shape

torch.Size([3, 2])

&gt;&gt; skip = SkipConnection(dense, op='cat')
&gt;&gt; skip(x).shape

torch.Size([3, 6])

&gt;&gt; skip = SkipConnection(dense, op='add')
&gt;&gt; skip(x).shape

RuntimeError: The size of tensor a (4) must match the size of tensor b (2)
at non-singleton dimension 1</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Embeddings-and-Encodings">Embeddings and Encodings<a class="anchor-link" href="#Embeddings-and-Encodings"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="trunc_normal_" class="doc_header"><code>trunc_normal_</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L498" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>trunc_normal_</code>(<strong><code>x</code></strong>, <strong><code>mean</code></strong>=<em><code>0.0</code></em>, <strong><code>std</code></strong>=<em><code>1.0</code></em>)</p>
</blockquote>

<pre><code>Ported from fastai to remove dependency:

Truncated normal initialization.
From https://discuss.pytorch.org/t/implementing-truncated-normal-initializer/4778/12</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="InitializedEmbedding" class="doc_header"><code>class</code> <code>InitializedEmbedding</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L508" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>InitializedEmbedding</code>(<strong><code>num_embeddings</code></strong>:<code>int</code>, <strong><code>embedding_dim</code></strong>:<code>int</code>, <strong><code>padding_idx</code></strong>:<code>Optional</code>[<code>int</code>]=<em><code>None</code></em>, <strong><code>max_norm</code></strong>:<code>Optional</code>[<code>float</code>]=<em><code>None</code></em>, <strong><code>norm_type</code></strong>:<code>float</code>=<em><code>2.0</code></em>, <strong><code>scale_grad_by_freq</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>sparse</code></strong>:<code>bool</code>=<em><code>False</code></em>, <strong><code>_weight</code></strong>:<code>Optional</code>[<code>Tensor</code>]=<em><code>None</code></em>) :: <code>Embedding</code></p>
</blockquote>

<pre><code>Same as nn.Embedding but with truncated normal initialization. This
also differs from fastai's Embedding class in that it allows padding.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">InitializedEmbedding</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[ 0.0000,  0.0000,  0.0000],
        [ 0.0031, -0.0033, -0.0013],
        [ 0.0076, -0.0107,  0.0008],
        [ 0.0119, -0.0014,  0.0027]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">InitializedEmbedding</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[ 0.0038, -0.0103, -0.0074],
        [ 0.0104, -0.0036,  0.0039],
        [-0.0007,  0.0008,  0.0191],
        [ 0.0000,  0.0000,  0.0000]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">InitializedEmbedding</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[-0.0082,  0.0058, -0.0055],
        [-0.0104, -0.0144,  0.0036],
        [ 0.0028, -0.0020, -0.0009],
        [ 0.0046, -0.0088, -0.0026]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BloomEmbedding" class="doc_header"><code>class</code> <code>BloomEmbedding</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L521" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BloomEmbedding</code>(<strong><code>n_emb</code></strong>=<em><code>251</code></em>, <strong><code>emb_dim</code></strong>=<em><code>100</code></em>, <strong><code>n_hashes</code></strong>=<em><code>4</code></em>, <strong><code>padding_idx</code></strong>=<em><code>0</code></em>, <strong><code>pre_hashed</code></strong>=<em><code>False</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Bloom Embedding layer for memory-efficient word representations.
Each word is encoded by a combination of rows of the embedding
matrix. The number of rows can therefore be far lower than the number
of words in our vocabulary while still providing unique representations.
The reduction in rows allows us to use memory in other ways: a larger
embedding dimension, more or larger layers after the embedding,
larger batch sizes, etc.

Note that if hashing is done in the Dataset, we could use a simple
nn.EmbeddingBag to achieve the same thing. Many users have reported
poor performance with this layer though (especially on CPU, but in some
cases on GPU) so I stick with the standard Embedding. We also bake in
the truncated normal intialization provided by fastai, with a slight tweak
to allow a row for padding.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Data</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_w2i</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">make_w2i</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tok_rows</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> 
                <span class="nb">enumerate</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">tok_rows</span><span class="p">))</span><span class="o">.</span><span class="n">most_common</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)}</span>
    
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tok_rows</span><span class="p">):</span>
        <span class="n">enc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">tok_rows</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tok_rows</span><span class="p">):</span>
            <span class="n">trunc</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w2i</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">]]</span>
            <span class="n">enc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">trunc</span><span class="p">)]</span> <span class="o">=</span> <span class="n">trunc</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">enc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;I walked to the store so I hope it is not closed.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The theater is closed today and the sky is grey.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;His dog is brown while hers is grey.&#39;</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">ds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4]), tensor(1))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]),
 tensor([0, 1, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]),
 tensor([0, 1, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">be</span> <span class="o">=</span> <span class="n">BloomEmbedding</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">be</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [-1.3866e-02,  2.7083e-03,  1.9108e-03,  2.3947e-03],
        [ 5.0557e-03, -4.8774e-03,  1.5206e-03,  1.0080e-03],
        [ 4.5406e-05,  2.1932e-03, -9.5886e-03,  4.7936e-03],
        [-9.7800e-03,  1.9145e-02,  2.4422e-03,  1.2713e-02],
        [ 1.2850e-02,  4.0345e-03, -1.9255e-02, -2.5600e-03],
        [ 5.7765e-03,  1.4253e-02,  1.8160e-02, -1.6686e-02],
        [ 1.2343e-02,  2.8021e-03,  9.5432e-04,  4.2866e-03],
        [ 6.4279e-03, -3.4935e-03, -1.9902e-03, -9.9574e-03],
        [ 9.7122e-04, -6.8190e-03, -1.2612e-02, -1.6921e-03],
        [-1.1588e-02, -4.2316e-03, -9.5648e-03, -6.5988e-03]],
       requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># (bs x seq_len) -&gt; (bs -&gt; seq_len -&gt; emb_size)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">be</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 10, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 0.0363, -0.0098,  0.0052,  0.0023],
        [ 0.0337, -0.0130, -0.0147, -0.0183],
        [ 0.0075, -0.0316,  0.0120,  0.0236],
        [ 0.0304, -0.0328,  0.0388, -0.0240],
        [ 0.0144,  0.0004, -0.0022,  0.0019],
        [ 0.0084,  0.0117,  0.0089, -0.0284],
        [ 0.0363, -0.0098,  0.0052,  0.0023],
        [ 0.0177, -0.0087,  0.0344, -0.0139],
        [ 0.0272, -0.0108, -0.0036,  0.0130],
        [ 0.0035, -0.0162,  0.0048,  0.0260]], grad_fn=&lt;SelectBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below, we show by step how to get from x to y. This is meant to demonstrate the basic mechanism, not to show how PyTorch actually implements this under the hood. Let's look at a single row of x, corresponding to 1 sentence where each word is mapped to its index in the vocabulary.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we hash each item.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hashed</span> <span class="o">=</span> <span class="p">[</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">11</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
<span class="n">hashed</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[[8, 2, 7, 8],
 [2, 8, 1, 2],
 [6, 6, 10, 10],
 [10, 5, 5, 5],
 [6, 9, 7, 2],
 [5, 9, 4, 0],
 [8, 2, 7, 8],
 [5, 10, 8, 9],
 [7, 8, 6, 2],
 [6, 10, 6, 0]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then use each row of hashed integers to index into the embedding weight matrix.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">hashed</span><span class="p">:</span>
    <span class="n">row_out</span> <span class="o">=</span> <span class="n">be</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">row</span><span class="p">]</span>
    <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row_out</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">output</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([10, 4, 4])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[ 0.0089,  0.0007,  0.0076,  0.0034],
         [ 0.0097,  0.0003, -0.0098, -0.0082],
         [ 0.0089, -0.0114, -0.0001,  0.0037],
         [ 0.0089,  0.0007,  0.0076,  0.0034]],

        [[ 0.0097,  0.0003, -0.0098, -0.0082],
         [ 0.0089,  0.0007,  0.0076,  0.0034],
         [ 0.0054, -0.0142, -0.0027, -0.0052],
         [ 0.0097,  0.0003, -0.0098, -0.0082]]], grad_fn=&lt;SliceBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we sum up the embedding rows. Above, each word is represented by four rows of the embedding matrix. After summing, we get a single vector for each word.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
<span class="n">output</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 0.0363, -0.0098,  0.0052,  0.0023],
        [ 0.0337, -0.0130, -0.0147, -0.0183],
        [ 0.0075, -0.0316,  0.0120,  0.0236],
        [ 0.0304, -0.0328,  0.0388, -0.0240],
        [ 0.0144,  0.0004, -0.0022,  0.0019],
        [ 0.0084,  0.0117,  0.0089, -0.0284],
        [ 0.0363, -0.0098,  0.0052,  0.0023],
        [ 0.0177, -0.0087,  0.0344, -0.0139],
        [ 0.0272, -0.0108, -0.0036,  0.0130],
        [ 0.0035, -0.0162,  0.0048,  0.0260]], grad_fn=&lt;SumBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Notice that the values now match the output of our embedding layer.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Axial encodings are intended to work as positional embeddings for transformer-like architectures. It's possible they could work for word embeddings as well, similar to our use of Bloom embeddings. However, the standard version of axial encodings results in similar vectors for adjacent indices - this makes some sense for positional indices, but for word indices it might require some additional preprocessing. For example, we could compress word embeddings down to 1 dimension and sort them, or simply sort by number of occurrences in our corpus which could be considered to be doing the same thing. Large chunks of the outputs vectors will be shared among different inputs, whereas Bloom embeddings seem like they would have a greater capacity to avoid this issue.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="AxialEncoding" class="doc_header"><code>class</code> <code>AxialEncoding</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L610" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>AxialEncoding</code>(<strong><code>vocab_dim</code></strong>, <strong><code>emb_dim</code></strong>, <strong><code>pad_idx</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Axial encodings. These are intended to encode position in a sequence
(e.g. index in a sentence). It's possible we could adapt these for use as
word embeddings but this would likely require some experimentation (for
example, words would likely need to be sorted in a thoughtful manner
(e.g. pre-trained embeddings compressed to 1D?) since adjacent inputs will
share half of their encodings).</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="MultiAxialEncoding" class="doc_header"><code>class</code> <code>MultiAxialEncoding</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L655" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>MultiAxialEncoding</code>(<strong><code>vocab_dim</code></strong>, <strong><code>emb_dim</code></strong>, <strong><code>n_blocks</code></strong>=<em><code>2</code></em>, <strong><code>pre_hashed</code></strong>=<em><code>False</code></em>, <strong><code>pad_idx</code></strong>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>

<pre><code>Adapted axial encodings to allow for more than 2 embedding matrices.
These are intended to encode position in a sequence (e.g. index in a
sentence) but might work as word embeddings. This version may be better
suited for that use case because using more blocks results in fewer shared
numbers in the output vectors of adjacent inputs.

Some experimentation is still required for this use case (for
example, words would likely need to be sorted in a thoughtful manner
(e.g. pre-trained embeddings compressed to 1D?) since adjacent inputs will
share half of their encodings).

I made this separate from AxialEncoding (at least for now) since I made a
few tweaks to the original design to make this possible and I wanted to
preserve the option to use the simpler, well-tested method
(AxialEncoding). Here, we use a probabilistic hashing scheme to map each
input to multiple embedding rows, while the original design uses
x%v and x//v.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">reduction_ratio</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For testing purposes. Lets us compare the number of weights in a</span>
<span class="sd">    traditional embedding matrix vs. the number of weights in our axial</span>
<span class="sd">    encoding.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">normal_n</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">*</span> <span class="n">emb_dim</span>
    <span class="n">ax_n</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">e</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="n">ax</span><span class="o">.</span><span class="n">emb</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Normal embedding weights:&#39;</span><span class="p">,</span> <span class="n">normal_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Axial encoding weights:&#39;</span><span class="p">,</span> <span class="n">ax_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Difference:&#39;</span><span class="p">,</span> <span class="n">normal_n</span> <span class="o">-</span> <span class="n">ax_n</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Ratio:&#39;</span><span class="p">,</span> <span class="n">normal_n</span> <span class="o">/</span> <span class="n">ax_n</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">30_000</span>
<span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">AxialEncoding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ax</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([12, 2])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>AxialEncoding(
  (emb): ModuleList(
    (0): InitializedEmbedding(174, 50)
    (1): InitializedEmbedding(174, 50)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">ax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([12, 2, 100])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reduction_ratio</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Normal embedding weights: 3000000
Axial encoding weights: 17400
Difference: 2982600
Ratio: 172.41379310344828
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">30_000</span>
<span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">MultiAxialEncoding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">ax</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([12, 2])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>MultiAxialEncoding(
  (emb): ModuleList(
    (0): Embedding(14, 25)
    (1): Embedding(14, 25)
    (2): Embedding(14, 25)
    (3): Embedding(14, 25)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">res1</span> <span class="o">=</span> <span class="n">ax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">res1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([12, 2, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">30_000</span>
<span class="n">emb_dim</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">bs</span> <span class="o">=</span> <span class="mi">12</span>

<span class="n">ax_pre</span> <span class="o">=</span> <span class="n">MultiAxialEncoding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">pre_hashed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax_pre</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>MultiAxialEncoding(
  (emb): ModuleList(
    (0): Embedding(14, 25)
    (1): Embedding(14, 25)
    (2): Embedding(14, 25)
    (3): Embedding(14, 25)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By setting the weights of our pre-hashed embedding to the weights of our hashing embedding, we can check that the outputs are ultimately the same.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">e</span><span class="p">,</span> <span class="n">e_pre</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">emb</span><span class="p">,</span> <span class="n">ax_pre</span><span class="o">.</span><span class="n">emb</span><span class="p">):</span>
    <span class="n">e_pre</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">xhash</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">res2</span> <span class="o">=</span> <span class="n">ax_pre</span><span class="p">(</span><span class="n">xhash</span><span class="p">)</span>
<span class="n">res2</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([12, 2, 100])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">res1</span> <span class="o">==</span> <span class="n">res2</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reduction_ratio</span><span class="p">(</span><span class="n">ax_pre</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Normal embedding weights: 3000000
Axial encoding weights: 1400
Difference: 2998600
Ratio: 2142.8571428571427
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I imagine that as we increase <code>n_blocks</code>, there's likely a point where we simply won't have enough weights to encode the amount of information that's present in the data. It would take some experimentation to find where that line is, however.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ax_large</span> <span class="o">=</span> <span class="n">MultiAxialEncoding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">pre_hashed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax_large</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>MultiAxialEncoding(
  (emb): ModuleList(
    (0): Embedding(4, 12)
    (1): Embedding(4, 12)
    (2): Embedding(4, 12)
    (3): Embedding(4, 12)
    (4): Embedding(4, 12)
    (5): Embedding(4, 12)
    (6): Embedding(4, 12)
    (7): Embedding(4, 12)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">reduction_ratio</span><span class="p">(</span><span class="n">ax_large</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Normal embedding weights: 3000000
Axial encoding weights: 384
Difference: 2999616
Ratio: 7812.5
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Model-Bases">Model Bases<a class="anchor-link" href="#Model-Bases"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SiameseBase" class="doc_header"><code>class</code> <code>SiameseBase</code><a href="https://github.com/hdmamin/incendio/tree/master/incendio/layers.py#L708" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SiameseBase</code>() :: <a href="/incendio/core#BaseModel"><code>BaseModel</code></a></p>
</blockquote>

<pre><code>Parent class to implement a Siamese network or triplet network (or any
network that passes n inputs of the same shape through a shared encoder).
It concatenates the items into a single batch so the encoder's forward
method (implemented as self._forward) only needs to be called once.</code></pre>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">xb</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span>
<span class="n">smap</span><span class="p">(</span><span class="o">*</span><span class="n">xb</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[torch.Size([4, 3, 8, 8]), torch.Size([4, 3, 8, 8]), torch.Size([4, 3, 8, 8])]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">TripletNet</span><span class="p">(</span><span class="n">SiameseBase</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">c_in</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="nf">_forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xb</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">xb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">xb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">xb</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">xb</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this example, each image is encoded as a 16D vector. We have 3 images per row and 4 rows per batch so we end up with a tensor of shape (4, 3, 16). Notice we only perform 1 forward pass: while we could simply define a separate encoder and pass each image through it separately (e.g. <code>[self.encoder(x) for x in xb]</code>), this becomes rather slow if n is large or if our encoder is enormous.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tnet</span> <span class="o">=</span> <span class="n">TripletNet</span><span class="p">()</span>
<span class="n">yh</span> <span class="o">=</span> <span class="n">tnet</span><span class="p">(</span><span class="o">*</span><span class="n">xb</span><span class="p">)</span>
<span class="n">yh</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([12, 3, 8, 8])
torch.Size([12, 16, 3, 3])
torch.Size([12, 16, 1, 1])
torch.Size([12, 16])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 3, 16])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our name TripletNet was slightly misleading here: the network can actually handle any choice of n. For instance, here we use it as a Siamese Net.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">yh</span> <span class="o">=</span> <span class="n">tnet</span><span class="p">(</span><span class="o">*</span><span class="n">xb</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">yh</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([8, 3, 8, 8])
torch.Size([8, 16, 3, 3])
torch.Size([8, 16, 1, 1])
torch.Size([8, 16])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 2, 16])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

