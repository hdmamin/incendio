---

title: Title

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/scratch_torch_resnet_tabular.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">from</span> <span class="nn">operator</span> <span class="k">import</span> <span class="n">add</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">htools</span> <span class="k">import</span> <span class="n">InvalidArgumentError</span>
<span class="kn">from</span> <span class="nn">incendio.core</span> <span class="k">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span> <span class="nn">incendio.layers</span> <span class="k">import</span> <span class="n">JRelu</span><span class="p">,</span> <span class="n">GRelu</span><span class="p">,</span> <span class="n">mish</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Experimenting">Experimenting<a class="anchor-link" href="#Experimenting"> </a></h2><p>Maybe skip connections could be useful for tabular data? Apparently usually not useful, maybe if network is very deep. Similar idea may be used here: <a href="https://arxiv.org/abs/1708.05123">https://arxiv.org/abs/1708.05123</a></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># class DenseLinear(BaseModel):</span>
    
<span class="c1">#     def __init__(self, x_dim, hidden_dim, activation=mish, skip_size=2):</span>
<span class="c1">#         super().__init__()</span>
<span class="c1">#         assert hidden_dim &gt;= 2 ** (skip_size-1), (&#39;Increase hidden dimension &#39;</span>
<span class="c1">#                                                   &#39;or decrease skip size.&#39;)</span>
        
<span class="c1">#         self.activation = activation</span>
<span class="c1">#         self.skip_size = skip_size</span>
<span class="c1">#         self.layers = nn.ModuleList([nn.Linear(x_dim, hidden_dim)])</span>
        
<span class="c1">#         prev_dim = hidden_dim</span>
<span class="c1">#         for i in range(1, skip_size):</span>
<span class="c1">#             new_dim = prev_dim // 2</span>
<span class="c1">#             new_layer = nn.Linear(prev_dim, new_dim)</span>
<span class="c1">#             self.layers.append(new_layer)</span>
<span class="c1">#             prev_dim = new_dim</span>
            
<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         out = x</span>
<span class="c1">#         for i, layer in enumerate(self.layers):</span>
<span class="c1">#             out = layer(out)</span>
<span class="c1">#             if i != self.skip_size - 1:</span>
<span class="c1">#                 out = self.activation(out)</span>
<span class="c1">#         return self.activation(torch.cat((x, out), dim=1))</span>

<span class="k">class</span> <span class="nc">DenseLinear</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">layer_dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">mish</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span> <span class="k">for</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span>
                                     <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">x_dim</span><span class="p">]</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">),</span> <span class="n">layer_dims</span><span class="p">)])</span>
            
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_size</span><span class="p">:</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">concat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="n">dim</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LinearSkipBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">layer_dims</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">mish</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skip_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span><span class="p">)</span> <span class="k">for</span> <span class="n">d_in</span><span class="p">,</span> <span class="n">d_out</span>
                                     <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">x_dim</span><span class="p">]</span><span class="o">+</span><span class="nb">list</span><span class="p">(</span><span class="n">layer_dims</span><span class="p">),</span> <span class="n">layer_dims</span><span class="p">)])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">op</span> <span class="o">=</span> <span class="n">op</span>
            
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">skip_size</span><span class="p">:</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">op</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># class ResLinear(BaseModel):</span>
    
<span class="c1">#     def __init__(self, x_dim, hidden_dims, activation=JRelu):</span>
<span class="c1">#         super().__init__()</span>
<span class="c1">#         self.skip_size = len(hidden_dims)</span>
<span class="c1">#         self.activation = activation</span>
<span class="c1">#         self.layers = nn.ModuleList([</span>
<span class="c1">#             nn.Linear(in_dim, out_dim) for in_dim, out_dim </span>
<span class="c1">#             in zip([x_dim] + list(hidden_dims), list(hidden_dims) + [x_dim])</span>
<span class="c1">#         ])</span>
    
<span class="c1">#     def forward(self, x):</span>
<span class="c1">#         out = x</span>
<span class="c1">#         for i, layer in enumerate(self.layers):</span>
<span class="c1">#             out = layer(out)</span>
<span class="c1">#             if i != self.skip_size - 1:</span>
<span class="c1">#                 out = self.activation(out)</span>
<span class="c1">#         return self.activation(x + out)</span>

<span class="k">class</span> <span class="nc">LinearResBlock</span><span class="p">(</span><span class="n">LinearSkipBlock</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">mish</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">hidden_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="n">x_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">InvalidArgumentError</span><span class="p">(</span>
                <span class="s1">&#39;Last hidden dimension must match input dimension.&#39;</span>
            <span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">add</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">LinearDenseBlock</span><span class="p">(</span><span class="n">LinearSkipBlock</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">mish</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">,</span> <span class="n">concat</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">i</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">2</span>
<span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">i</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[3]],

        [[5]],

        [[1]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t1</span><span class="o">.</span><span class="n">ndim</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>2</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">weighted_avg</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">weights</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">total</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span> <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span> <span class="o">/</span> <span class="n">total</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
    <span class="n">weights_shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">ndim</span><span class="p">))]</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">res</span> <span class="o">*</span> <span class="n">weights</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">*</span><span class="n">weights_shape</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([0., 1., 2., 3., 4.]) tensor([1., 1., 1., 1., 1.]) tensor([-0.9681,  0.8185,  0.4446,  0.6494,  1.6390])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weighted_avg</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span>  <span class="n">t3</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 0.0000,  0.3333,  0.6667,  1.0000,  1.3333],
        [ 0.5556,  0.5556,  0.5556,  0.5556,  0.5556],
        [-0.1076,  0.0909,  0.0494,  0.0722,  0.1821]])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([0.1493, 0.3266, 0.4239, 0.5426, 0.6903])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">t1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span> <span class="n">t3</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0., 1.],
        [2., 3.],
        [4., 5.]])
tensor([[1., 1.],
        [1., 1.],
        [1., 1.]])
tensor([[-0.8853, -0.8809],
        [ 0.5187, -0.9115],
        [-1.2926,  0.5497]])
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weighted_avg</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">t2</span><span class="p">,</span>  <span class="n">t3</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[[ 0.0000,  0.3333],
         [ 0.6667,  1.0000],
         [ 1.3333,  1.6667]],

        [[ 0.5556,  0.5556],
         [ 0.5556,  0.5556],
         [ 0.5556,  0.5556]],

        [[-0.0984, -0.0979],
         [ 0.0576, -0.1013],
         [-0.1436,  0.0611]]])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.1524, 0.2637],
        [0.4266, 0.4848],
        [0.5818, 0.7611]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mf">0.3333</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.5556</span><span class="p">],</span>
        <span class="p">[</span><span class="mf">0.1111</span><span class="p">]])</span><span class="o">.</span><span class="n">shape</span>
<span class="c1"># * torch.tensor([[[ 0.0000,  1.0000],</span>
<span class="c1">#          [ 2.0000,  3.0000],</span>
<span class="c1">#          [ 4.0000,  5.0000]],</span>

<span class="c1">#         [[ 1.0000,  1.0000],</span>
<span class="c1">#          [ 1.0000,  1.0000],</span>
<span class="c1">#          [ 1.0000,  1.0000]],</span>

<span class="c1">#         [[-1.5408, -0.7166],</span>
<span class="c1">#          [ 0.6646,  0.2769],</span>
<span class="c1">#          [-0.3888,  0.1351]]])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 1])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearDenseBlock</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="p">[</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[2., 2., 0., 0., 0., 4.],
        [4., 0., 3., 1., 1., 4.],
        [2., 4., 0., 1., 3., 4.],
        [2., 1., 0., 2., 0., 4.]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LinearDenseBlock(
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=9, bias=True)
    (2): Linear(in_features=9, out_features=3, bias=True)
    (3): Linear(in_features=3, out_features=5, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">out</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 2.0000e+00,  2.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          4.0000e+00, -1.7781e-01,  3.1595e-03,  2.1543e-01, -4.4647e-01,
         -4.8824e-01],
        [ 4.0000e+00,  0.0000e+00,  3.0000e+00,  1.0000e+00,  1.0000e+00,
          4.0000e+00, -1.7555e-01, -3.0404e-03,  2.7364e-01, -3.9930e-01,
         -4.9190e-01],
        [ 2.0000e+00,  4.0000e+00,  0.0000e+00,  1.0000e+00,  3.0000e+00,
          4.0000e+00, -2.3689e-01, -1.3044e-02,  2.6283e-01, -4.1826e-01,
         -4.2047e-01],
        [ 2.0000e+00,  1.0000e+00,  0.0000e+00,  2.0000e+00,  0.0000e+00,
          4.0000e+00, -2.0205e-01, -2.1700e-03,  2.3462e-01, -4.3416e-01,
         -4.6056e-01]], grad_fn=&lt;CatBackward&gt;)
torch.Size([4, 11])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 1.9440e+00,  1.9440e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,
          3.9974e+00, -9.6526e-02,  1.8989e-03,  1.4385e-01, -2.0443e-01,
         -2.1730e-01],
        [ 3.9974e+00,  0.0000e+00,  2.9865e+00,  8.6510e-01,  8.6510e-01,
          3.9974e+00, -9.5423e-02, -1.8213e-03,  1.8756e-01, -1.8867e-01,
         -2.1838e-01],
        [ 1.9440e+00,  3.9974e+00,  0.0000e+00,  8.6510e-01,  2.9865e+00,
          3.9974e+00, -1.2411e-01, -7.7718e-03,  1.7930e-01, -1.9516e-01,
         -1.9591e-01],
        [ 1.9440e+00,  8.6510e-01,  0.0000e+00,  1.9440e+00,  0.0000e+00,
          3.9974e+00, -1.0811e-01, -1.3005e-03,  1.5804e-01, -2.0044e-01,
         -2.0888e-01]], grad_fn=&lt;MulBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">trainable</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[((16, 6), True),
 ((16,), True),
 ((9, 16), True),
 ((9,), True),
 ((3, 9), True),
 ((3,), True),
 ((5, 3), True),
 ((5,), True)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">dims</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(16, 6), (16,), (8, 16), (8,)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[4., 0., 0., 1., 2., 2.],
        [4., 0., 1., 0., 2., 3.],
        [0., 3., 3., 0., 3., 1.],
        [2., 0., 4., 4., 0., 4.]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ResLinear</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="p">[</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0., 4., 0., 4., 1., 3.],
        [1., 0., 2., 0., 0., 1.],
        [4., 0., 0., 3., 3., 3.],
        [2., 0., 0., 0., 4., 3.]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>ResLinear(
  (activation): GReLU(leak=0.1, max=6.0, sub=0.4)
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=12, bias=True)
    (2): Linear(in_features=12, out_features=6, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 6])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearResBlock</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="p">[</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="o">//</span><span class="mi">4</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[4., 2., 4., 1., 3., 0.],
        [4., 3., 4., 4., 0., 4.],
        [4., 1., 0., 3., 2., 3.],
        [1., 2., 1., 3., 0., 1.]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LinearResBlock(
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=16, bias=True)
    (1): Linear(in_features=16, out_features=4, bias=True)
    (2): Linear(in_features=4, out_features=6, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 4.1386,  1.9666,  3.6655,  0.9114,  3.2314, -0.0582],
        [ 4.0349,  3.1004,  3.5271,  3.9476,  0.2363,  3.9812],
        [ 4.1243,  1.1191, -0.3778,  2.7918,  2.3451,  2.6615],
        [ 1.1321,  2.1452,  0.5129,  2.9463,  0.3553,  0.8902]],
       grad_fn=&lt;AddBackward0&gt;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 6])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">feature_dim</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">LinearResBlock</span><span class="p">(</span><span class="n">feature_dim</span><span class="p">,</span> <span class="p">[</span><span class="n">feature_dim</span><span class="p">])</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">feature_dim</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[4., 2., 3., 1., 0., 0.],
        [2., 2., 3., 0., 4., 4.],
        [4., 0., 1., 2., 2., 0.],
        [2., 0., 1., 0., 0., 2.]])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>LinearResBlock(
  (layers): ModuleList(
    (0): Linear(in_features=6, out_features=6, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[ 4.5540,  1.9176,  3.6411,  0.9371, -1.8513, -1.2901],
        [ 3.8365,  1.4948,  1.5441, -1.9474,  2.3734,  2.9981],
        [ 4.3015,  0.4406, -0.1710,  2.4975,  0.8048, -0.8525],
        [ 2.2441,  1.1571,  0.2686, -0.5091, -0.8571,  1.4604]],
       grad_fn=&lt;AddBackward0&gt;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([4, 6])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dissecting-model-components">Dissecting model components<a class="anchor-link" href="#Dissecting-model-components"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">pprint</span> <span class="k">import</span> <span class="n">pprint</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NestedModel</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c_in</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="n">linears</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d0</span><span class="p">,</span> <span class="n">d1</span><span class="p">)</span> <span class="k">for</span> <span class="n">d0</span><span class="p">,</span> <span class="n">d1</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">,</span> 
                                                       <span class="n">hidden_dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:])]</span>
        <span class="n">linears</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">linears</span><span class="p">,</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">()</span> 
                                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">linears</span><span class="p">))]))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">arg</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">linears</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">pair</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mod</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span> 
                                  <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)])</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">mod</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="s1">&#39;Linear&#39;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">layer</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">mod</span> <span class="o">=</span> <span class="n">NestedModel</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">mod</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0., 5., 2., 5., 9., 2.],
        [9., 0., 6., 3., 1., 3.],
        [2., 3., 9., 1., 2., 0.],
        [3., 3., 5., 9., 8., 5.]])
tensor([[[ 6.4326e-02,  3.1435e-02, -2.5885e-03,  3.9018e-01, -9.5811e-04,
           3.1741e-01]],

        [[-2.4429e-03,  5.3331e-02, -2.8642e-03,  5.5245e-01, -1.1792e-03,
           3.9474e-01]],

        [[-5.9604e-04,  1.5087e-01, -2.1209e-03,  3.9323e-01, -1.7153e-03,
           2.8635e-01]],

        [[-4.7646e-04,  9.2174e-02, -2.9102e-03,  4.3538e-01, -7.5166e-04,
           3.6905e-01]]], grad_fn=&lt;UnsqueezeBackward0&gt;)
tensor([[[0.0643, 0.3902]],

        [[0.0533, 0.5525]],

        [[0.1509, 0.3932]],

        [[0.0922, 0.4354]]], grad_fn=&lt;SqueezeBackward1&gt;)
tensor([[[-0.5289,  0.7264,  0.1837]],

        [[-0.5338,  0.7737,  0.1986]],

        [[-0.5653,  0.7254,  0.2313]],

        [[-0.5432,  0.7389,  0.2047]]], grad_fn=&lt;AddBackward0&gt;)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[0.1527, 0.5359, 0.3114]],

        [[0.1476, 0.5455, 0.3069]],

        [[0.1459, 0.5304, 0.3236]],

        [[0.1489, 0.5366, 0.3145]]], grad_fn=&lt;SoftmaxBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mod</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NestedModel(
  (fc): Linear(in_features=6, out_features=12, bias=True)
  (relu): ReLU()
  (seq): Sequential(
    (0): Linear(in_features=12, out_features=10, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=10, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=8, out_features=6, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
  (mod): ModuleList(
    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (1): Linear(in_features=2, out_features=3, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Gets list of all layers, extracting them from within modules and </span>
<span class="c1"># sequentials. Don&#39;t think we typically need to do this though. </span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mod</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
    <span class="n">children</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">children</span><span class="p">())</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">children</span><span class="p">:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">children</span><span class="p">)</span>

<span class="n">layers</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Linear(in_features=6, out_features=12, bias=True),
 ReLU(),
 Linear(in_features=12, out_features=10, bias=True),
 LeakyReLU(negative_slope=0.01),
 Linear(in_features=10, out_features=8, bias=True),
 LeakyReLU(negative_slope=0.01),
 Linear(in_features=8, out_features=6, bias=True),
 LeakyReLU(negative_slope=0.01),
 MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False),
 Linear(in_features=2, out_features=3, bias=True)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">mod</span><span class="o">.</span><span class="n">children</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">([(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">c</span><span class="o">.</span><span class="n">parameters</span><span class="p">()])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[(torch.Size([12, 6]), True), (torch.Size([12]), True)]
[]
[(torch.Size([10, 12]), True), (torch.Size([10]), True), (torch.Size([8, 10]), True), (torch.Size([8]), True), (torch.Size([6, 8]), True), (torch.Size([6]), True)]
[(torch.Size([3, 2]), True), (torch.Size([3]), True)]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Model.parameters() seems to automatically iterate through each param in each</span>
<span class="c1"># child, same as in the cell above. Recurse=False oddly returns empty list?</span>
<span class="p">[(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">mod</span><span class="o">.</span><span class="n">parameters</span><span class="p">(</span><span class="n">recurse</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(torch.Size([12, 6]), True),
 (torch.Size([12]), True),
 (torch.Size([10, 12]), True),
 (torch.Size([10]), True),
 (torch.Size([8, 10]), True),
 (torch.Size([8]), True),
 (torch.Size([6, 8]), True),
 (torch.Size([6]), True),
 (torch.Size([3, 2]), True),
 (torch.Size([3]), True)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pprint</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">children</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[Linear(in_features=6, out_features=12, bias=True),
 ReLU(),
 Sequential(
  (0): Linear(in_features=12, out_features=10, bias=True)
  (1): LeakyReLU(negative_slope=0.01)
  (2): Linear(in_features=10, out_features=8, bias=True)
  (3): LeakyReLU(negative_slope=0.01)
  (4): Linear(in_features=8, out_features=6, bias=True)
  (5): LeakyReLU(negative_slope=0.01)
),
 ModuleList(
  (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (1): Linear(in_features=2, out_features=3, bias=True)
)]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Seems to start at high level and then dive deeper into model. So first item</span>
<span class="c1"># is whole model; then we get single layers, sequentials, and module lists; </span>
<span class="c1"># then linear layers in the sequentials and module lists.</span>
<span class="c1"># Not sure when this would be useful.</span>
<span class="n">pprint</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">modules</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[NestedModel(
  (fc): Linear(in_features=6, out_features=12, bias=True)
  (relu): ReLU()
  (seq): Sequential(
    (0): Linear(in_features=12, out_features=10, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=10, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=8, out_features=6, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
  (mod): ModuleList(
    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (1): Linear(in_features=2, out_features=3, bias=True)
  )
),
 Linear(in_features=6, out_features=12, bias=True),
 ReLU(),
 Sequential(
  (0): Linear(in_features=12, out_features=10, bias=True)
  (1): LeakyReLU(negative_slope=0.01)
  (2): Linear(in_features=10, out_features=8, bias=True)
  (3): LeakyReLU(negative_slope=0.01)
  (4): Linear(in_features=8, out_features=6, bias=True)
  (5): LeakyReLU(negative_slope=0.01)
),
 Linear(in_features=12, out_features=10, bias=True),
 LeakyReLU(negative_slope=0.01),
 Linear(in_features=10, out_features=8, bias=True),
 LeakyReLU(negative_slope=0.01),
 Linear(in_features=8, out_features=6, bias=True),
 LeakyReLU(negative_slope=0.01),
 ModuleList(
  (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
  (1): Linear(in_features=2, out_features=3, bias=True)
),
 MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False),
 Linear(in_features=2, out_features=3, bias=True)]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Also have named_parameters() which is almost identical, but each item is a</span>
<span class="c1"># tuple of name_str and weights.</span>
<span class="n">pprint</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">parameters</span><span class="p">())))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>{0: Parameter containing:
tensor([[ 0.0099,  0.0274, -0.3193,  0.0329,  0.0444, -0.0355],
        [-0.1402,  0.0693, -0.2843,  0.1135,  0.2485, -0.3240],
        [ 0.3001,  0.2224,  0.3611, -0.2890, -0.1202,  0.2756],
        [ 0.2442, -0.2935,  0.3827, -0.1233,  0.0305,  0.3249],
        [-0.0148, -0.3202, -0.2059, -0.3465,  0.3627,  0.0037],
        [ 0.2162, -0.2803, -0.0667, -0.1019,  0.2888,  0.1954],
        [-0.1414,  0.0042, -0.2206,  0.3683, -0.1271,  0.3424],
        [ 0.3351, -0.0391, -0.0489,  0.0146,  0.3899, -0.1330],
        [ 0.1441,  0.3223, -0.2437,  0.2658, -0.3622, -0.2808],
        [-0.2277,  0.2159,  0.1413,  0.0822, -0.2127, -0.3655],
        [ 0.1330, -0.0927, -0.1883,  0.1051,  0.2737, -0.3455],
        [-0.3727, -0.3064,  0.1242,  0.2320,  0.1606, -0.3888]],
       requires_grad=True),
 1: Parameter containing:
tensor([-0.3684, -0.1282, -0.3694, -0.3890, -0.1481, -0.0204, -0.0075, -0.3795,
         0.0747, -0.3468, -0.3417,  0.3524], requires_grad=True),
 2: Parameter containing:
tensor([[ 0.1218, -0.0761, -0.0120,  0.0730,  0.2812,  0.2723, -0.2831,  0.0307,
          0.1458,  0.0535,  0.1407,  0.0326],
        [ 0.0956, -0.0056, -0.2243,  0.2006, -0.0331,  0.0396,  0.0297, -0.1867,
          0.0730,  0.0936,  0.2092, -0.0216],
        [ 0.1340,  0.0692,  0.0893,  0.2082, -0.1712,  0.0070,  0.1338,  0.0725,
          0.0661, -0.1325, -0.2492,  0.2249],
        [ 0.2326, -0.0943,  0.0143,  0.0548, -0.1819, -0.2451, -0.0165, -0.2134,
         -0.0264, -0.1255,  0.1310, -0.1273],
        [ 0.1956, -0.0349,  0.2513,  0.2321, -0.0313,  0.0090,  0.1948,  0.1912,
          0.1067, -0.1999,  0.1750,  0.1220],
        [-0.1931, -0.2380,  0.1895,  0.0183,  0.2548,  0.0775, -0.1535, -0.2706,
          0.2450, -0.0042, -0.2272,  0.1963],
        [-0.1117,  0.2865,  0.1624, -0.0923, -0.2090, -0.2283,  0.1598,  0.0226,
          0.0706,  0.1944, -0.0590, -0.1806],
        [ 0.1509,  0.2629, -0.0122,  0.2163,  0.1838, -0.1217,  0.1874,  0.1182,
         -0.0430, -0.1105,  0.1791, -0.0754],
        [ 0.0030, -0.2304, -0.0721,  0.1958,  0.2722, -0.1599, -0.2681, -0.2423,
         -0.0797, -0.1292, -0.0545,  0.2021],
        [ 0.1640, -0.0687,  0.1112, -0.2076, -0.1312, -0.2439,  0.2274, -0.2404,
         -0.1419,  0.0797, -0.0663, -0.1577]], requires_grad=True),
 3: Parameter containing:
tensor([ 0.1346,  0.0102,  0.1094,  0.1869,  0.2584, -0.0750,  0.0970, -0.1234,
         0.2273, -0.2064], requires_grad=True),
 4: Parameter containing:
tensor([[ 0.0136, -0.2747, -0.2321,  0.0125,  0.1407, -0.1759, -0.0683, -0.2617,
         -0.2084,  0.2241],
        [-0.0144,  0.3063,  0.2932,  0.2269, -0.2087, -0.0757, -0.0802, -0.2231,
         -0.2876,  0.0129],
        [-0.0723, -0.1356,  0.2138,  0.0837,  0.0761,  0.1815, -0.0679, -0.0009,
         -0.3145, -0.0566],
        [ 0.1749, -0.0709, -0.1534, -0.0685, -0.0100, -0.1924,  0.0904, -0.1376,
          0.0298, -0.0786],
        [-0.0408, -0.1029, -0.0200, -0.2492, -0.0109,  0.2911,  0.0210, -0.1113,
          0.3098, -0.2203],
        [ 0.0453, -0.2374,  0.2246,  0.3039,  0.0717,  0.2330, -0.3061,  0.0568,
         -0.1814,  0.2802],
        [-0.1517, -0.0314, -0.1753,  0.0360, -0.0018,  0.1814, -0.1370,  0.1212,
         -0.0021,  0.0842],
        [ 0.2843, -0.0906,  0.0303, -0.3052, -0.0215,  0.1676,  0.0957,  0.1913,
          0.0906,  0.1857]], requires_grad=True),
 5: Parameter containing:
tensor([ 0.0237,  0.2515,  0.2972, -0.0931,  0.1398,  0.2505, -0.1615, -0.0918],
       requires_grad=True),
 6: Parameter containing:
tensor([[-0.0911, -0.0017, -0.1301, -0.1094, -0.1342, -0.2672, -0.1154, -0.3215],
        [-0.2693, -0.1723,  0.2728, -0.0590,  0.3465, -0.0345,  0.0120, -0.3030],
        [ 0.1827,  0.3301,  0.3213, -0.3359,  0.2034, -0.3083, -0.2250,  0.1050],
        [ 0.1521,  0.0442,  0.0285, -0.3250, -0.1369,  0.1280, -0.2510,  0.2786],
        [ 0.0467, -0.1751,  0.1018,  0.1364, -0.2758, -0.0378,  0.3034, -0.1265],
        [-0.2261, -0.2045,  0.0899, -0.0072, -0.2106,  0.0735, -0.0334, -0.0052]],
       requires_grad=True),
 7: Parameter containing:
tensor([ 0.2792, -0.0338, -0.3071,  0.2837, -0.1006,  0.2528],
       requires_grad=True),
 8: Parameter containing:
tensor([[-0.4191, -0.0590],
        [-0.0212,  0.2901],
        [ 0.5463,  0.1291]], requires_grad=True),
 9: Parameter containing:
tensor([-0.4789,  0.6145,  0.0982], requires_grad=True)}
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mod</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NestedModel(
  (fc): Linear(in_features=6, out_features=12, bias=True)
  (relu): ReLU()
  (seq): Sequential(
    (0): Linear(in_features=12, out_features=10, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=10, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=8, out_features=6, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
  (mod): ModuleList(
    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (1): Linear(in_features=2, out_features=3, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">freeze</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">x</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span> 
        <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">mod</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
    
<span class="n">pprint</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">trainable</span><span class="p">())</span>
<span class="n">mod</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">freeze</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">mod</span><span class="o">.</span><span class="n">trainable</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[((12, 6), True),
 ((12,), True),
 ((10, 12), True),
 ((10,), True),
 ((8, 10), True),
 ((8,), True),
 ((6, 8), True),
 ((6,), True),
 ((3, 2), True),
 ((3,), True)]

[((12, 6), False),
 ((12,), False),
 ((10, 12), False),
 ((10,), False),
 ((8, 10), False),
 ((8,), False),
 ((6, 8), False),
 ((6,), False),
 ((3, 2), False),
 ((3,), False)]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Uses outputs of model.children()</span>
<span class="n">mod</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TYPE&#39;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TYPE &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; [Parameter containing:
tensor([[-0.3656,  0.0783,  0.0917, -0.2374,  0.0969,  0.3274],
        [-0.3152,  0.1356,  0.3497, -0.0860, -0.3696, -0.2798],
        [-0.2190, -0.2395,  0.3667, -0.0832,  0.3711,  0.3256],
        [-0.3963,  0.1195,  0.0215,  0.1382, -0.1302,  0.3039],
        [ 0.2511,  0.3575,  0.1222,  0.3794, -0.3783, -0.1140],
        [ 0.1015,  0.1762,  0.2396,  0.0652,  0.2090,  0.0854],
        [ 0.0255,  0.3808, -0.0934, -0.1005,  0.2855,  0.0401],
        [-0.1884, -0.2917,  0.2465,  0.2880,  0.1670, -0.1933],
        [-0.1640,  0.2293,  0.1941,  0.3935,  0.2173, -0.0118],
        [ 0.3743, -0.3663, -0.2443,  0.1506, -0.2140,  0.3509],
        [-0.3813,  0.3435, -0.3736,  0.2517,  0.1702,  0.2703],
        [-0.0246, -0.2631, -0.0188,  0.2428, -0.2185, -0.2560]]), Parameter containing:
tensor([-0.2712,  0.3741,  0.0636,  0.1773, -0.1028, -0.2567, -0.3787,  0.1860,
        -0.0886, -0.1423,  0.1464, -0.0419])] 

TYPE &lt;class &#39;torch.nn.modules.activation.ReLU&#39;&gt; [] 

TYPE &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; [Parameter containing:
tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,
          0.2061, -0.0768,  0.2724, -0.1730],
        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,
          0.2709,  0.1090,  0.1634,  0.2299],
        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,
         -0.0259,  0.0829, -0.2655,  0.1763],
        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,
          0.1057, -0.0431,  0.0209,  0.0338],
        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,
         -0.1545,  0.0360, -0.0649,  0.1500],
        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,
          0.2144, -0.0529, -0.0212, -0.1253],
        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,
          0.0639, -0.1279,  0.1157,  0.1313],
        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,
         -0.0682,  0.2860, -0.2305,  0.0628],
        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,
          0.0679, -0.2104, -0.1249,  0.0936],
        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,
         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:
tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,
         0.0292, -0.2681])] 

TYPE &lt;class &#39;torch.nn.modules.activation.LeakyReLU&#39;&gt; [] 

TYPE &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; [Parameter containing:
tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,
          0.1507, -0.0261],
        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,
         -0.1080, -0.1217],
        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,
         -0.2130,  0.0930],
        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,
         -0.2225,  0.0426],
        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,
         -0.2736, -0.1497],
        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,
          0.1581, -0.2330],
        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,
          0.0059,  0.0456],
        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,
          0.2920,  0.0589]]), Parameter containing:
tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084])] 

TYPE &lt;class &#39;torch.nn.modules.activation.LeakyReLU&#39;&gt; [] 

TYPE &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; [Parameter containing:
tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],
        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],
        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],
        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],
        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],
        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:
tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343])] 

TYPE &lt;class &#39;torch.nn.modules.activation.LeakyReLU&#39;&gt; [] 

TYPE &lt;class &#39;torch.nn.modules.container.Sequential&#39;&gt; [Parameter containing:
tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,
          0.2061, -0.0768,  0.2724, -0.1730],
        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,
          0.2709,  0.1090,  0.1634,  0.2299],
        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,
         -0.0259,  0.0829, -0.2655,  0.1763],
        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,
          0.1057, -0.0431,  0.0209,  0.0338],
        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,
         -0.1545,  0.0360, -0.0649,  0.1500],
        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,
          0.2144, -0.0529, -0.0212, -0.1253],
        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,
          0.0639, -0.1279,  0.1157,  0.1313],
        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,
         -0.0682,  0.2860, -0.2305,  0.0628],
        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,
          0.0679, -0.2104, -0.1249,  0.0936],
        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,
         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:
tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,
         0.0292, -0.2681]), Parameter containing:
tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,
          0.1507, -0.0261],
        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,
         -0.1080, -0.1217],
        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,
         -0.2130,  0.0930],
        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,
         -0.2225,  0.0426],
        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,
         -0.2736, -0.1497],
        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,
          0.1581, -0.2330],
        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,
          0.0059,  0.0456],
        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,
          0.2920,  0.0589]]), Parameter containing:
tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084]), Parameter containing:
tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],
        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],
        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],
        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],
        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],
        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:
tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343])] 

TYPE &lt;class &#39;torch.nn.modules.pooling.MaxPool1d&#39;&gt; [] 

TYPE &lt;class &#39;torch.nn.modules.linear.Linear&#39;&gt; [Parameter containing:
tensor([[-1.3405e-04,  6.5233e-01],
        [-3.6495e-01,  1.0810e-01],
        [-2.5539e-01, -4.3903e-01]]), Parameter containing:
tensor([-0.3769,  0.5977, -0.0545])] 

TYPE &lt;class &#39;torch.nn.modules.container.ModuleList&#39;&gt; [Parameter containing:
tensor([[-1.3405e-04,  6.5233e-01],
        [-3.6495e-01,  1.0810e-01],
        [-2.5539e-01, -4.3903e-01]]), Parameter containing:
tensor([-0.3769,  0.5977, -0.0545])] 

TYPE &lt;class &#39;__main__.NestedModel&#39;&gt; [Parameter containing:
tensor([[-0.3656,  0.0783,  0.0917, -0.2374,  0.0969,  0.3274],
        [-0.3152,  0.1356,  0.3497, -0.0860, -0.3696, -0.2798],
        [-0.2190, -0.2395,  0.3667, -0.0832,  0.3711,  0.3256],
        [-0.3963,  0.1195,  0.0215,  0.1382, -0.1302,  0.3039],
        [ 0.2511,  0.3575,  0.1222,  0.3794, -0.3783, -0.1140],
        [ 0.1015,  0.1762,  0.2396,  0.0652,  0.2090,  0.0854],
        [ 0.0255,  0.3808, -0.0934, -0.1005,  0.2855,  0.0401],
        [-0.1884, -0.2917,  0.2465,  0.2880,  0.1670, -0.1933],
        [-0.1640,  0.2293,  0.1941,  0.3935,  0.2173, -0.0118],
        [ 0.3743, -0.3663, -0.2443,  0.1506, -0.2140,  0.3509],
        [-0.3813,  0.3435, -0.3736,  0.2517,  0.1702,  0.2703],
        [-0.0246, -0.2631, -0.0188,  0.2428, -0.2185, -0.2560]]), Parameter containing:
tensor([-0.2712,  0.3741,  0.0636,  0.1773, -0.1028, -0.2567, -0.3787,  0.1860,
        -0.0886, -0.1423,  0.1464, -0.0419]), Parameter containing:
tensor([[-0.2721,  0.2885, -0.1404, -0.0643, -0.0898,  0.1328,  0.0449,  0.2016,
          0.2061, -0.0768,  0.2724, -0.1730],
        [ 0.2456,  0.0554, -0.2034,  0.0739, -0.2291, -0.2463,  0.2816, -0.2108,
          0.2709,  0.1090,  0.1634,  0.2299],
        [-0.0761,  0.0393,  0.2800,  0.2224, -0.1961,  0.1295, -0.0902, -0.1960,
         -0.0259,  0.0829, -0.2655,  0.1763],
        [-0.0358, -0.0146,  0.0449,  0.1288, -0.1617,  0.2226, -0.0680,  0.1265,
          0.1057, -0.0431,  0.0209,  0.0338],
        [ 0.0036, -0.2455,  0.0723,  0.0915,  0.2510, -0.2583,  0.2817,  0.2173,
         -0.1545,  0.0360, -0.0649,  0.1500],
        [-0.2338, -0.1430,  0.0669,  0.0953, -0.2803,  0.0465, -0.1381, -0.0652,
          0.2144, -0.0529, -0.0212, -0.1253],
        [-0.2869, -0.2012, -0.0707,  0.1050,  0.1641, -0.2376, -0.0580, -0.0287,
          0.0639, -0.1279,  0.1157,  0.1313],
        [-0.1111,  0.1733, -0.0164,  0.1780,  0.1754,  0.2803, -0.2515,  0.0158,
         -0.0682,  0.2860, -0.2305,  0.0628],
        [ 0.0258, -0.1924,  0.0559, -0.1239, -0.0746,  0.0690,  0.2542, -0.2007,
          0.0679, -0.2104, -0.1249,  0.0936],
        [ 0.1977, -0.0612, -0.2050,  0.0755,  0.2689, -0.0587,  0.0256,  0.1075,
         -0.1771, -0.1485, -0.2787,  0.2262]]), Parameter containing:
tensor([ 0.0440,  0.1829, -0.1089, -0.1831, -0.0271,  0.1132,  0.2721,  0.2612,
         0.0292, -0.2681]), Parameter containing:
tensor([[-0.1199, -0.1610, -0.2526,  0.2792,  0.2477, -0.2625, -0.1226,  0.2017,
          0.1507, -0.0261],
        [-0.1990, -0.2757,  0.2858, -0.1452, -0.0426,  0.0644,  0.1083,  0.2040,
         -0.1080, -0.1217],
        [-0.1619, -0.1239,  0.1120,  0.1415,  0.1227,  0.0668, -0.2929, -0.1472,
         -0.2130,  0.0930],
        [-0.0837, -0.0611,  0.1713,  0.1157,  0.2262,  0.0327,  0.2264,  0.2537,
         -0.2225,  0.0426],
        [ 0.1044, -0.0771, -0.2367, -0.1995, -0.1433, -0.1828,  0.1951, -0.0896,
         -0.2736, -0.1497],
        [-0.2552,  0.1375, -0.0586,  0.0034,  0.1827,  0.3054,  0.1879, -0.0163,
          0.1581, -0.2330],
        [ 0.0498,  0.2441, -0.2557, -0.1788, -0.1719, -0.2198, -0.1680, -0.1080,
          0.0059,  0.0456],
        [ 0.2989,  0.1357,  0.1121,  0.3137,  0.2887,  0.1763,  0.2437,  0.0433,
          0.2920,  0.0589]]), Parameter containing:
tensor([-0.0012,  0.2212,  0.2655,  0.3153, -0.2801,  0.1340, -0.2298,  0.2084]), Parameter containing:
tensor([[-0.1740, -0.0951, -0.1273, -0.0127,  0.2046, -0.2810, -0.1087, -0.2491],
        [ 0.3502, -0.2675,  0.3403, -0.1057,  0.3366, -0.0193,  0.3497,  0.0865],
        [-0.1169, -0.2323, -0.1347,  0.2748, -0.1299, -0.1389,  0.1470,  0.1082],
        [-0.2287, -0.2035, -0.0368, -0.2402,  0.0944,  0.0563, -0.2079, -0.2379],
        [-0.0884,  0.3172,  0.3125, -0.2183, -0.2229, -0.0815,  0.2401, -0.0282],
        [ 0.0580,  0.0570,  0.1441,  0.0925, -0.3486,  0.1702, -0.2793,  0.0755]]), Parameter containing:
tensor([ 0.0779, -0.2107, -0.2574, -0.0953,  0.0147, -0.3343]), Parameter containing:
tensor([[-1.3405e-04,  6.5233e-01],
        [-3.6495e-01,  1.0810e-01],
        [-2.5539e-01, -4.3903e-01]]), Parameter containing:
tensor([-0.3769,  0.5977, -0.0545])] 

</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NestedModel(
  (fc): Linear(in_features=6, out_features=12, bias=True)
  (relu): ReLU()
  (seq): Sequential(
    (0): Linear(in_features=12, out_features=10, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=10, out_features=8, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
    (4): Linear(in_features=8, out_features=6, bias=True)
    (5): LeakyReLU(negative_slope=0.01)
  )
  (mod): ModuleList(
    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (1): Linear(in_features=2, out_features=3, bias=True)
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="More-freezing:-module-list-of-sequentials">More freezing: module list of sequentials<a class="anchor-link" href="#More-freezing:-module-list-of-sequentials"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">NestedSequentials</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">dims</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">),</span>
                                   <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
                                   <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
                                   <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dec</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                                 <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blocks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">trans</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec</span><span class="p">])</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">block</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blocks</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">block</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">bs</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">x_dim</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">nested</span> <span class="o">=</span> <span class="n">NestedSequentials</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="n">dims</span><span class="p">)</span>
<span class="n">nested</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor([[0., 2., 1., 2., 5.],
        [1., 1., 4., 3., 0.],
        [4., 5., 1., 1., 1.],
        [0., 5., 1., 1., 0.]])
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>NestedSequentials(
  (enc): Sequential(
    (0): Linear(in_features=5, out_features=8, bias=True)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Linear(in_features=8, out_features=6, bias=True)
    (3): LeakyReLU(negative_slope=0.01)
  )
  (trans): Sequential(
    (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
    (1): ReLU()
    (2): Linear(in_features=2, out_features=4, bias=True)
    (3): ReLU()
  )
  (dec): Sequential(
    (0): Linear(in_features=4, out_features=3, bias=True)
    (1): Softmax(dim=-1)
  )
  (blocks): ModuleList(
    (0): Sequential(
      (0): Linear(in_features=5, out_features=8, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=8, out_features=6, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)
      (1): ReLU()
      (2): Linear(in_features=2, out_features=4, bias=True)
      (3): ReLU()
    )
    (2): Sequential(
      (0): Linear(in_features=4, out_features=3, bias=True)
      (1): Softmax(dim=-1)
    )
  )
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nested</span><span class="o">.</span><span class="n">_init_variables</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;x_dim&#39;: 5, &#39;dims&#39;: [8, 6]}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nested</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.2564, 0.3047, 0.4389],
        [0.2811, 0.2976, 0.4213],
        [0.2688, 0.2922, 0.4390],
        [0.2694, 0.3175, 0.4131]], grad_fn=&lt;SqueezeBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nested</span><span class="o">.</span><span class="n">weight_stats</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(0.033, 0.282),
 (0.075, 0.213),
 (-0.004, 0.193),
 (0.078, 0.224),
 (0.178, 0.512),
 (0.041, 0.604),
 (-0.055, 0.213),
 (-0.19, 0.17)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">nested</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
    <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
<span class="n">nested</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">freeze</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">nested</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>torch.Size([8, 5]) False
torch.Size([8, 5]) True 

torch.Size([8]) False
torch.Size([8]) True 

torch.Size([6, 8]) False
torch.Size([6, 8]) True 

torch.Size([6]) False
torch.Size([6]) True 

torch.Size([4, 2]) False
torch.Size([4, 2]) True 

torch.Size([4]) False
torch.Size([4]) True 

torch.Size([3, 4]) False
torch.Size([3, 4]) True 

torch.Size([3]) False
torch.Size([3]) True 

--------------------
torch.Size([8, 5]) False
torch.Size([8]) False
torch.Size([6, 8]) False
torch.Size([6]) False
torch.Size([4, 2]) False
torch.Size([4]) False
torch.Size([3, 4]) False
torch.Size([3]) False
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nested</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="mi">11</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Weights saved from epoch 11.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">NestedSequentials</span><span class="o">.</span><span class="n">from_path</span><span class="p">(</span><span class="s1">&#39;data/model_11.pth&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 11 weights loaded from data/model_11.pth.
Model parameters: {&#39;x_dim&#39;: 5, &#39;dims&#39;: [8, 6]}
Currently in eval mode.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[0.2564, 0.3047, 0.4389],
        [0.2811, 0.2976, 0.4213],
        [0.2688, 0.2922, 0.4390],
        [0.2694, 0.3175, 0.4131]], grad_fn=&lt;SqueezeBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">weight_stats</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(0.033, 0.282),
 (0.075, 0.213),
 (-0.004, 0.193),
 (0.078, 0.224),
 (0.178, 0.512),
 (0.041, 0.604),
 (-0.055, 0.213),
 (-0.19, 0.17)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">variable_lr_optimizer</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">lrs</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Get an optimizer that uses different learning rates for different layer</span>
<span class="sd">    groups. Additional keyword arguments can be used to alter momentum and/or</span>
<span class="sd">    weight decay, for example, but for the sake of simplicity these values </span>
<span class="sd">    will be the same across layer groups. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    groups: nn.ModuleList</span>
<span class="sd">        For this use case, the model should contain a ModuleList of layer </span>
<span class="sd">        groups in the form of Sequential objects. This variable is then passed</span>
<span class="sd">        in so each group can receive its own learning rate.</span>
<span class="sd">    lrs: list[float]</span>
<span class="sd">        A list containing the learning rates to use for each layer group. This </span>
<span class="sd">        should be the same length as the number of layer groups in the model.</span>
<span class="sd">        At times, we may want to use the same learning rate for all groups, </span>
<span class="sd">        and can achieve this by passing in a list containing a single float.</span>
<span class="sd">    optimizer: torch optimizer</span>
<span class="sd">        The Torch optimizer to be created (Adam by default). </span>
<span class="sd">        </span>
<span class="sd">    Examples</span>
<span class="sd">    ---------</span>
<span class="sd">    optim = variable_lr_optimizer(model.groups, [3e-3, 3e-2, 1e-1])</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lrs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">lrs</span> <span class="o">*=</span> <span class="nb">len</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
        
    <span class="n">data</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">group</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="n">lr</span><span class="p">}</span> 
            <span class="k">for</span> <span class="n">group</span><span class="p">,</span> <span class="n">lr</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">groups</span><span class="p">,</span> <span class="n">lrs</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">optimizer</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">variable_lr_optimizer</span><span class="p">(</span><span class="n">nested</span><span class="o">.</span><span class="n">blocks</span><span class="p">,</span> <span class="p">[</span><span class="o">.</span><span class="mi">5</span><span class="p">,</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="o">.</span><span class="mi">005</span><span class="p">],</span> <span class="n">weight_decay</span><span class="o">=.</span><span class="mi">75</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.5
    weight_decay: 0.75

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.05
    weight_decay: 0.75

Parameter Group 2
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.005
    weight_decay: 0.75
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">dir_</span><span class="o">=</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="n">file_pre</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Save model weights.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    epoch: int</span>
<span class="sd">        The epoch of training the weights correspond to.</span>
<span class="sd">    dir_: str</span>
<span class="sd">        The directory which will contain the output file.</span>
<span class="sd">    file_pre: str</span>
<span class="sd">        The first part of the file name to save the weights to. The epoch</span>
<span class="sd">        and file extension will be added automatically.</span>
<span class="sd">    verbose: bool</span>
<span class="sd">        If True, print message to notify user that weights have been saved.</span>
<span class="sd">    **kwargs: any type</span>
<span class="sd">        User can optionally provide additional information to save </span>
<span class="sd">        (e.g. optimizer state dict).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dir_</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">file</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{file_pre}</span><span class="s1">_</span><span class="si">{epoch}</span><span class="s1">.pth&#39;</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dir_</span><span class="p">,</span> <span class="n">file</span><span class="p">)</span>
    
    <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
                <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span>
                <span class="n">params</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_init_variables</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">data</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">}</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Weights saved from epoch </span><span class="si">{epoch}</span><span class="s1">.&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">from_path</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Factory method to load a model from a file containing saved weights.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    -----------</span>
<span class="sd">    path: str</span>
<span class="sd">        File path to load weights from.</span>
<span class="sd">    verbose: bool</span>
<span class="sd">        If True, print message notifying user which weights have been loaded</span>
<span class="sd">        and what mode the model is in.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;params&#39;</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;weights&#39;</span><span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Weights loaded from epoch </span><span class="si">{data[&quot;epoch&quot;]}</span><span class="s1">. &#39;</span>
              <span class="s1">&#39;Currently in eval mode.&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Hooks">Hooks<a class="anchor-link" href="#Hooks"> </a></h2><p>Related notes:<br>
-leaf variable - tensor defined by user (see x2 below)<br>
    -non-leaf - result of tensor operation (see y below)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">htools.ml</span> <span class="k">import</span> <span class="n">stats</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hook_plot_gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">grads</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">clip_gradients</span><span class="p">(</span><span class="n">grads</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">penalty</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Arbitrarily chosen.&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">y</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">x2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[8., 4., 5., 7., 4., 8., 2., 3.],
        [2., 0., 1., 8., 7., 5., 3., 9.],
        [2., 4., 3., 9., 2., 0., 6., 0.],
        [6., 1., 3., 0., 4., 0., 5., 5.]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">w</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">hook_plot_gradients</span><span class="p">)</span>
<span class="n">w</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.9228,  1.0944],
        [ 0.7592,  0.1647],
        [-1.0077,  0.5434],
        [ 1.0515, -0.9802],
        [-0.1555, -0.0869],
        [-1.1046,  1.9011],
        [-1.2100, -1.3748],
        [ 0.3485,  0.4592]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">@</span> <span class="n">w</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">penalty</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">cost</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(79.9269, grad_fn=&lt;VarBackward0&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cost</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">w</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 21.9028,  21.9028],
        [ -3.5688,  -3.5688],
        [  4.8685,   4.8685],
        [ 18.6997,  18.6997],
        [ 23.7503,  23.7503],
        [ 68.9819,  68.9819],
        [-32.5070, -32.5070],
        [ 33.5617,  33.5617]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">hooks</span><span class="p">,</span> <span class="n">iters</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">lr</span><span class="o">=.</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">((</span><span class="mi">128</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1">#     w.register_hook(hook_plot_gradients)</span>
<span class="c1">#     w.register_hook(lambda x: print(stats(x)))</span>
    <span class="k">for</span> <span class="n">hook</span> <span class="ow">in</span> <span class="n">hooks</span><span class="p">:</span>
        <span class="n">w</span><span class="o">.</span><span class="n">register_hook</span><span class="p">(</span><span class="n">hook</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">penalty</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">cost</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">w</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hooks</span> <span class="o">=</span> <span class="p">[</span><span class="n">hook_plot_gradients</span><span class="p">,</span> 
         <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">stats</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span>
         <span class="n">clip_gradients</span><span class="p">,</span>
         <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">))]</span>

<span class="n">train</span><span class="p">(</span><span class="n">hooks</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXAAAAD7CAYAAABzGc+QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAOP0lEQVR4nO3dXYxc9X2H8ecbDEmVNDKEhVoYd4nkUEgbXrRBVKhVAiElMQIuoCKKUqu1ZDWiiKipgiFXlXJh2iqQqi+qBbSuRAuIQI2ApnEdaFWpmJi3AHEolLrExcGmhYYoEsjw68Ucq8t61zPe3dmZv3k+krVzzpzZ+XFYPz57ds5sqgpJUnveM+oBJEnzY8AlqVEGXJIaZcAlqVEGXJIaZcAlqVHLBtkoyS7gdeAtYH9VTSU5DrgDmAR2Ab9eVa8OZ0xJ0kyHcwT+yao6s6qmuuUNwLaqWg1s65YlSUskg1zI0x2BT1XVK9PWPQt8oqr2JFkBPFRVpx7q8xx//PE1OTm5sIkl6V3m0UcffaWqJmauH+gUClDAt5MU8BdVtQk4sar2AHQRP6HfJ5mcnGTHjh2HM7ckvesl+c/Z1g8a8POq6qUu0luT/OAwnng9sB5g1apVgz5MktTHQOfAq+ql7uNe4B7gHODl7tQJ3ce9czx2U1VNVdXUxMRB3wFIkuapb8CTvD/Jzx64DXwaeBq4F1jbbbYW2DKsISVJBxvkFMqJwD1JDmz/N1X1rSTfBe5Msg54EbhieGNKkmbqG/CqegE4Y5b1/w1cMIyhJEn9eSWmJDXKgEtSowy4JDXKgEtSowa9kEdaEpMb7h/J8+7auGYkzysthEfgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjfIXOkiM7hdJgL9MQvPnEbgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjBg54kqOSPJ7kvm75lCTbkzyX5I4kxwxvTEnSTIdzBH4NsHPa8g3AjVW1GngVWLeYg0mSDm2ggCdZCawBbu6WA5wP3NVtshm4bBgDSpJmN+gR+E3AV4C3u+UPAa9V1f5ueTdw0iLPJkk6hL4BT3IxsLeqHp2+epZNa47Hr0+yI8mOffv2zXNMSdJMgxyBnwdckmQXcDu9Uyc3AcuTHPiNPiuBl2Z7cFVtqqqpqpqamJhYhJElSTBAwKvquqpaWVWTwJXAd6rq88CDwOXdZmuBLUObUpJ0kIW8Dvxa4HeTPE/vnPgtizOSJGkQh/VLjavqIeCh7vYLwDmLP5IkaRBeiSlJjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSow3ozKy2tyQ33j+R5d21cM5Lnfbfy/7PmyyNwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWpU34AneV+SR5I8meSZJL/frT8lyfYkzyW5I8kxwx9XknTAIEfgbwDnV9UZwJnARUnOBW4Abqyq1cCrwLrhjSlJmqlvwKvnJ93i0d2fAs4H7urWbwYuG8qEkqRZDXQOPMlRSZ4A9gJbgX8HXquq/d0mu4GThjOiJGk2AwW8qt6qqjOBlcA5wGmzbTbbY5OsT7IjyY59+/bNf1JJ0jsc1qtQquo14CHgXGB5kmXdXSuBl+Z4zKaqmqqqqYmJiYXMKkmaZpBXoUwkWd7d/hngU8BO4EHg8m6ztcCWYQ0pSTrYsv6bsALYnOQoesG/s6ruS/J94PYkXwMeB24Z4pySpBn6BryqvgecNcv6F+idD5ckjYBXYkpSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDVq2agHGHeTG+4f9QjSUIzya3vXxjUje+4jiUfgktQoAy5JjTLgktQoAy5Jjeob8CQnJ3kwyc4kzyS5plt/XJKtSZ7rPh47/HElSQcMcgS+H/hyVZ0GnAtcleR0YAOwrapWA9u6ZUnSEukb8KraU1WPdbdfB3YCJwGXApu7zTYDlw1rSEnSwQ7rHHiSSeAsYDtwYlXtgV7kgRMWezhJ0twGvpAnyQeAbwJfqqofJxn0ceuB9QCrVq2az4xaYl68JLVhoCPwJEfTi/dtVXV3t/rlJCu6+1cAe2d7bFVtqqqpqpqamJhYjJklSQz2KpQAtwA7q+rr0+66F1jb3V4LbFn88SRJcxnkFMp5wBeAp5I80a27HtgI3JlkHfAicMVwRpQkzaZvwKvqX4C5TnhfsLjjSJIG5ZWYktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktQoAy5JjTLgktSoZaMeYFCTG+4f9QiSNFY8ApekRhlwSWqUAZekRhlwSWpU34AnuTXJ3iRPT1t3XJKtSZ7rPh473DElSTMNcgT+V8BFM9ZtALZV1WpgW7csSVpCfQNeVf8M/M+M1ZcCm7vbm4HLFnkuSVIf8z0HfmJV7QHoPp6weCNJkgYx9At5kqwH1gOsWrVq2E8nSXMa1QWBuzauGcrnne8R+MtJVgB0H/fOtWFVbaqqqaqampiYmOfTSZJmmm/A7wXWdrfXAlsWZxxJ0qAGeRnh3wL/CpyaZHeSdcBG4MIkzwEXdsuSpCXU9xx4VX1ujrsuWORZJEmHwSsxJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGmXAJalRBlySGjX0X+ggSTON6hcrHGk8ApekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRhlwSWqUAZekRi0o4EkuSvJskueTbFisoSRJ/c074EmOAv4U+AxwOvC5JKcv1mCSpENbyBH4OcDzVfVCVb0J3A5cujhjSZL6WUjATwJ+OG15d7dOkrQEli3gsZllXR20UbIeWN8t/iTJswt4zsN1PPDKEj7fQjnvcDnv8LU285LMmxsW/Cl+fraVCwn4buDkacsrgZdmblRVm4BNC3ieeUuyo6qmRvHc8+G8w+W8w9fazK3NO9NCTqF8F1id5JQkxwBXAvcuzliSpH7mfQReVfuT/A7wD8BRwK1V9cyiTSZJOqSFnEKhqh4AHlikWYZhJKduFsB5h8t5h6+1mVub9x1SddDPHSVJDfBSeklq1BEZ8CRXd5f4P5PkD6atv6677P/ZJL82yhlnSvJ7SSrJ8d1ykvxxN+/3kpw96hkPSPKHSX7QzXVPkuXT7hvLfTzub/uQ5OQkDybZ2X3dXtOtPy7J1iTPdR+PHfWs0yU5KsnjSe7rlk9Jsr2b947uBQ5jIcnyJHd1X7s7k/zyuO/ffo64gCf5JL0rQj9WVR8F/qhbfzq9V8p8FLgI+LPu7QBGLsnJwIXAi9NWfwZY3f1ZD/z5CEaby1bgF6vqY8C/AdfB+O7jRt72YT/w5ao6DTgXuKqbcQOwrapWA9u65XFyDbBz2vINwI3dvK8C60Yy1ey+AXyrqn4BOIPe3OO+fw/piAs48EVgY1W9AVBVe7v1lwK3V9UbVfUfwPP03g5gHNwIfIV3Xgh1KfDX1fMwsDzJipFMN0NVfbuq9neLD9O7BgDGdx+P/ds+VNWeqnqsu/06vbicRG/Ozd1mm4HLRjPhwZKsBNYAN3fLAc4H7uo2GZt5k3wQ+FXgFoCqerOqXmOM9+8gjsSAfwT4le7buH9K8vFu/Vhe+p/kEuC/qurJGXeN5byz+C3g77vb4zrzuM41qySTwFnAduDEqtoDvcgDJ4xusoPcRO/A4+1u+UPAa9P+cR+n/fxhYB/wl90pn5uTvJ/x3r99LehlhKOS5B+Bn5vlrq/S+286lt63oR8H7kzyYQa89H8Y+sx7PfDp2R42y7ole8nQoWauqi3dNl+l963/bQceNsv24/Ayp3Gd6yBJPgB8E/hSVf24d1A7fpJcDOytqkeTfOLA6lk2HZf9vAw4G7i6qrYn+QaNnS6ZTZMBr6pPzXVfki8Cd1fv9ZGPJHmb3vsdDHTp/zDMNW+SXwJOAZ7s/qKuBB5Lcg4jnBcOvY8BkqwFLgYuqP9/LepIZz6EcZ3rHZIcTS/et1XV3d3ql5OsqKo93Sm0vXN/hiV1HnBJks8C7wM+SO+IfHmSZd1R+Djt593A7qra3i3fRS/g47p/B3IknkL5O3rn4UjyEeAYem9Wcy9wZZL3JjmF3g8HHxnZlEBVPVVVJ1TVZFVN0vsiO7uqfkRv3t/oXo1yLvC/B77VG7UkFwHXApdU1U+n3TV2+7gz9m/70J0/vgXYWVVfn3bXvcDa7vZaYMtSzzabqrquqlZ2X7dXAt+pqs8DDwKXd5uN07w/An6Y5NRu1QXA9xnT/TuoJo/A+7gVuDXJ08CbwNruCPGZJHfS+5+2H7iqqt4a4Zz9PAB8lt4PAn8K/OZox3mHPwHeC2ztvnN4uKp+u6rGch838rYP5wFfAJ5K8kS37npgI73TgOvovUrpihHNN6hrgduTfA14nO6HhmPiauC27h/xF+j9nXoPbe3fd/BKTElq1JF4CkWS3hUMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ16v8Acma5dj2C+6EAAAAASUVORK5CYII=
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-0.8818, 31.2236)
tensor(-0.8818) tensor(31.2236)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPC0lEQVR4nO3df6xkZX3H8fenuyDGHwXkQrYs24vJxohJRXtDaWyaFvyBYApNtMGYZlNJNqnaatqkXUtiY9omoEk1piZ2U03XxB8gaqASq9stxDZRcFHExRV3QaobNixWqPqP7eq3f8yzMrvM5c7cO3N/PLxfyWTOec4593yfO+d87rnnzJxJVSFJ6scvrXUBkqTpMtglqTMGuyR1xmCXpM4Y7JLUmc2rubJzzjmn5ufnV3OVkrTh3XPPPT+oqrlx51/VYJ+fn2f//v2ruUpJ2vCS/Nck83sqRpI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHVmrLc7JnkY+DHwM+B4VS0kORu4CZgHHgb+oKoen02ZkqRxTXLE/rtVdXFVLbTxXcC+qtoO7GvjkqQ1tpJTMVcDe9rwHuCalZcjSVqpcT95WsAXkxTwj1W1Gzivqo4CVNXRJOeOWjDJTmAnwLZt26ZQsno2v+v2NVnvwzdctSbrlWZh3GB/RVU90sJ7b5Jvj7uC9kdgN8DCwoJf1yRJMzbWqZiqeqQ9HwM+C1wCPJpkC0B7PjarIiVJ41sy2JM8J8nzTgwDrwYOALcBO9psO4BbZ1WkJGl845yKOQ/4bJIT83+8qv41yVeBm5NcB3wPeMPsypQkjWvJYK+qh4CXjmj/b+DyWRQlSVo+P3kqSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTPj3rZX6tpa3QcevBe8ps8jdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOjB3sSTYl+XqSz7XxC5PcleRQkpuSnD67MiVJ45rkiP3twMGh8RuB91XVduBx4LppFiZJWp6xgj3JVuAq4J/aeIDLgFvaLHuAa2ZRoCRpMuMesb8f+Avg5238BcATVXW8jR8Bzh+1YJKdSfYn2f/YY4+tqFhJ0tKWDPYkrwOOVdU9w80jZq1Ry1fV7qpaqKqFubm5ZZYpSRrX5jHmeQXwe0muBM4Ans/gCP7MJJvbUftW4JHZlSlJGteSR+xV9c6q2lpV88C1wL9X1ZuAO4DXt9l2ALfOrEpJ0thW8j72vwT+LMlhBufcPzydkiRJKzHOqZhfqKo7gTvb8EPAJdMvSZK0En7yVJI6Y7BLUmcmOhUjqR/zu25fs3U/fMNVa7buZwKP2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnfGLNvQUa/kFDJJWziN2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHVmyWBPckaSu5N8I8n9Sd7d2i9McleSQ0luSnL67MuVJC1lnCP2nwKXVdVLgYuBK5JcCtwIvK+qtgOPA9fNrkxJ0riWDPYa+EkbPa09CrgMuKW17wGumUmFkqSJjHWOPcmmJPcCx4C9wIPAE1V1vM1yBDh/NiVKkiYxVrBX1c+q6mJgK3AJ8OJRs41aNsnOJPuT7H/ssceWX6kkaSwTvSumqp4A7gQuBc5McuIbmLYCjyyyzO6qWqiqhbm5uZXUKkkawzjviplLcmYbfjbwSuAgcAfw+jbbDuDWWRUpSRrfON95ugXYk2QTgz8EN1fV55J8C/hkkr8Fvg58eIZ1SpLGtGSwV9V9wMtGtD/E4Hy7JGkd8ZOnktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmfG+TJrSZqq+V23r8l6H77hqjVZ72rziF2SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzSwZ7kguS3JHkYJL7k7y9tZ+dZG+SQ+35rNmXK0layjhH7MeBP6+qFwOXAm9NchGwC9hXVduBfW1ckrTGlgz2qjpaVV9rwz8GDgLnA1cDe9pse4BrZlWkJGl8E33RRpJ54GXAXcB5VXUUBuGf5NxFltkJ7ATYtm3bSmp9xlmrLyOQtLGNffE0yXOBTwPvqKofjbtcVe2uqoWqWpibm1tOjZKkCYwV7ElOYxDqH6uqz7TmR5NsadO3AMdmU6IkaRLjvCsmwIeBg1X190OTbgN2tOEdwK3TL0+SNKlxzrG/AvhD4JtJ7m1tfwXcANyc5Drge8AbZlOiJGkSSwZ7Vf0nkEUmXz7dciRJK+UnTyWpMwa7JHVmovexS5o+P6+gafOIXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR1xmCXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpM0sGe5KPJDmW5MBQ29lJ9iY51J7Pmm2ZkqRxjXPE/s/AFae07QL2VdV2YF8blyStA0sGe1V9CfjhKc1XA3va8B7gminXJUlaps3LXO68qjoKUFVHk5y72IxJdgI7AbZt27bM1cH8rtuXvexKPHzDVWuyXknT90zJkZlfPK2q3VW1UFULc3Nzs16dJD3jLTfYH02yBaA9H5teSZKklVhusN8G7GjDO4Bbp1OOJGmlxnm74yeALwMvSnIkyXXADcCrkhwCXtXGJUnrwJIXT6vqjYtMunzKtUiSpsBPnkpSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ1Z7hdtPGOs1Y35JWm5PGKXpM4Y7JLUGYNdkjpjsEtSZwx2SeqMwS5JnTHYJakzBrskdcZgl6TOGOyS1BmDXZI6Y7BLUmcMdknqjMEuSZ0x2CWpMwa7JHXGYJekzhjsktQZg12SOmOwS1JnDHZJ6syKgj3JFUkeSHI4ya5pFSVJWr5lB3uSTcAHgdcCFwFvTHLRtAqTJC3PSo7YLwEOV9VDVfW/wCeBq6dTliRpuTavYNnzge8PjR8BfuPUmZLsBHa20Z8keWAF6zzVOcAPpvjz1pJ9Wb966o99WQO5cazZnq4/vzrJ+lYS7BnRVk9pqNoN7F7BehYvINlfVQuz+Nmrzb6sXz31x76sX9Psz0pOxRwBLhga3wo8srJyJEkrtZJg/yqwPcmFSU4HrgVum05ZkqTlWvapmKo6nuRtwBeATcBHqur+qVU2npmc4lkj9mX96qk/9mX9mlp/UvWU0+KSpA3MT55KUmcMdknqzLoN9iR/k+S+JPcm+WKSX2ntSfKBdhuD+5K8fGiZHUkOtceOofZfT/LNtswHkox6q+Ys+/LeJN9u9X42yZlD097Z6nogyWuG2kferqFdrL6r9fGmduF6VSV5Q5L7k/w8ycIp0zZcfxazUW6ZkeQjSY4lOTDUdnaSve33ujfJWa194v1nlftyQZI7khxs29jbN2p/kpyR5O4k32h9eXdrH7nNJ3lWGz/cps8P/ayR+9WiqmpdPoDnDw3/KfChNnwl8HkG76O/FLirtZ8NPNSez2rDZ7VpdwO/2Zb5PPDaVe7Lq4HNbfhG4MY2fBHwDeBZwIXAgwwuRG9qwy8ETm/zXNSWuRm4tg1/CPjjNXhtXgy8CLgTWBhq35D9WaSPi9a83h7AbwMvBw4Mtb0H2NWGdw1tcxPvP6vcly3Ay9vw84DvtO1qw/Wn1fTcNnwacFerceQ2D7yFJ3PuWuCmNjxyv3q6da/bI/aq+tHQ6HN48sNPVwMfrYGvAGcm2QK8BthbVT+sqseBvcAVbdrzq+rLNfgtfRS4ZvV6AlX1xao63ka/wuA9/yf68smq+mlVfRc4zOBWDSNv19D+07gMuKUtv4dV7gtAVR2sqlGfIN6Q/VnEhrllRlV9CfjhKc1XM/h9wsm/14n2n9lXf7KqOlpVX2vDPwYOMviU+4brT6vpJ230tPYoFt/mh/t4C3B520cW268WtW6DHSDJ3yX5PvAm4F2tedStDM5fov3IiPa18mYGRxgweV9eADwx9Edirftyqp76s1jNG8V5VXUUBmEJnNvaJ32N1kw7FfEyBke6G7I/STYluRc4xuCPy4Msvs3/ouY2/X8Y7CMT92VNgz3JvyU5MOJxNUBVXV9VFwAfA952YrERP6qW0T5VS/WlzXM9cJxBf1hGzavSFxivP6MWW6S+Ne/PMqzn2lZiQ7wWSZ4LfBp4xyn/vT9l1hFt66Y/VfWzqrqYwX/plzA4jfmU2drz1PqyknvFrFhVvXLMWT8O3A78NYvfyuAI8DuntN/Z2reOmH+qlupLu3jzOuDydkoInv62DKPaf8DgX83N7S/6zG7jMMFrM2zd9mcZNvotMx5NsqWqjrZTE8da+6T7z6pLchqDUP9YVX2mNW/Y/gBU1RNJ7mRwjn2xbf5EX44k2Qz8MoNTbJNvi6t5MWHCCw/bh4b/BLilDV/FyRdL7q4nL5Z8l8GFkrPa8Nlt2lfbvCcunl65yn25AvgWMHdK+0s4+aLIQwwu2m1uwxfy5IW7l7RlPsXJF17esoav0Z2cfPF0Q/fnlL4tWvN6fADznHzx9L2cfLHxPW144v1nlfsRBtfB3n9K+4brDzAHnNmGnw38B4ODu5HbPPBWTr54enMbHrlfPe2613qDfJpfyqeBA8B9wL8A5w+98B9kcK7qm6cEy5sZXFg4DPzRUPtC+1kPAv9A+8TtKvblMINzZPe2x4eGpl3f6nqAoXfrMLja/5027fqh9hcyeJfP4baBPGsNXpvfZ3AU8VPgUeALG7k/T9PPkTWvtwfwCeAo8H/tdbmOwbnZfcCh9nziIGfi/WeV+/JbDE4z3De0v1y5EfsD/Brw9daXA8C7WvvIbR44o40fbtNfOPSzRu5Xiz28pYAkdWZdvytGkjQ5g12SOmOwS1JnDHZJ6ozBLkmdMdglqTMGuyR15v8BMFBVJ2+0eJYAAAAASUVORK5CYII=
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(33.1751, 1318.7448)
tensor(6.9012) tensor(798.8826)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-193.5696, 31778.0195)
tensor(43.3803) tensor(998.2910)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-1093.7861, 11979.1465)
tensor(-104.1612) tensor(982.8121)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAPjklEQVR4nO3db4xc1XnH8e8TDKRNSLBhQRbGXdO6CPIiQFaUiqZqcf4YnAa3DRGoqqwWadWGSNC0ajdFqlKpL0yiNKhqVOSWKJuKBBMSBMJqg+viVFUTgw3mXxxi4zipY9c2AQqRKionT1/MWWV2Pbvzf3YP/X6k0dx75s49z5y5+9u7986djcxEklSfNy12AZKk3hjgklQpA1ySKmWAS1KlDHBJqtSyUXZ27rnn5vj4+Ci7lKTq7dmz58XMHJvbPtIAHx8fZ/fu3aPsUpKqFxHfa9XuIRRJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSarUSK/ElHSq8alti9Lvoc0bFqVfDY574JJUKQNckiplgEtSpQxwSapURycxI+IQ8BrwY+BkZk5ExApgKzAOHAI+nJkvD6dMSdJc3eyB/3pmXpaZE2V+CtiRmWuBHWVekjQi/RxCuR6YLtPTwMb+y5EkdarTAE/gkYjYExGTpe38zDwKUO7Pa/XEiJiMiN0RsfvEiRP9VyxJAjq/kOfqzDwSEecB2yPi2512kJlbgC0AExMT2UONkqQWOtoDz8wj5f448ABwJXAsIlYClPvjwypSknSqtgEeEW+JiLNmpoH3Ac8CDwGbymKbgAeHVaQk6VSdHEI5H3ggImaW/2Jm/nNEPA7cFxE3A98HbhhemZKkudoGeGYeBN7Zov2HwLphFCVJas8rMSWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVaqT/4kp6Q1ofGrbovV9aPOGRev7jcQ9cEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIdB3hEnBYRT0bEw2V+TUTsioj9EbE1Is4YXpmSpLm62QO/FdjXNH8H8JnMXAu8DNw8yMIkSQvrKMAjYhWwAfiHMh/ANcD9ZZFpYOMwCpQktdbpHvidwJ8CPynz5wCvZObJMn8YuGDAtUmSFtA2wCPiA8DxzNzT3Nxi0Zzn+ZMRsTsidp84caLHMiVJc3WyB3418MGIOATcS+PQyZ3A2REx8w8hVgFHWj05M7dk5kRmToyNjQ2gZEkSdBDgmfnxzFyVmePAjcC/ZubvAI8CHyqLbQIeHFqVkqRT9PM58D8DPhYRB2gcE797MCVJkjrR1f/EzMydwM4yfRC4cvAlSZI64ZWYklQpA1ySKtXVIRTpjWp8attilyB1zT1wSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIq5efAtaT4eWypc+6BS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUm0DPCLeHBGPRcRTEfFcRPxlaV8TEbsiYn9EbI2IM4ZfriRpRid74K8D12TmO4HLgPURcRVwB/CZzFwLvAzcPLwyJUlztQ3wbPhRmT293BK4Bri/tE8DG4dSoSSppWWdLBQRpwF7gF8APgu8ALySmSfLIoeBC+Z57iQwCbB69ep+69UIjE9tW+wSJHWgo5OYmfnjzLwMWAVcCVzSarF5nrslMycyc2JsbKz3SiVJs3T1KZTMfAXYCVwFnB0RM3vwq4Ajgy1NkrSQTj6FMhYRZ5fpnwHeA+wDHgU+VBbbBDw4rCIlSafq5Bj4SmC6HAd/E3BfZj4cEd8C7o2IvwKeBO4eYp2SpDnaBnhmPg1c3qL9II3j4ZKkReCVmJJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVaptgEfEhRHxaETsi4jnIuLW0r4iIrZHxP5yv3z45UqSZnSyB34S+OPMvAS4CrglIi4FpoAdmbkW2FHmJUkj0jbAM/NoZj5Rpl8D9gEXANcD02WxaWDjsIqUJJ1qWTcLR8Q4cDmwCzg/M49CI+Qj4rx5njMJTAKsXr26n1olvUGMT21blH4Pbd6wKP0OS8cnMSPircBXgNsy89VOn5eZWzJzIjMnxsbGeqlRktRCRwEeEafTCO97MvOrpflYRKwsj68Ejg+nRElSK518CiWAu4F9mfnXTQ89BGwq05uABwdfniRpPp0cA78a+F3gmYjYW9r+HNgM3BcRNwPfB24YTomSpFbaBnhm/jsQ8zy8brDlSJI65ZWYklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKrVssQvQ/Manti12CZKWMPfAJalSBrgkVcoAl6RKGeCSVKm2AR4Rn4uI4xHxbFPbiojYHhH7y/3y4ZYpSZqrkz3wzwPr57RNATsycy2wo8xLkkaobYBn5r8BL81pvh6YLtPTwMYB1yVJaqPXz4Gfn5lHATLzaEScN9+CETEJTAKsXr26x+4kqX+LdW3Foc0bhrLeoZ/EzMwtmTmRmRNjY2PD7k6S/t/oNcCPRcRKgHJ/fHAlSZI60WuAPwRsKtObgAcHU44kqVOdfIzwS8A3gIsj4nBE3AxsBt4bEfuB95Z5SdIItT2JmZk3zfPQugHXIknqgldiSlKlDHBJqpTfB96G38ktaalyD1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEpV8zlwP48tSbO5By5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEr1FeARsT4ino+IAxExNaiiJEnt9RzgEXEa8FngWuBS4KaIuHRQhUmSFtbPHviVwIHMPJiZ/wvcC1w/mLIkSe0s6+O5FwD/2TR/GPiluQtFxCQwWWZ/FBHPt1jXucCLfdQyatY7XNY7XLXVC/XVPKveuKPv9f1cq8Z+AjxatOUpDZlbgC0Lrihid2ZO9FHLSFnvcFnvcNVWL9RX86jq7ecQymHgwqb5VcCR/sqRJHWqnwB/HFgbEWsi4gzgRuChwZQlSWqn50MomXkyIj4KfA04DfhcZj7X4+oWPMSyBFnvcFnvcNVWL9RX80jqjcxTDltLkirglZiSVCkDXJIqNbAAj4gbIuK5iPhJREzMeezj5XL75yPi/U3tLS/FLydGd0XE/ojYWk6SEhFnlvkD5fHxdn10WPvWiNhbbociYm9pH4+I/2l67K6m57wrIp4pff5NRERpXxER20vt2yNieWmPstyBiHg6Iq7opsY59X4iIn7QVNd17cZhkGPdQ72fiohvl9f9QEScXdqX5Ph2+doW5eskIuLCiHg0IvaVn7tbS/vQt40+6z5U3te9EbG7tHX9nkbEprL8/ojY1NTecrvpsdaLm8Zxb0S8GhG3LakxzsyB3IBLgIuBncBEU/ulwFPAmcAa4AUaJz1PK9MXAWeUZS4tz7kPuLFM3wX8YZn+CHBXmb4R2LpQHz2+jk8Df1Gmx4Fn51nuMeCXaXwe/p+Aa0v7J4GpMj0F3FGmryvLBXAVsKuPsf4E8Cct2oc+1j3W+z5gWZm+o2lMluT4dvG65h3XEfS9EriiTJ8FfKe8/0PfNvqs+xBw7py2rt5TYAVwsNwvL9PLF9puBvRe/xeNC2qWzBgPbA88M/dlZqurLK8H7s3M1zPzu8ABGpfht7wUv/zGvAa4vzx/GtjYtK7pMn0/sK4sP18fXSnr+jDwpTbLrQTelpnfyMbIf2GeGufW/oVs+CZwdlnPII1irLuWmY9k5sky+00a1wzMawmP71yL9nUSmXk0M58o068B+2hcHT2fQW4bg9bte/p+YHtmvpSZLwPbgfVttpt+rQNeyMzvtXkdIx3jURwDb3XJ/QULtJ8DvNL0Az/TPmtd5fH/LsvPt65uvRs4lpn7m9rWRMSTEfH1iHh3Ux2H5+nv/Mw8Wmo8Cpw3t/Y+a5zx0fJn5edm/uRcoI9BjnW/fp/GntGMpTq+nViMPk8RjcNblwO7StOwt41+JPBIROyJxtdsQPfv6ULt8203/bqR2Tt2S2KMuwrwiPiXiHi2xW2hvY75Lrnvtr2XdXVb+03MfpOOAqsz83LgY8AXI+JtnfTXQlfPaVPv3wE/D1xWavx0mz4GOda91DuzzO3ASeCe0rRo4zsgi9Hn7AIi3gp8BbgtM19lNNtGP67OzCtofIvpLRHxqwssuyRqLselPwh8uTQtmTHu6kKezHxPN8sXC11y36r9RRp/Ki0rv5mal59Z1+GIWAa8HXipTR8d1V7W91vAu5qe8zrwepneExEvAL9Y+ms+DNDc37GIWJmZR8ufdMc7GIdTdDrWEfH3wMMd9DGose6p3nKi6QPAuvLn7aKO74As6tdJRMTpNML7nsz8KkBmHmt6fFjbRs8y80i5Px4RD9A4vNDte3oY+LU57TtZeLvpx7XAEzNju6TGeBAH+OccyN/J7JOY72D2gf2DNA7qLyvTa/jpgf13lOd8mdkH9j9Spm9h9om1+xbqo8u61wNfn9M2NrMeGicgfgCsKPOP0zixMnOy5LrS/ilmn5D5ZJnewOwTMo/1McYrm6b/iMZxt5GMdY/1rge+BYzVML5dvK55x3UEfQeNY7x3jnrb6KPmtwBnNU3/R9k2unpPaZy8/C6NE5jLy/SC202fdd8L/N5SHONBblC/SeM30OvAMeBrTY/dTuMs7PM0nRWmcZb5O+Wx25vaL6JxNvlAeYFnlvY3l/kD5fGL2vXRRf2fB/5gTttvA8+VAX8C+I2mxyaAZ0uff8tPr2o9B9gB7C/3MxtW0PgHGC8Az9D0S66HWv+xrONpGt8/07xBDX2se6j3AI1jgHvLbeYXw5Ic3y5fW8txHUG/v0Ljz+2nm8b1ulFsG33UfFF5r58q7/vtvb6nNM6lHCi35nBtud30UfPPAj8E3j7Kn79Ob15KL0mV8kpMSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIq9X90WWwVk+8h3QAAAABJRU5ErkJggg==
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(3164.0146, 35859.3125)
tensor(81.5004) tensor(991.8568)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-1254.1228, 13872.3652)
tensor(-105.7121) tensor(984.0605)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(3300.1748, 37887.875)
tensor(83.0058) tensor(991.3549)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-1059.9579, 14192.6484)
tensor(-82.3730) tensor(986.9633)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(2753.9849, 37713.6133)
tensor(80.4163) tensor(996.7465)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(-934.8754, 14230.0137)
tensor(-98.5673) tensor(985.5751)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">is_leaf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>True</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">is_leaf</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>False</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-30-1f8a688cae5d&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>model

<span class="ansi-red-fg">NameError</span>: name &#39;model&#39; is not defined</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

