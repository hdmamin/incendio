---

title: Title

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/scratch_reflection_pad.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="kn">from</span> <span class="nn">incendio.core</span> <span class="k">import</span> <span class="n">BaseModel</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">leaky_relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">adapt</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    
<span class="k">class</span> <span class="nc">Model2</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_outs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">c_in</span><span class="p">]</span> <span class="o">+</span> <span class="n">c_outs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>
                                   <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">*</span><span class="p">(</span><span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span><span class="p">),</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
                                   <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">())</span>
                                   <span class="k">for</span> <span class="n">c_in</span><span class="p">,</span> <span class="n">c_out</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">dims</span><span class="p">,</span> <span class="n">dims</span><span class="p">[</span><span class="mi">1</span><span class="p">:])])</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c_outs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m2</span> <span class="o">=</span> <span class="n">Model2</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">])</span>
<span class="n">m2</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model2(
  (enc): Sequential(
    (0): Sequential(
      (0): ReflectionPad2d((2, 2, 2, 2))
      (1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))
      (2): LeakyReLU(negative_slope=0.01)
    )
    (1): Sequential(
      (0): ReflectionPad2d((2, 2, 2, 2))
      (1): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))
      (2): LeakyReLU(negative_slope=0.01)
    )
    (2): Sequential(
      (0): ReflectionPad2d((2, 2, 2, 2))
      (1): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))
      (2): LeakyReLU(negative_slope=0.01)
    )
  )
  (pool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=32, out_features=1, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">m1</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="n">m1</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Model(
  (pad): ReflectionPad2d((2, 2, 2, 2))
  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))
  (adapt): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=16, out_features=1, bias=True)
)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[[  6., 210., 214.,  38.],
          [176., 197.,  80., 112.],
          [168.,  81., 106., 252.],
          [202.,  38., 147., 102.]],

         [[ 28.,  64., 112., 143.],
          [152.,  87., 219., 151.],
          [123., 154.,  79.,  27.],
          [127., 198., 100., 223.]],

         [[253., 150., 155., 243.],
          [222.,  96., 219.,  40.],
          [ 75., 251., 234., 149.],
          [112., 234., 204.,  13.]]],


        [[[248., 236., 113., 144.],
          [223.,  34., 192., 156.],
          [248., 183.,  35.,  35.],
          [101.,  64.,  25., 203.]],

         [[ 23., 145.,  52., 237.],
          [119., 254., 116., 180.],
          [ 70., 199., 149.,   5.],
          [ 78.,  58.,  22.,  34.]],

         [[221., 226.,  48., 109.],
          [212., 146.,  67.,   0.],
          [ 65.,  45., 175.,  85.],
          [233., 187., 190.,  22.]]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 4, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show_img</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_img</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 4, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 3, 4, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pad</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">x_pad</span> <span class="o">=</span> <span class="n">pad</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_pad</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 3, 8, 8])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">show_img</span><span class="p">(</span><span class="n">x_pad</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ReflectionPaddedConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                 <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reflect</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span>
                              <span class="n">stride</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reflect</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">rc</span> <span class="o">=</span> <span class="n">ReflectionPaddedConv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">rc</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">rc</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([0., 0., 0.], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">r</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">x_p</span> <span class="o">=</span> <span class="n">r</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x_p</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([2, 3, 4, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Applies a 2D convolution over an input signal composed of several input
    planes.

    In the simplest case, the output value of the layer with input size
    :math:`(N, C_{\text{in}}, H, W)` and output :math:`(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})`
    can be precisely described as:

    .. math::
        \text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
        \sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)


    where :math:`\star` is the valid 2D `cross-correlation`_ operator,
    :math:`N` is a batch size, :math:`C` denotes a number of channels,
    :math:`H` is a height of input planes in pixels, and :math:`W` is
    width in pixels.

    * :attr:`stride` controls the stride for the cross-correlation, a single
      number or a tuple.

    * :attr:`padding` controls the amount of implicit zero-paddings on both
      sides for :attr:`padding` number of points for each dimension.

    * :attr:`dilation` controls the spacing between the kernel points; also
      known as the à trous algorithm. It is harder to describe, but this `link`_
      has a nice visualization of what :attr:`dilation` does.

    * :attr:`groups` controls the connections between inputs and outputs.
      :attr:`in_channels` and :attr:`out_channels` must both be divisible by
      :attr:`groups`. For example,

        * At groups=1, all inputs are convolved to all outputs.
        * At groups=2, the operation becomes equivalent to having two conv
          layers side by side, each seeing half the input channels,
          and producing half the output channels, and both subsequently
          concatenated.
        * At groups= :attr:`in_channels`, each input channel is convolved with
          its own set of filters, of size:
          :math:`\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor`.

    The parameters :attr:`kernel_size`, :attr:`stride`, :attr:`padding`, :attr:`dilation` can either be:

        - a single ``int`` -- in which case the same value is used for the height and width dimension
        - a ``tuple`` of two ints -- in which case, the first `int` is used for the height dimension,
          and the second `int` for the width dimension

    .. note::

         Depending of the size of your kernel, several (of the last)
         columns of the input might be lost, because it is a valid `cross-correlation`_,
         and not a full `cross-correlation`_.
         It is up to the user to add proper padding.

    .. note::

        When `groups == in_channels` and `out_channels == K * in_channels`,
        where `K` is a positive integer, this operation is also termed in
        literature as depthwise convolution.

        In other words, for an input of size :math:`(N, C_{in}, H_{in}, W_{in})`,
        a depthwise convolution with a depthwise multiplier `K`, can be constructed by arguments
        :math:`(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})`.

    .. include:: cudnn_deterministic.rst

    Args:
        in_channels (int): Number of channels in the input image
        out_channels (int): Number of channels produced by the convolution
        kernel_size (int or tuple): Size of the convolving kernel
        stride (int or tuple, optional): Stride of the convolution. Default: 1
        padding (int or tuple, optional): Zero-padding added to both sides of the input. Default: 0
        padding_mode (string, optional). Accepted values `zeros` and `circular` Default: `zeros`
        dilation (int or tuple, optional): Spacing between kernel elements. Default: 1
        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1
        bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``

    Shape:
        - Input: :math:`(N, C_{in}, H_{in}, W_{in})`
        - Output: :math:`(N, C_{out}, H_{out}, W_{out})` where

          .. math::
              H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
                        \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor

          .. math::
              W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
                        \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor

    Attributes:
        weight (Tensor): the learnable weights of the module of shape
                         :math:`(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},`
                         :math:`\text{kernel\_size[0]}, \text{kernel\_size[1]})`.
                         The values of these weights are sampled from
                         :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                         :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`
        bias (Tensor):   the learnable bias of the module of shape (out_channels). If :attr:`bias` is ``True``,
                         then the values of these weights are
                         sampled from :math:`\mathcal{U}(-\sqrt{k}, \sqrt{k})` where
                         :math:`k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}`

    Examples::

        &gt;&gt;&gt; # With square kernels and equal stride
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, 3, stride=2)
        &gt;&gt;&gt; # non-square kernels and unequal stride and with padding
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))
        &gt;&gt;&gt; # non-square kernels and unequal stride and with padding and dilation
        &gt;&gt;&gt; m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
        &gt;&gt;&gt; input = torch.randn(20, 16, 50, 100)
        &gt;&gt;&gt; output = m(input)

    .. _cross-correlation:
        https://en.wikipedia.org/wiki/Cross-correlation

    .. _link:
        https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md
    
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

