---

title: To do:

keywords: fastai
sidebar: home_sidebar



---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: notebooks/scratch_bloom_embeddings.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">abc</span><span class="p">,</span> <span class="n">Counter</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="k">import</span> <span class="n">lru_cache</span>
<span class="kn">from</span> <span class="nn">itertools</span> <span class="k">import</span> <span class="n">chain</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mmh3</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="k">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">htools</span> <span class="k">import</span> <span class="n">hdir</span><span class="p">,</span> <span class="n">eprint</span><span class="p">,</span> <span class="n">assert_raises</span><span class="p">,</span> <span class="n">flatten</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sents</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s1">&#39;I walked to the store so I hope it is not closed.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;The theater is closed today and the sky is grey.&#39;</span><span class="p">,</span>
    <span class="s1">&#39;His dog is brown while hers is grey.&#39;</span>
<span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">Data</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sentences</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2i</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_w2i</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span> <span class="o">=</span> <span class="n">seq_len</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">make_w2i</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tok_rows</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span> <span class="ow">in</span> 
                <span class="nb">enumerate</span><span class="p">(</span><span class="n">Counter</span><span class="p">(</span><span class="n">chain</span><span class="p">(</span><span class="o">*</span><span class="n">tok_rows</span><span class="p">))</span><span class="o">.</span><span class="n">most_common</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)}</span>
    
    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tok_rows</span><span class="p">):</span>
        <span class="n">enc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">tok_rows</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tok_rows</span><span class="p">):</span>
            <span class="n">trunc</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">w2i</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">row</span><span class="p">[:</span><span class="bp">self</span><span class="o">.</span><span class="n">seq_len</span><span class="p">]]</span>
            <span class="n">enc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="n">trunc</span><span class="p">)]</span> <span class="o">=</span> <span class="n">trunc</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">enc</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span> <span class="o">=</span> <span class="n">Data</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">ds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4]), tensor(1))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]), tensor([0, 1, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 10])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds</span><span class="o">.</span><span class="n">w2i</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;is&#39;: 1,
 &#39;I&#39;: 2,
 &#39;the&#39;: 3,
 &#39;grey.&#39;: 4,
 &#39;walked&#39;: 5,
 &#39;to&#39;: 6,
 &#39;store&#39;: 7,
 &#39;so&#39;: 8,
 &#39;hope&#39;: 9,
 &#39;it&#39;: 10,
 &#39;not&#39;: 11,
 &#39;closed.&#39;: 12,
 &#39;The&#39;: 13,
 &#39;theater&#39;: 14,
 &#39;closed&#39;: 15,
 &#39;today&#39;: 16,
 &#39;and&#39;: 17,
 &#39;sky&#39;: 18,
 &#39;His&#39;: 19,
 &#39;dog&#39;: 20,
 &#39;brown&#39;: 21,
 &#39;while&#39;: 22,
 &#39;hers&#39;: 23}</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>For now, just convert int to str and take hash. Another option that is meant for ints is Knuth's multiplicative method:</p>
<p>hash(i) = i*2654435761 mod 2^32</p>
<p>But we'd need to make this dependent on a random seed.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">probabilistic_hash_item</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hashes</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Slightly hacky way to probabilistically hash an integer by</span>
<span class="sd">    first converting it to a string.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: int</span>
<span class="sd">        The integer or string to hash.</span>
<span class="sd">    n_buckets: int</span>
<span class="sd">        The number of buckets that items will be mapped to. Typically </span>
<span class="sd">        this would occur outside the hashing function, but since </span>
<span class="sd">        the intended use case is so narrow here it makes sense to me </span>
<span class="sd">        to include it here.</span>
<span class="sd">    mode: type</span>
<span class="sd">        The type of input you want to hash. This is user-provided to prevent</span>
<span class="sd">        accidents where we pass in a different item than intended and hash </span>
<span class="sd">        the wrong thing. One of (int, str). When using this inside a</span>
<span class="sd">        BloomEmbedding layer, this must be `int` because there are no</span>
<span class="sd">        string tensors. When used inside a dataset or as a one-time</span>
<span class="sd">        pre-processing step, you can choose either as long as you</span>
<span class="sd">        pass in the appropriate inputs.</span>
<span class="sd">    n_hashes: int</span>
<span class="sd">        The number of times to hash x, each time with a different seed.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[int]: A list of integers with length `n_hashes`, where each integer</span>
<span class="sd">        is in [0, n_buckets).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check type to ensure we don&#39;t accidentally hash Tensor(5) instead of 5.</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="p">),</span> <span class="n">f</span><span class="s1">&#39;Input `x` must have type </span><span class="si">{mode}</span><span class="s1">.&#39;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">i</span><span class="p">,</span> <span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_buckets</span> 
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_hashes</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x_r2</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="n">n_hashes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Hash a rank 2 LongTensor.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x_r2: torch.LongTensor</span>
<span class="sd">        Rank 2 tensor of integers. Shape: (bs, seq_len)</span>
<span class="sd">    n_buckets: int</span>
<span class="sd">        Number of buckets to hash items into (i.e. the number of </span>
<span class="sd">        rows in the embedding matrix). Typically a moderately large</span>
<span class="sd">        prime number, like 251 or 997.</span>
<span class="sd">    n_hashes: int</span>
<span class="sd">        Number of hashes to take for each input index. This determines</span>
<span class="sd">        the number of rows of the embedding matrix that will be summed</span>
<span class="sd">        to get the representation for each word. Typically 2-5.</span>
<span class="sd">    pad_idx: int or None</span>
<span class="sd">        If you want to pad sequences with vectors of zeros, pass in an</span>
<span class="sd">        integer (same as the `padding_idx` argument to nn.Embedding).</span>
<span class="sd">        If None, no padding index will be used. The sequences must be</span>
<span class="sd">        padded before passing them into this function.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.LongTensor: Tensor of indices where each row corresponds</span>
<span class="sd">        to one of the input indices. Shape: (bs, seq_len, n_hashes)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_hashes</span><span class="p">)</span> 
          <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">pad_idx</span> <span class="k">else</span> <span class="p">[</span><span class="n">pad_idx</span><span class="p">]</span><span class="o">*</span><span class="n">n_hashes</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
         <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">x_r2</span><span class="p">]</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">row</span><span class="p">],</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0
tensor([ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1])
[2, 5, 6, 3, 7, 8, 2, 9, 10, 1]

1
tensor([13, 14,  1, 15, 16, 17,  3, 18,  1,  4])
[13, 14, 1, 15, 16, 17, 3, 18, 1, 4]

2
tensor([19, 20,  1, 21, 22, 23,  1,  4,  0,  0])
[19, 20, 1, 21, 22, 23, 1, 4, 0, 0]

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[ 8,  2,  7],
         [ 2,  8,  1],
         [ 6,  6, 10],
         [10,  5,  5],
         [ 6,  9,  7],
         [ 5,  9,  4],
         [ 8,  2,  7],
         [ 5, 10,  8],
         [ 7,  8,  6],
         [ 6, 10,  6]],

        [[ 2,  5,  1],
         [ 9,  8,  8],
         [ 6, 10,  6],
         [ 8,  1, 10],
         [ 6,  3,  9],
         [ 2,  6,  9],
         [10,  5,  5],
         [10,  5,  0],
         [ 6, 10,  6],
         [ 4,  8,  6]],

        [[ 2, 10,  6],
         [ 1,  7,  8],
         [ 6, 10,  6],
         [ 2,  7,  1],
         [ 9,  4,  8],
         [ 5,  3,  3],
         [ 6, 10,  6],
         [ 4,  8,  6],
         [ 0,  0,  0],
         [ 0,  0,  0]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">11</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[ 8,  2,  7],
         [ 2,  8,  1],
         [ 6,  6, 10],
         [10,  5,  5],
         [ 6,  9,  7],
         [ 5,  9,  4],
         [ 8,  2,  7],
         [ 5, 10,  8],
         [ 7,  8,  6],
         [ 6, 10,  6]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">11</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[ 2, 10,  6],
         [ 1,  7,  8],
         [ 6, 10,  6],
         [ 2,  7,  1],
         [ 9,  4,  8],
         [ 5,  3,  3],
         [ 6, 10,  6],
         [ 4,  8,  6],
         [ 0,  0,  0],
         [ 0,  0,  0]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="p">[</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">11</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[[8, 2, 7],
 [2, 8, 1],
 [6, 6, 10],
 [10, 5, 5],
 [6, 9, 7],
 [5, 9, 4],
 [8, 2, 7],
 [5, 10, 8],
 [7, 8, 6],
 [6, 10, 6]]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">17</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[9, 8, 1]
[2, 6, 9]
[8, 2, 7]
[2, 5, 7]
[10, 10, 2]
[0, 10, 4]
[3, 8, 4]
[6, 5, 0]
[6, 10, 8]
[4, 4, 0]
[7, 1, 0]
[10, 4, 6]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">sents</span><span class="p">]:</span>
    <span class="n">eprint</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="p">(</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">row</span><span class="p">))))</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre> 0: (&#39;I&#39;, [0, 5, 5])
 1: (&#39;walked&#39;, [2, 5, 1])
 2: (&#39;to&#39;, [10, 4, 6])
 3: (&#39;the&#39;, [4, 1, 4])
 4: (&#39;store&#39;, [4, 6, 3])
 5: (&#39;so&#39;, [7, 8, 8])
 6: (&#39;I&#39;, [0, 5, 5])
 7: (&#39;hope&#39;, [1, 2, 7])
 8: (&#39;it&#39;, [3, 9, 0])
 9: (&#39;is&#39;, [3, 1, 3])
10: (&#39;not&#39;, [6, 10, 4])
11: (&#39;closed.&#39;, [3, 6, 10])

 0: (&#39;The&#39;, [1, 6, 9])
 1: (&#39;theater&#39;, [8, 10, 2])
 2: (&#39;is&#39;, [3, 1, 3])
 3: (&#39;closed&#39;, [5, 5, 0])
 4: (&#39;today&#39;, [3, 10, 8])
 5: (&#39;and&#39;, [7, 2, 4])
 6: (&#39;the&#39;, [4, 1, 4])
 7: (&#39;sky&#39;, [1, 2, 9])
 8: (&#39;is&#39;, [3, 1, 3])
 9: (&#39;grey.&#39;, [7, 6, 7])

 0: (&#39;His&#39;, [0, 10, 3])
 1: (&#39;dog&#39;, [8, 6, 6])
 2: (&#39;is&#39;, [3, 1, 3])
 3: (&#39;brown&#39;, [9, 8, 9])
 4: (&#39;while&#39;, [9, 2, 8])
 5: (&#39;hers&#39;, [0, 5, 4])
 6: (&#39;is&#39;, [3, 1, 3])
 7: (&#39;grey.&#39;, [7, 6, 7])

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sents</span><span class="p">),</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)),</span> <span class="s1">&#39;np array&#39;</span>
<span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)),</span> <span class="s1">&#39;list&#39;</span>
<span class="k">with</span> <span class="n">assert_raises</span><span class="p">(</span><span class="ne">AssertionError</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)),</span> <span class="s1">&#39;torch tensor&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>As expected, got AssertionError(torch tensor).
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="p">(</span><span class="n">abc</span><span class="o">.</span><span class="n">Iterable</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Collection</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Container</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">Sequence</span><span class="p">,</span> <span class="n">abc</span><span class="o">.</span><span class="n">MutableSequence</span><span class="p">):</span>
    <span class="n">tname</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="vm">__name__</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tname</span><span class="p">,</span> <span class="s1">&#39;tensor&#39;</span><span class="p">,</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tname</span><span class="p">,</span> <span class="s1">&#39;list&#39;</span><span class="p">,</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sents</span><span class="p">,</span> <span class="n">t</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tname</span><span class="p">,</span> <span class="s1">&#39;array&#39;</span><span class="p">,</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sents</span><span class="p">),</span> <span class="n">t</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Iterable tensor True
Iterable list True
Iterable array True

Collection tensor True
Collection list True
Collection array True

Container tensor True
Container list True
Container array True

Sequence tensor False
Sequence list True
Sequence array False

MutableSequence tensor False
MutableSequence list True
MutableSequence array False

</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingBag</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="n">emb</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[ 0.5849, -0.1108, -0.1991, -1.1982],
        [-0.5891,  1.5808,  1.4062, -1.5162],
        [-1.0055,  0.1712, -0.5717, -0.2766],
        [ 1.6280, -0.1770, -1.4850, -2.0490],
        [ 0.8724,  0.5324,  0.1913, -0.9653]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="n">emb</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-2.1837,  3.3329,  2.2408, -3.3091],
        [ 1.2073, -0.1165, -2.2557, -3.5238]], grad_fn=&lt;EmbeddingBagBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">BloomEmbedding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Bloom Embedding layer for memory-efficient word representations.</span>
<span class="sd">    Each word is encoded by a combination of rows of the embedding</span>
<span class="sd">    matrix. The number of rows can therefore be far lower than the number</span>
<span class="sd">    of words in our vocabulary while still providing unique representations.</span>
<span class="sd">    </span>
<span class="sd">    The reduction in rows allows us to use memory in other ways: </span>
<span class="sd">    a larger embedding dimension, more or larger layers after the embedding,</span>
<span class="sd">    or larger batch sizes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_emb</span><span class="o">=</span><span class="mi">251</span><span class="p">,</span> <span class="n">emb_dim</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_hashes</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                 <span class="n">pre_hashed</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_emb: int</span>
<span class="sd">            Number of rows to create in the embedding matrix. A prime</span>
<span class="sd">            number is recommended. Lower numbers will be more </span>
<span class="sd">            memory-efficient but increase the chances of collisions.</span>
<span class="sd">        emb_dim: int</span>
<span class="sd">            Size of each embedding. If emb_dim=100, each word will</span>
<span class="sd">            be represented by a 100-dimensional vector.</span>
<span class="sd">        n_hashes: int</span>
<span class="sd">            This determines the number of hashes that will be taken</span>
<span class="sd">            for each word index, and as a result, the number of rows</span>
<span class="sd">            that will be summed to create each unique representation.</span>
<span class="sd">            The higher the number, the lower the chances of a collision.</span>
<span class="sd">        padding_idx: int or None</span>
<span class="sd">            If an integer is provided, this will set aside the corresponding</span>
<span class="sd">            row in the embedding matrix as a vector of zeros. If None, no</span>
<span class="sd">            padding vector will be allocated.</span>
<span class="sd">        pre_hashed: bool</span>
<span class="sd">            Pass in True if the input tensor will already be hashed by the time </span>
<span class="sd">            it enters this layer (you may prefer pre-compute the hashes in the</span>
<span class="sd">            Dataset to save computation time during training). In this</span>
<span class="sd">            scenario, the layer is a simple embedding bag with mode &quot;sum&quot;. </span>
<span class="sd">            Pass in False if the inputs will be word indices that have not yet</span>
<span class="sd">            been hashed. In this case, hashing will be done inside the `forward`</span>
<span class="sd">            call.</span>
<span class="sd">            </span>
<span class="sd">        Suggested values for a vocab size of ~30,000:</span>
<span class="sd">        </span>
<span class="sd">        | n_emb | n_hashes | unique combos |</span>
<span class="sd">        |-------|----------|---------------|</span>
<span class="sd">        | 127   | 5        | 29,998        |</span>
<span class="sd">        | 251   | 4        | 29,996        |</span>
<span class="sd">        | 997   | 3        | 29,997        |</span>
<span class="sd">        | 5,003 | 2        | 29,969        |</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_emb</span> <span class="o">=</span> <span class="n">n_emb</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">n_emb</span><span class="p">,</span> <span class="n">emb_dim</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="n">padding_idx</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_hashes</span> <span class="o">=</span> <span class="n">n_hashes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span> <span class="o">=</span> <span class="n">padding_idx</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pre_hashed</span> <span class="o">=</span> <span class="n">pre_hashed</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x: torch.LongTensor</span>
<span class="sd">            Input tensor of word indices (bs x seq_len) if pre_hashed is False.</span>
<span class="sd">            Hashed indices (bs x seq_len x n_hashes) if pre_hashed is False.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.FloatTensor: Words encoded with combination of embeddings.</span>
<span class="sd">            (bs x seq_len x emb_dim)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">pre_hashed</span><span class="p">:</span>
            <span class="c1"># (bs, seq_len) -&gt; hash -&gt; (bs, seq_len, n_hashes)</span>
            <span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> 
                                               <span class="bp">self</span><span class="o">.</span><span class="n">n_emb</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">n_hashes</span><span class="p">,</span>
                                               <span class="bp">self</span><span class="o">.</span><span class="n">pad_idx</span><span class="p">)</span>
        <span class="c1"># (bs, seq_len, n_hashes, emb_dim) -&gt; sum -&gt; (bs, seq_len, emb_dim)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">emb</span><span class="p">(</span><span class="n">hashed</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dl</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
         [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
         [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]]), tensor([0, 1, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">be</span> <span class="o">=</span> <span class="n">BloomEmbedding</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">be</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Parameter containing:
tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0890,  2.8199,  1.8165, -1.9656],
        [ 1.2061,  0.3585, -0.5961, -1.2669],
        [-1.5584, -2.4416,  1.1176, -0.4356],
        [ 0.1442, -0.2951,  0.8433, -0.1157],
        [-0.2319,  0.6422, -0.1494,  0.2830],
        [ 0.7345,  2.0709,  1.4002,  0.0562],
        [-0.3707,  0.5033,  0.6533, -1.4163],
        [ 0.7275,  0.1103,  1.3854,  0.0924],
        [ 0.3850,  0.0692,  0.1639,  0.3658],
        [-1.2039, -1.9414, -0.2005, -0.4414]], requires_grad=True)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2,  5,  6,  3,  7,  8,  2,  9, 10,  1],
        [13, 14,  1, 15, 16, 17,  3, 18,  1,  4],
        [19, 20,  1, 21, 22, 23,  1,  4,  0,  0]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">24</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">11</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[9, 8, 1]
[6, 10, 6]
[8, 2, 7]
[10, 5, 5]
[4, 8, 6]
[2, 8, 1]
[6, 6, 10]
[6, 9, 7]
[5, 9, 4]
[5, 10, 8]
[7, 8, 6]
[7, 9, 2]
[1, 7, 3]
[2, 5, 1]
[9, 8, 8]
[8, 1, 10]
[6, 3, 9]
[2, 6, 9]
[10, 5, 0]
[2, 10, 6]
[1, 7, 8]
[2, 7, 1]
[9, 4, 8]
[5, 3, 3]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># (bs x seq_len) -&gt; (bs -&gt; seq_len -&gt; emb_size)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">be</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([3, 10, 4])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2.2904,  1.0825,  2.8281, -2.4985],
        [ 3.2287,  3.6471,  2.0098, -4.4070],
        [-0.9388,  0.2589,  2.3995, -0.7704],
        [-1.8995, -0.0147, -0.6485,  0.4076],
        [ 1.9549,  3.0019,  1.6213, -2.2612],
        [ 0.2973,  0.4164,  0.8578,  0.5331],
        [ 2.2904,  1.0825,  2.8281, -2.4985],
        [-0.3233, -1.1196,  1.1995,  0.2997],
        [ 2.2974,  3.0430,  2.8428, -2.5347],
        [ 0.2651,  2.2004,  2.6000, -0.3290]], grad_fn=&lt;SelectBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[ 2.2693,  4.1790,  0.4750, -4.2163],
        [ 2.5744,  2.3608,  4.3350,  0.6067],
        [ 0.2651,  2.2004,  2.6000, -0.3290],
        [-1.9458, -1.4528,  4.1191, -2.7502],
        [-0.4390, -0.3015,  2.6817, -0.0136],
        [ 2.3256,  2.4986,  0.9680, -0.8449],
        [-1.8995, -0.0147, -0.6485,  0.4076],
        [-0.2297, -0.9407, -0.9459, -1.4253],
        [ 0.2651,  2.2004,  2.6000, -0.3290],
        [ 2.8123,  2.2446,  3.0328, -1.2341]], grad_fn=&lt;SelectBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">y</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[-0.4671, -1.4535,  0.4032, -2.0935],
        [ 1.1803,  5.5044,  5.2554, -3.2333],
        [ 0.2651,  2.2004,  2.6000, -0.3290],
        [ 1.0686,  3.3866,  2.7170, -4.7645],
        [ 1.9912,  1.9554,  3.7928,  0.3986],
        [-2.6212, -4.1307,  3.4713, -0.4958],
        [ 0.2651,  2.2004,  2.6000, -0.3290],
        [ 2.8123,  2.2446,  3.0328, -1.2341],
        [ 0.0000,  0.0000,  0.0000,  0.0000],
        [ 0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=&lt;SelectBackward&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ds</span><span class="o">.</span><span class="n">w2i</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">be</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="n">i</span><span class="p">]]))</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">())</span>
<span class="c1">#           .emb.weight[hash_int(i, be.n_emb)])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>is 1 [ 0.26507235  2.2003503   2.5999665  -0.32898915]
I 2 [ 2.2903948  1.0824531  2.828073  -2.498523 ]
the 3 [-1.8995289  -0.01470172 -0.6485326   0.40761688]
grey. 4 [ 2.812286   2.24457    3.0328324 -1.2340608]
walked 5 [ 3.2286701  3.6471388  2.009758  -4.4069753]
to 6 [-0.93877876  0.2589332   2.3995147  -0.7704108 ]
store 7 [ 1.9548693  3.0019045  1.6212814 -2.2612271]
so 8 [0.29734743 0.41637933 0.85779124 0.5330522 ]
hope 9 [-0.3232504  -1.1195885   1.1994998   0.29972154]
it 10 [ 2.2973628  3.042996   2.8428445 -2.534657 ]
not 11 [ 0.8497246  1.4343383  0.8743619 -3.7337801]
closed. 12 [-3.043953  -1.0598472  3.3869708 -4.2589087]
The 13 [ 2.2692842  4.179036   0.4749601 -4.2163124]
theater 14 [2.5744486  2.3608148  4.334958   0.60669684]
closed 15 [-1.9457765 -1.452824   4.1191187 -2.7502215]
today 16 [-0.43895298 -0.30150518  2.6817129  -0.01360181]
and 17 [ 2.325552    2.498587    0.9679917  -0.84489024]
sky 18 [-0.22965312 -0.9407249  -0.9459034  -1.4252954 ]
His 19 [-0.4671499  -1.4534968   0.40321434 -2.0935135 ]
dog 20 [ 1.1802679  5.5044327  5.2554398 -3.2333224]
brown 21 [ 1.0686436  3.3865533  2.716979  -4.764516 ]
while 22 [1.9911952  1.9553655  3.792798   0.39860588]
hers 23 [-2.621228   -4.1306973   3.471336   -0.49583316]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">23</span><span class="p">])</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">hashed</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[5, 3, 3, 8]]])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">be</span><span class="o">.</span><span class="n">emb</span><span class="o">.</span><span class="n">weight</span><span class="p">[</span><span class="n">hashed</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([[[-2.6212, -4.1307,  3.4713, -0.4958]]], grad_fn=&lt;SumBackward1&gt;)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">unique_combos</span><span class="p">(</span><span class="n">tups</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">tups</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hash_all_idx</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="n">n_hashes</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_hashes</span><span class="p">)</span> 
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">)]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">buckets2hashes</span> <span class="o">=</span> <span class="p">{</span><span class="mi">127</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
                  <span class="mi">251</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
                  <span class="mi">997</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
                  <span class="mi">5_003</span><span class="p">:</span> <span class="mi">2</span><span class="p">}</span>
<span class="k">for</span> <span class="n">b</span><span class="p">,</span> <span class="n">h</span> <span class="ow">in</span> <span class="n">buckets2hashes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">tups</span> <span class="o">=</span> <span class="n">hash_all_idx</span><span class="p">(</span><span class="mi">30_000</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span>  <span class="n">h</span><span class="p">)</span>
    <span class="n">unique</span> <span class="o">=</span> <span class="n">unique_combos</span><span class="p">(</span><span class="n">tups</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Buckets:&#39;</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="s1">&#39;Hashes:&#39;</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="s1">&#39;Unique combos:&#39;</span><span class="p">,</span> <span class="n">unique</span><span class="p">,</span>
          <span class="s1">&#39;</span><span class="si">% u</span><span class="s1">nique:&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">unique</span><span class="o">/</span><span class="mi">30_000</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Buckets: 127 Hashes: 5 Unique combos: 29998 % unique: 0.99993
Buckets: 251 Hashes: 4 Unique combos: 29996 % unique: 0.99987
Buckets: 997 Hashes: 3 Unique combos: 29997 % unique: 0.9999
Buckets: 5003 Hashes: 2 Unique combos: 29969 % unique: 0.99897
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">eval_n_buckets</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">hash_sizes</span><span class="p">,</span> <span class="n">bucket_sizes</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">bs</span> <span class="ow">in</span> <span class="n">bucket_sizes</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">hs</span> <span class="ow">in</span> <span class="n">hash_sizes</span><span class="p">:</span>
            <span class="n">tups</span> <span class="o">=</span> <span class="n">hash_all_idx</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> <span class="n">hs</span><span class="p">)</span>
            <span class="n">unique</span> <span class="o">=</span> <span class="n">unique_combos</span><span class="p">(</span><span class="n">tups</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;buckets:&#39;</span><span class="p">,</span> <span class="n">bs</span><span class="p">,</span> 
                  <span class="s1">&#39;hashes:&#39;</span><span class="p">,</span> <span class="n">hs</span><span class="p">,</span> 
                  <span class="s1">&#39;unique:&#39;</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">unique</span><span class="o">/</span><span class="n">vocab_size</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">eval_n_buckets</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">19</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">37</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>buckets: 5 hashes: 2 unique: 0.1875
buckets: 5 hashes: 3 unique: 0.3625
buckets: 5 hashes: 4 unique: 0.5375
buckets: 5 hashes: 5 unique: 0.625
buckets: 11 hashes: 2 unique: 0.625
buckets: 11 hashes: 3 unique: 0.875
buckets: 11 hashes: 4 unique: 0.975
buckets: 11 hashes: 5 unique: 1.0
buckets: 13 hashes: 2 unique: 0.675
buckets: 13 hashes: 3 unique: 0.9
buckets: 13 hashes: 4 unique: 1.0
buckets: 13 hashes: 5 unique: 1.0
buckets: 19 hashes: 2 unique: 0.85
buckets: 19 hashes: 3 unique: 0.975
buckets: 19 hashes: 4 unique: 1.0
buckets: 19 hashes: 5 unique: 1.0
buckets: 29 hashes: 2 unique: 0.9375
buckets: 29 hashes: 3 unique: 0.9875
buckets: 29 hashes: 4 unique: 1.0
buckets: 29 hashes: 5 unique: 1.0
buckets: 37 hashes: 2 unique: 0.925
buckets: 37 hashes: 3 unique: 1.0
buckets: 37 hashes: 4 unique: 1.0
buckets: 37 hashes: 5 unique: 1.0
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30_000</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">500</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([64, 500])</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">127</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>339 ms  2.82 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">251</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>343 ms  2.82 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">997</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>352 ms  4.19 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>346 ms  3.62 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">251</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>318 ms  1.54 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">997</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>303 ms  3.05 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>284 ms  2.39 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="p">[</span><span class="mi">284</span><span class="p">,</span> <span class="mi">303</span><span class="p">,</span> <span class="mi">318</span><span class="p">,</span> <span class="mi">339</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="p">[</span><span class="mi">127</span><span class="p">,</span> <span class="mi">251</span><span class="p">,</span> <span class="mi">997</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;# of Hashes&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Time (ms) </span><span class="se">\n</span><span class="s1">to encode </span><span class="se">\n</span><span class="s1">a batch with </span><span class="se">\n</span><span class="s1">32,000 words&#39;</span><span class="p">,</span>
           <span class="n">rotation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">labelpad</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Try-memoizing-hash-func.">Try memoizing hash func.<a class="anchor-link" href="#Try-memoizing-hash-func."> </a></h2><p>Caching results does save computation but it increases memory usage, which is one of the benefits of Bloom Embeddings. However, this is probably still more memory efficient since each word in the cache is represented by only a few indices rather than a large embedding. A large embedding matrix also forces us to devote a lot of memory to unused gradients during training (if the layer is not frozen). Still, the fact that <a href="/incendio/data#probabilistic_hash_tensor"><code>probabilistic_hash_tensor</code></a> is not vectorized means that it may be best to pre-compute these and load the indices in the Dataset. Rather than caching, it may be easiest to create a w2hash dict similar to a standard w2index dict. Leaving this implementation lets the user determine what tradeoff they want between speed and memory.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nd">@lru_cache</span><span class="p">(</span><span class="n">maxsize</span><span class="o">=</span><span class="mi">30_000</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">probabilistic_hash_item</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">n_hashes</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Slightly hacky way to probabilistically hash an integer by</span>
<span class="sd">    first converting it to a string.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x: int</span>
<span class="sd">        The integer or string to hash.</span>
<span class="sd">    n_buckets: int</span>
<span class="sd">        The number of buckets that items will be mapped to. Typically </span>
<span class="sd">        this would occur outside the hashing function, but since </span>
<span class="sd">        the intended use case is so narrow here it makes sense to me </span>
<span class="sd">        to include it here.</span>
<span class="sd">    mode: type</span>
<span class="sd">        The type of input you want to hash. This is user-provided to prevent</span>
<span class="sd">        accidents where we pass in a different item than intended and hash </span>
<span class="sd">        the wrong thing. One of (int, str). When using this inside a</span>
<span class="sd">        BloomEmbedding layer, this must be `int` because there are no</span>
<span class="sd">        string tensors. When used inside a dataset or as a one-time</span>
<span class="sd">        pre-processing step, you can choose either as long as you</span>
<span class="sd">        pass in the appropriate inputs.</span>
<span class="sd">    n_hashes: int</span>
<span class="sd">        The number of times to hash x, each time with a different seed.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list[int]: A list of integers with length `n_hashes`, where each integer</span>
<span class="sd">        is in [0, n_buckets).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check type to ensure we don&#39;t accidentally hash Tensor(5) instead of 5.</span>
    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mode</span><span class="p">),</span> <span class="n">f</span><span class="s1">&#39;Input `x` must have type </span><span class="si">{mode}</span><span class="s1">.&#39;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">mmh3</span><span class="o">.</span><span class="n">hash</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">i</span><span class="p">,</span> <span class="n">signed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">%</span> <span class="n">n_buckets</span> 
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_hashes</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x_r2</span><span class="p">,</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="n">n_hashes</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">pad_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Hash a rank 2 LongTensor.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x_r2: torch.LongTensor</span>
<span class="sd">        Rank 2 tensor of integers. Shape: (bs, seq_len)</span>
<span class="sd">    n_buckets: int</span>
<span class="sd">        Number of buckets to hash items into (i.e. the number of </span>
<span class="sd">        rows in the embedding matrix). Typically a moderately large</span>
<span class="sd">        prime number, like 251 or 997.</span>
<span class="sd">    n_hashes: int</span>
<span class="sd">        Number of hashes to take for each input index. This determines</span>
<span class="sd">        the number of rows of the embedding matrix that will be summed</span>
<span class="sd">        to get the representation for each word. Typically 2-5.</span>
<span class="sd">    pad_idx: int or None</span>
<span class="sd">        If you want to pad sequences with vectors of zeros, pass in an</span>
<span class="sd">        integer (same as the `padding_idx` argument to nn.Embedding).</span>
<span class="sd">        If None, no padding index will be used. The sequences must be</span>
<span class="sd">        padded before passing them into this function.</span>
<span class="sd">        </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.LongTensor: Tensor of indices where each row corresponds</span>
<span class="sd">        to one of the input indices. Shape: (bs, seq_len, n_hashes)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
        <span class="p">[[</span><span class="n">probabilistic_hash_item</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">n_buckets</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">n_hashes</span><span class="p">)</span> 
          <span class="k">if</span> <span class="n">x</span> <span class="o">!=</span> <span class="n">pad_idx</span> <span class="k">else</span> <span class="p">[</span><span class="n">pad_idx</span><span class="p">]</span><span class="o">*</span><span class="n">n_hashes</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
         <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">x_r2</span><span class="p">]</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>191 ms  12 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>185 ms  8.76 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%%time</span>it -n 5 -r 5
<span class="n">hashed</span> <span class="o">=</span> <span class="n">probabilistic_hash_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">5_003</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>195 ms  5.1 ms per loop (mean  std. dev. of 5 runs, 5 loops each)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_item</span><span class="o">.</span><span class="n">cache_info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>CacheInfo(hits=780342, misses=19633, maxsize=30000, currsize=19633)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>19634</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_item</span><span class="o">.</span><span class="n">cache_clear</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">probabilistic_hash_item</span><span class="o">.</span><span class="n">cache_info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>CacheInfo(hits=0, misses=0, maxsize=30000, currsize=0)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

